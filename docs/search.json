[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "",
    "text": "This project is inspired from CityNerd Youtube channel and focuses on farebox recovery - the percentage of a transit system’s revenue that comes from fares instead of taxes. The data for this analysis comes from the National Transit Database(NTD). This mini-project analyzes farebox revenues, total trips, vehicle miles traveled and operating expenses for public transit systems in the U.S. in 2022.\nKey data sources:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Valeriia Frolova",
    "section": "",
    "text": "Short Bio\nFor more than 7 years, I’ve been optimizing websites and elevating brands through targeted SEO strategies. To complement my experience with advanced analytical skills, I’m pursuing an MSBA at Baruch College, driven by a passion for data-driven decisions.\n\nYou can view some of my ML projects.\nConnect with me on: X & Linkedin."
  },
  {
    "objectID": "mp01.html#step-1.-data-downloading-cleaning",
    "href": "mp01.html#step-1.-data-downloading-cleaning",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 1. Data Downloading & Cleaning",
    "text": "Step 1. Data Downloading & Cleaning\nThe first step is to install the tidyverse package, as it provides useful data manipulation tools such as:\n\ndplyr for data manipulation functions (e.g.mutate(), select(), group_by())\nggplot2 for data visualization (e.g. bar charts, line charts, scatter plots)\nreadr for reading and writing data (e.g.read_csv(), write_csv())\n\n\na) Fare Revenue Data\n\nThis dataset contains information on the total fare revenues for transit agencies. All files in downloading steps are taken directly from the official website. After the FARES data is cleaned, only important columns are selected and data is filtered by the rows where Expense Type is Funds Earned During Period.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# Let's start with Fare Revenue\nlibrary(tidyverse)\nif(!file.exists(\"2022_fare_revenue.xlsx\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_fare_revenue.xlsx\" in your project\n    # directory.\n    download.file(\"http://www.transit.dot.gov/sites/fta.dot.gov/files/2024-04/2022%20Fare%20Revenue.xlsx\", \n                  destfile=\"2022_fare_revenue.xlsx\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n    select(-`State/Parent NTD ID`, \n           -`Reporter Type`,\n           -`Reporting Module`,\n           -`TOS`,\n           -`Passenger Paid Fares`,\n           -`Organization Paid Fares`) |&gt;\n    filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n    select(-`Expense Type`) |&gt;\n    group_by(`NTD ID`,       # Sum over different `TOS` for the same `Mode`\n             `Agency Name`,  # These are direct operated and sub-contracted \n             `Mode`) |&gt;      # of the same transit modality\n                             # Not a big effect in most munis (significant DO\n                             # tends to get rid of sub-contractors), but we'll sum\n                             # to unify different passenger experiences\n    summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n    ungroup()\n\n\n\nb) Expenses Data\n\nThis step involves getting the 2022 operating expenses data. The expenses are grouped by NTD ID, Agency, Total and Mode to calculate total operating costs for each agency and transportation mode.\n\n\nif(!file.exists(\"2022_expenses.csv\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_expenses.csv\" in your project\n    # directory.\n    download.file(\"https://data.transportation.gov/api/views/dkxx-zjd6/rows.csv?date=20231102&accessType=DOWNLOAD&bom=true&format=true\", \n                  destfile=\"2022_expenses.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n    select(`NTD ID`, \n           `Agency`,\n           `Total`, \n           `Mode`) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n    rename(Expenses = Total) |&gt;\n    group_by(`NTD ID`, `Mode`) |&gt;\n    summarize(Expenses = sum(Expenses)) |&gt;\n    ungroup()\n\n\n\nc) Merging Financial Data\nFINANCIALS = FARES + EXPENSES\nTo combine the fare revenue and expenses by NTD ID and Mode – the inner_join() function is used.\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n\n\nd) Ridership Data\nIn this part, the monthly ridership data is downloaded and necessary columns are kept, especially we are interested in this data:\n\nUPT - Unlinked Passenger Trips\nVRM - Vehicle Revenue Miles\n\n\nif(!file.exists(\"ridership.xlsx\")){\n  # This should work _in theory_ but in practice it's still a bit finicky\n  # If it doesn't work for you, download this file 'by hand' in your\n  # browser and save it as \"ridership.xlsx\" in your project\n  # directory.\n  download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-09/July%202024%20Complete%20Monthly%20Ridership%20%28with%20adjustments%20and%20estimates%29_240903.xlsx\", \n                destfile=\"ridership.xlsx\", \n                quiet=FALSE, \n                method=\"wget\")\n}\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  rename(metro_area = `UZA Name`) |&gt; #task1\n  pivot_longer(-c(`NTD ID`:`3 Mode`, metro_area), \n               names_to=\"month\", \n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`), \n               names_to=\"month\", \n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  rename(metro_area =`UZA Name`) |&gt; #task1\n  group_by(`NTD ID`, `Agency`, metro_area, \n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\n\n\ne) Merging Ridership Data\nThe inner_join() function is used again for TRIPS and MILES to get them together into USAGE dataset.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\n\n\nf) Glimpse on the Main Dataset and Improving Mode column\n\nsample_n(USAGE, 1000) selects a random sample of 1000 records from the USAGE dataset;\nmutate helps to convert the month column to a character format, ensuring it’s one format for further analysis;\nDT::datatable() gives a web-like interactive table for a sampled dataset for filtering, sorting etc., ensure that DT library is installed, if not use install.packages(\"DT\") function from the previous step;\n\n\nsample_n(USAGE, 1000) |&gt; \n  mutate(month=as.character(month)) |&gt; \n  DT::datatable()\n\n\n\n\n\nNext, the mutate function is used to recode Mode column for better clarity for transportation systems. And, case_when() function replace abbreviations\nAR -&gt; Alaska Railroad etc. The distinct function checks correct transformation for unique modes.\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n))\ndistinct(USAGE, Mode)\n\n# A tibble: 18 × 1\n   Mode                       \n   &lt;chr&gt;                      \n 1 Demand Response            \n 2 Ferryboat                  \n 3 Bus                        \n 4 Streercar Rail             \n 5 Trolleybus                 \n 6 Vanpool                    \n 7 Commuter Bus               \n 8 Bus Rapid Transit          \n 9 Light Rail                 \n10 Hybrid Rail                \n11 Monorail/Automated Guideway\n12 Commuter Rail              \n13 Alaska Railroad            \n14 Aerial Tramway             \n15 Heavy Rail                 \n16 Inclined Plane             \n17 Publico                    \n18 Cable Car"
  },
  {
    "objectID": "mp01.html#step-2.-data-analysis",
    "href": "mp01.html#step-2.-data-analysis",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 2. Data Analysis",
    "text": "Step 2. Data Analysis\nQuestion 1. What transit agency had the most total VRM in our data set?\nTo get this answer, the total vehicle miles traveled by agency are aggregated (ensure to remove empty rows, and get only one agency with the highest VRM):\n\nmost_vrm_agency &lt;- USAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_agency\n\n# A tibble: 1 × 2\n  Agency                      total_VRM\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 MTA New York City Transit 10832855350\n\n\nQuestion 2. What transit mode had the most total VRM in our data set?\nThis question is pretty simple. We need to update the code above to a ‘Mode’ instead of ‘Agency’\n\nmost_vrm_mode &lt;- USAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_mode\n\n# A tibble: 1 × 2\n  Mode    total_VRM\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Bus   49444494088\n\n\nQuestion 3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThe code below calculates MTA NYC Transit trips taken by Heavy Rail mode for the month of May 2024. The summarize() function is used to create a new variable total_trips, sum sums the values in the UPT column and na.rm ignores missing values.\n\nnyc_subway_may2024 &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", Mode == \"Heavy Rail\", month == \"2024-05-01\") |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE))\nnyc_subway_may2024\n\n# A tibble: 1 × 1\n  total_trips\n        &lt;dbl&gt;\n1   180458819\n\n\nQuestion 4. How much did NYC subway ridership fall between April 2019 and April 2020? The code filters only “MTA New York City Transit” for the dates mentioned, then sums the UPT for each month. After that, the percentage drop in ridership is calculated to reflect the impact of the COVID-19 on public transportation usage during the pandemic.\n\nnyc_subway_april_ridership &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", \n         Mode == \"Heavy Rail\", \n         month %in% c(\"2019-04-01\", \"2020-04-01\")) |&gt;\n  group_by(month) |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE)) #ridership fall\n\nridership_fall &lt;- nyc_subway_april_ridership |&gt; # % fall \n  summarize(fall = 100* (total_trips[month == \"2020-04-01\"] - total_trips[month == \"2019-04-01\"]) / total_trips[month == \"2019-04-01\"])\nridership_fall\n\n# A tibble: 1 × 1\n   fall\n  &lt;dbl&gt;\n1 -91.3"
  },
  {
    "objectID": "mp01.html#more-interesting-transit-facts",
    "href": "mp01.html#more-interesting-transit-facts",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "More interesting transit facts",
    "text": "More interesting transit facts\n1. Which transit agency had the most trips in a single month?\nLet’s find out the transit agency with the most trips in a single month by grouping the data by agency and month, summing the total trips, sorting in descending order and getting the top result.\n\nmost_trip_single_month &lt;- USAGE |&gt;\n  group_by(Agency, month) |&gt;\n  summarize(total_trips = sum(UPT,na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(total_trips)) |&gt;\n  slice(1)\nmost_trip_single_month\n\n# A tibble: 1 × 3\n  Agency                    month      total_trips\n  &lt;chr&gt;                     &lt;date&gt;           &lt;dbl&gt;\n1 MTA New York City Transit 2014-10-01   322725962\n\n\n2. Which mode of transit had the highest trip length in 2024?\nThis code filters 2024 by using grepl function for month column. Then, groups Mode and calculates the average trip length by diving totals of VRM and UPT.\n\nlongest_avg_trip_2024 &lt;-USAGE |&gt;\n  filter(grepl(\"2024\", month)) |&gt;\n  group_by(Mode) |&gt;\n  summarize(avg_trip_length = sum(VRM, na.rm = TRUE) / sum(UPT, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_trip_length)) |&gt;\n  slice(1)\nlongest_avg_trip_2024\n\n# A tibble: 1 × 2\n  Mode            avg_trip_length\n  &lt;chr&gt;                     &lt;dbl&gt;\n1 Demand Response            12.8\n\n\n3. Which transit agency had the largest vehicle fleet(VRM) in 2024? This code provides the agency with the most distance(VRM) with its fleet in 2024.\n\nlargest_fleet_2024 &lt;- USAGE |&gt;\n  filter(grepl(\"2024\", month)) |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1)\nlargest_fleet_2024\n\n# A tibble: 1 × 2\n  Agency                    total_VRM\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 MTA New York City Transit 273222702"
  },
  {
    "objectID": "mp01.html#step-3.-table-summarization",
    "href": "mp01.html#step-3.-table-summarization",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 3. Table Summarization",
    "text": "Step 3. Table Summarization\n\n#Task 5 table summarization\nlibrary(dplyr)\nlibrary(lubridate) #year function\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  filter(year(month) == 2022) |&gt;\n  group_by(`NTD ID`, Agency, metro_area, Mode) |&gt;\n  summarize(\n    UPT = sum(UPT, na.rm = TRUE),\n    VRM = sum(VRM, na.rm = TRUE),\n    .groups = \"drop\"\n  )\nUSAGE_2022_ANNUAL\n\n# A tibble: 1,141 × 6\n   `NTD ID` Agency                                metro_area Mode     UPT    VRM\n      &lt;int&gt; &lt;chr&gt;                                 &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1        1 King County                           Seattle--… Bus   5.40e7 6.16e7\n 2        1 King County                           Seattle--… Dema… 6.63e5 1.29e7\n 3        1 King County                           Seattle--… Ferr… 4.00e5 5.12e4\n 4        1 King County                           Seattle--… Stre… 1.12e6 1.80e5\n 5        1 King County                           Seattle--… Trol… 9.58e6 2.64e6\n 6        1 King County                           Seattle--… Vanp… 7.03e5 4.41e6\n 7        2 Spokane Transit Authority             Spokane, … Bus   6.60e6 6.49e6\n 8        2 Spokane Transit Authority             Spokane, … Dema… 3.10e5 4.04e6\n 9        2 Spokane Transit Authority             Spokane, … Vanp… 9.06e4 9.06e5\n10        3 Pierce County Transportation Benefit… Seattle--… Bus   4.95e6 4.23e6\n# ℹ 1,131 more rows\n\nFINANCIALS_mode_updated &lt;- FINANCIALS %&gt;%\n  mutate(Mode =case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n  ))\nFINANCIALS_mode_updated\n\n# A tibble: 1,173 × 5\n   `NTD ID` `Agency Name`                           Mode  `Total Fares` Expenses\n      &lt;dbl&gt; &lt;chr&gt;                                   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1        1 King County Department of Metro Transit Comm…       5216912   0     \n 2        1 King County Department of Metro Transit Dema…        832327   6.05e7\n 3        1 King County Department of Metro Transit Ferr…       1715265   8.90e6\n 4        1 King County Department of Metro Transit Ligh…      29386480   0     \n 5        1 King County Department of Metro Transit Bus        56846337   6.72e8\n 6        1 King County Department of Metro Transit Stre…        588495   1.25e7\n 7        1 King County Department of Metro Transit Trol…      10123486   8.42e7\n 8        1 King County Department of Metro Transit Vanp…       5484481   8.91e6\n 9        2 Spokane Transit Authority               Dema…        531284   1.80e7\n10        2 Spokane Transit Authority               Bus         6135110   7.53e7\n# ℹ 1,163 more rows\n\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n                                  FINANCIALS_mode_updated, \n                                  join_by(`NTD ID`, Mode)) |&gt;\n  drop_na()"
  },
  {
    "objectID": "mp01.html#step-4.-farebox-recovery-among-major-systems",
    "href": "mp01.html#step-4.-farebox-recovery-among-major-systems",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 4. Farebox Recovery Among Major Systems",
    "text": "Step 4. Farebox Recovery Among Major Systems\n\nWhich transit system (agency and mode) had the most UPT in 2022?\n\n\nmost_upt_2022 &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  arrange(desc(UPT)) |&gt;\n  slice(1)\nmost_upt_2022\n\n# A tibble: 1 × 9\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20008 MTA New Y… New York-… Heav… 1.79e9 3.38e8 MTA New York…    2326782567\n# ℹ 1 more variable: Expenses &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\n\n\nhighest_farebox_recovery &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(farebox_recovery = `Total Fares` / Expenses) |&gt;\n  arrange(desc(farebox_recovery)) |&gt;\n  slice(1)\nhighest_farebox_recovery\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20190 Port Impe… New York-… Ferr… 3.76e6 504037 Port Imperia…      33443241\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, farebox_recovery &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the lowest expenses per UPT?\n\n\nlower_expenses_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_upt = Expenses / UPT) |&gt;\n  arrange(expenses_per_upt) |&gt;\n  slice(1)\nlower_expenses_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40147 North Car… Raleigh, … Bus   2.31e6 531555 North Caroli…             0\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_upt &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the highest total fares per UPT?\n\n\nhighest_fares_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_upt = `Total Fares` / UPT) |&gt;\n  arrange(desc(fares_per_upt)) |&gt;\n  slice(1)\nhighest_fares_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20217 Hampton J… New York-… Comm… 521577 2.04e6 Hampton Jitn…      21539188\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_upt &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the lowest expenses per VRM?\n\n\nlowest_expenses_per_vrm &lt;-USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_vrm = Expenses / VRM) |&gt;\n  arrange(expenses_per_vrm) |&gt;\n  slice(1)\nlowest_expenses_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    90094 Metropoli… San Franc… Vanp… 1.02e6 1.23e7 Metropolitan…       6504406\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_vrm &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the highest total fares per VRM?\n\n\nhighest_fares_per_vrm &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_vrm = `Total Fares` / VRM) |&gt;\n  arrange(desc(fares_per_vrm)) |&gt;\n  slice(1)\nhighest_fares_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency      metro_area Mode     UPT   VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40040 Jacksonvil… Jacksonvi… Ferr… 416129  9084 Jacksonville…       1432549\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_vrm &lt;dbl&gt;"
  },
  {
    "objectID": "mp01.html#part-1.-data-downloading-cleaning",
    "href": "mp01.html#part-1.-data-downloading-cleaning",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 1. Data Downloading & Cleaning",
    "text": "Part 1. Data Downloading & Cleaning\nThe first step is to install the tidyverse package, as it provides useful data manipulation tools such as:\n\ndplyr for data manipulation functions (e.g.mutate(), select(), group_by())\nggplot2 for data visualization (e.g. bar charts, line charts, scatter plots)\nreadr for reading and writing data (e.g.read_csv(), write_csv())\n\n\na) Fare Revenue Data\n\nThis dataset contains information on the total fare revenues for transit agencies. All files in downloading steps are taken directly from the official website. After the FARES data is cleaned, only important columns are selected and data is filtered by the rows where Expense Type is Funds Earned During Period.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# Let's start with Fare Revenue\nlibrary(tidyverse)\nif(!file.exists(\"2022_fare_revenue.xlsx\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_fare_revenue.xlsx\" in your project\n    # directory.\n    download.file(\"http://www.transit.dot.gov/sites/fta.dot.gov/files/2024-04/2022%20Fare%20Revenue.xlsx\", \n                  destfile=\"2022_fare_revenue.xlsx\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n    select(-`State/Parent NTD ID`, \n           -`Reporter Type`,\n           -`Reporting Module`,\n           -`TOS`,\n           -`Passenger Paid Fares`,\n           -`Organization Paid Fares`) |&gt;\n    filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n    select(-`Expense Type`) |&gt;\n    group_by(`NTD ID`,       # Sum over different `TOS` for the same `Mode`\n             `Agency Name`,  # These are direct operated and sub-contracted \n             `Mode`) |&gt;      # of the same transit modality\n                             # Not a big effect in most munis (significant DO\n                             # tends to get rid of sub-contractors), but we'll sum\n                             # to unify different passenger experiences\n    summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n    ungroup()\n\n\n\nb) Expenses Data\n\nThis step involves getting the 2022 operating expenses data. The expenses are grouped by NTD ID, Agency, Total and Mode to calculate total operating costs for each agency and transportation mode.\n\n\nif(!file.exists(\"2022_expenses.csv\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_expenses.csv\" in your project\n    # directory.\n    download.file(\"https://data.transportation.gov/api/views/dkxx-zjd6/rows.csv?date=20231102&accessType=DOWNLOAD&bom=true&format=true\", \n                  destfile=\"2022_expenses.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n    select(`NTD ID`, \n           `Agency`,\n           `Total`, \n           `Mode`) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n    rename(Expenses = Total) |&gt;\n    group_by(`NTD ID`, `Mode`) |&gt;\n    summarize(Expenses = sum(Expenses)) |&gt;\n    ungroup()\n\n\n\nc) Merging Financial Data\nFINANCIALS = FARES + EXPENSES\nTo combine the fare revenue and expenses by NTD ID and Mode – the inner_join() function is used.\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n\n\nd) Ridership Data\nIn this part, the monthly ridership data is downloaded and necessary columns are kept, especially we are interested in this data:\n\nUPT - Unlinked Passenger Trips\nVRM - Vehicle Revenue Miles\n\n\nif(!file.exists(\"ridership.xlsx\")){\n  # This should work _in theory_ but in practice it's still a bit finicky\n  # If it doesn't work for you, download this file 'by hand' in your\n  # browser and save it as \"ridership.xlsx\" in your project\n  # directory.\n  download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-09/July%202024%20Complete%20Monthly%20Ridership%20%28with%20adjustments%20and%20estimates%29_240903.xlsx\", \n                destfile=\"ridership.xlsx\", \n                quiet=FALSE, \n                method=\"wget\")\n}\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  rename(metro_area = `UZA Name`) |&gt; #task1\n  pivot_longer(-c(`NTD ID`:`3 Mode`, metro_area), \n               names_to=\"month\", \n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`), \n               names_to=\"month\", \n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  rename(metro_area =`UZA Name`) |&gt; #task1\n  group_by(`NTD ID`, `Agency`, metro_area, \n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\n\n\ne) Merging Ridership Data\nThe inner_join() function is used again for TRIPS and MILES to get them together into USAGE dataset.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\n\n\nf) Glimpse of the Main Dataset and Improving Mode column\n\nsample_n(USAGE, 1000) selects a random sample of 1000 records from the USAGE dataset;\nmutate helps to convert the month column to a character format, ensuring it’s one format for further analysis;\nDT::datatable() gives a web-like interactive table for a sampled dataset for filtering, sorting etc., ensure that DT library is installed, if not use install.packages(\"DT\") function from the previous step;\n\n\nsample_n(USAGE, 1000) |&gt; \n  mutate(month=as.character(month)) |&gt; \n  DT::datatable()\n\n\n\n\n\nNext, the mutate function is used to recode Mode column for better clarity for transportation systems. And, case_when() function replace abbreviations\nAR -&gt; Alaska Railroad etc. The distinct function checks correct transformation for unique modes.\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n))\ndistinct(USAGE, Mode)\n\n# A tibble: 18 × 1\n   Mode                       \n   &lt;chr&gt;                      \n 1 Demand Response            \n 2 Ferryboat                  \n 3 Bus                        \n 4 Streercar Rail             \n 5 Trolleybus                 \n 6 Vanpool                    \n 7 Commuter Bus               \n 8 Bus Rapid Transit          \n 9 Light Rail                 \n10 Hybrid Rail                \n11 Monorail/Automated Guideway\n12 Commuter Rail              \n13 Alaska Railroad            \n14 Aerial Tramway             \n15 Heavy Rail                 \n16 Inclined Plane             \n17 Publico                    \n18 Cable Car"
  },
  {
    "objectID": "mp01.html#part-2.-data-analysis",
    "href": "mp01.html#part-2.-data-analysis",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 2. Data Analysis",
    "text": "Part 2. Data Analysis\n\nQuestion 1. What transit agency had the most total VRM in our data set?\nTo get this answer, the total vehicle miles traveled by agency are aggregated (ensure to remove empty rows, and get only one agency with the highest VRM):\n\nmost_vrm_agency &lt;- USAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_agency\n\n# A tibble: 1 × 2\n  Agency                      total_VRM\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 MTA New York City Transit 10832855350\n\n\n\n\nQuestion 2. What transit mode had the most total VRM in our data set?\nThis question is pretty simple. We need to update the code above to a ‘Mode’ instead of ‘Agency’\n\nmost_vrm_mode &lt;- USAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_mode\n\n# A tibble: 1 × 2\n  Mode    total_VRM\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Bus   49444494088\n\n\n\n\nQuestion 3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThe code below calculates MTA NYC Transit trips taken by Heavy Rail mode for the month of May 2024. The summarize() function is used to create a new variable total_trips, sum sums the values in the UPT column and na.rm ignores missing values.\n\nnyc_subway_may2024 &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", Mode == \"Heavy Rail\", month == \"2024-05-01\") |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE))\nnyc_subway_may2024\n\n# A tibble: 1 × 1\n  total_trips\n        &lt;dbl&gt;\n1   180458819\n\n\n\n\nQuestion 4. How much did NYC subway ridership fall between April 2019 and April 2020?\nThe code filters only “MTA New York City Transit” for the dates mentioned, then sums the UPT for each month. After that, the percentage drop in ridership is calculated to reflect the impact of the COVID-19 on public transportation usage during the pandemic.\n\nnyc_subway_april_ridership &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", \n         Mode == \"Heavy Rail\", \n         month %in% c(\"2019-04-01\", \"2020-04-01\")) |&gt;\n  group_by(month) |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE)) #ridership fall\n\nridership_fall &lt;- nyc_subway_april_ridership |&gt; # % fall \n  summarize(fall = 100* (total_trips[month == \"2020-04-01\"] - total_trips[month == \"2019-04-01\"]) / total_trips[month == \"2019-04-01\"])\nridership_fall\n\n# A tibble: 1 × 1\n   fall\n  &lt;dbl&gt;\n1 -91.3"
  },
  {
    "objectID": "mp01.html#part-3.-table-summarization",
    "href": "mp01.html#part-3.-table-summarization",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 3. Table Summarization",
    "text": "Part 3. Table Summarization\nThis code is responsible for creating an annual summary of public transit usage and financial data for 2022 - USAGE_2022_ANNUAL, steps\n1) Filtering and summarizing transit data for 2022.\n2) Updating Financial data mode labels.\n3) Join the USAGE_AND_FINANCIALS and making sure that modes aren’t abbreviated.\n\n#Task 5 table summarization\nlibrary(dplyr)\nlibrary(lubridate) #year function\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  filter(year(month) == 2022) |&gt;\n  group_by(`NTD ID`, Agency, metro_area, Mode) |&gt;\n  summarize(\n    UPT = sum(UPT, na.rm = TRUE),\n    VRM = sum(VRM, na.rm = TRUE),\n    .groups = \"drop\"\n  )\nUSAGE_2022_ANNUAL\n\n# A tibble: 1,141 × 6\n   `NTD ID` Agency                                metro_area Mode     UPT    VRM\n      &lt;int&gt; &lt;chr&gt;                                 &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1        1 King County                           Seattle--… Bus   5.40e7 6.16e7\n 2        1 King County                           Seattle--… Dema… 6.63e5 1.29e7\n 3        1 King County                           Seattle--… Ferr… 4.00e5 5.12e4\n 4        1 King County                           Seattle--… Stre… 1.12e6 1.80e5\n 5        1 King County                           Seattle--… Trol… 9.58e6 2.64e6\n 6        1 King County                           Seattle--… Vanp… 7.03e5 4.41e6\n 7        2 Spokane Transit Authority             Spokane, … Bus   6.60e6 6.49e6\n 8        2 Spokane Transit Authority             Spokane, … Dema… 3.10e5 4.04e6\n 9        2 Spokane Transit Authority             Spokane, … Vanp… 9.06e4 9.06e5\n10        3 Pierce County Transportation Benefit… Seattle--… Bus   4.95e6 4.23e6\n# ℹ 1,131 more rows\n\nFINANCIALS_mode_updated &lt;- FINANCIALS %&gt;%\n  mutate(Mode =case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n  ))\nFINANCIALS_mode_updated\n\n# A tibble: 1,173 × 5\n   `NTD ID` `Agency Name`                           Mode  `Total Fares` Expenses\n      &lt;dbl&gt; &lt;chr&gt;                                   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1        1 King County Department of Metro Transit Comm…       5216912   0     \n 2        1 King County Department of Metro Transit Dema…        832327   6.05e7\n 3        1 King County Department of Metro Transit Ferr…       1715265   8.90e6\n 4        1 King County Department of Metro Transit Ligh…      29386480   0     \n 5        1 King County Department of Metro Transit Bus        56846337   6.72e8\n 6        1 King County Department of Metro Transit Stre…        588495   1.25e7\n 7        1 King County Department of Metro Transit Trol…      10123486   8.42e7\n 8        1 King County Department of Metro Transit Vanp…       5484481   8.91e6\n 9        2 Spokane Transit Authority               Dema…        531284   1.80e7\n10        2 Spokane Transit Authority               Bus         6135110   7.53e7\n# ℹ 1,163 more rows\n\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n                                  FINANCIALS_mode_updated, \n                                  join_by(`NTD ID`, Mode)) |&gt;\n  drop_na()"
  },
  {
    "objectID": "mp01.html#part-4.-farebox-recovery-among-major-systems",
    "href": "mp01.html#part-4.-farebox-recovery-among-major-systems",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 4. Farebox Recovery Among Major Systems",
    "text": "Part 4. Farebox Recovery Among Major Systems\n\n1. Which transit system (agency and mode) had the most UPT in 2022?\nThe metric of Unlinked Passengers Trips or UPT provides insight into how many time passengers boarded a transit vehicle. The high UPT equals to more frequent trips. To filter the busiest system, we set 400,000 UPT at least in 2022 and sorted by the highest total.\n\nmost_upt_2022 &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  arrange(desc(UPT)) |&gt;\n  slice(1)\nmost_upt_2022\n\n# A tibble: 1 × 9\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20008 MTA New Y… New York-… Heav… 1.79e9 3.38e8 MTA New York…    2326782567\n# ℹ 1 more variable: Expenses &lt;dbl&gt;\n\n\nResult: It’s no surprise that MTA New York City Transit - Heavy Rail leads with 1.79 billion UPT. The immense number of people rely on it every day, both New Yorkers and tourists.\n\n\n2. Which transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\nThe farebox recovery ratio measures the percentage of operating expenses covered by fare revenue. In this research we will take only a glimpse how financially self-sustaining a transit system is.\n\nhighest_farebox_recovery &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(farebox_recovery = `Total Fares` / Expenses) |&gt;\n  arrange(desc(farebox_recovery)) |&gt;\n  slice(1)\nhighest_farebox_recovery\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20190 Port Impe… New York-… Ferr… 3.76e6 504037 Port Imperia…      33443241\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, farebox_recovery &lt;dbl&gt;\n\n\nResult: Port Imperial Ferry (New York-New Jersey area) is on the top of the chart with 66.3% farebox recovery ratio. This higher ratio means that it’s less reliant on subsidies from local or federal governments.\n\n\n3. Which transit system (agency and mode) has the lowest expenses per UPT?\nWith Expenses per UPT we measure how much it costs to transport a single pasenger for a trip. Lower expenses per trip indicate better services at reduced cost.\n\nlower_expenses_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_upt = Expenses / UPT) |&gt;\n  arrange(expenses_per_upt) |&gt;\n  slice(1)\nlower_expenses_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40147 North Car… Raleigh, … Bus   2.31e6 531555 North Caroli…             0\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_upt &lt;dbl&gt;\n\n\nResult: The North Carolina Department of Transportation’s Bus system in Raleigh leads this chart with the lowest expenses per trip.\n\n\n4. Which transit system (agency and mode) has the highest total fares per UPT?\nTotal fares per UPT provide an indicator how much revenue the system is generating from each passenger trip. Higher fares can be due to the distances or premium services.\n\nhighest_fares_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_upt = `Total Fares` / UPT) |&gt;\n  arrange(desc(fares_per_upt)) |&gt;\n  slice(1)\nhighest_fares_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20217 Hampton J… New York-… Comm… 521577 2.04e6 Hampton Jitn…      21539188\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_upt &lt;dbl&gt;\n\n\nResult: Hampton Jitney(Commuter Bus) in the New York City are had the highest total $41.29 per UPT and is the combination of long-distance and premium services for people who want to spend the vacation in Hamptons.\n\n\n5. Which transit system (agency and mode) has the lowest expenses per VRM?\n\nlowest_expenses_per_vrm &lt;-USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_vrm = Expenses / VRM) |&gt;\n  arrange(expenses_per_vrm) |&gt;\n  slice(1)\nlowest_expenses_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    90094 Metropoli… San Franc… Vanp… 1.02e6 1.23e7 Metropolitan…       6504406\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_vrm &lt;dbl&gt;\n\n\n\n\n6. Which transit system (agency and mode) has the highest total fares per VRM?\nNow we are interested how much revenue is being generated for each mile traveled and the higher fare revenue is the more expensive/premium services are or efficient fare collection.\n\nhighest_fares_per_vrm &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_vrm = `Total Fares` / VRM) |&gt;\n  arrange(desc(fares_per_vrm)) |&gt;\n  slice(1)\nhighest_fares_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency      metro_area Mode     UPT   VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40040 Jacksonvil… Jacksonvi… Ferr… 416129  9084 Jacksonville…       1432549\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_vrm &lt;dbl&gt;\n\n\nResult: Jacksonville Transportation Authority’s Ferry service generates $157.71 per VTM. Meaning, ferry service in that location, has significantly higher fares compared to bus or rail, due to specific travel needs.\n\n\nThis mini-project provides valuable insights into the operational, financial efficiency and sustainability of various U.S. transit systems; and gives a great glimpse into the data how well certain transit agencies manage the cost efficiency and revenue generation from fares."
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "In this project, we will analyze the Hollywood history and get data-driven ideas for a “new movie” by defining best genres, actors, directors of a decade, all the time and assign special weighted score that will help us to identify the secret of a successful sauce to make the catchy and appealing movie for the nowadays audience. Let’s begin!\nThe key data source that will be used is the Internet Movie Database (IMDb) for non-commercial use."
  },
  {
    "objectID": "mp02.html#before-we-start",
    "href": "mp02.html#before-we-start",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "Before we start",
    "text": "Before we start\n\n1) Import libraries\nThe first step before you start doing anything on your project is to make sure that you have all your packages installed. However, don’t be worried if you miss any, you can add them anywhere in the code, but for readability and clean code writing you should build that habit of importing everything when you start. While we are familiar already with the most of the packages I will add only two comments for new ones.\nNote: The code will be collapsed for better navigation.\n\n\nImport Libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(tidyr)\nlibrary(knitr) #improves readability of outputs\nlibrary(kableExtra) #addition to knitr, styling tables in R Markdown documents \n#install.packages(\"kableExtra\") #if it didn't import, do install command\n\n\n\n\n2) Import the dataset\nIt might take some time to download it and several times I caught myself on thought that R Studio was not working, but it was. Just give it a time, some of the datasets have more than 3M rows!\n\n\nImport IMDb Data\nget_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS      &lt;- get_imdb_file(\"name.basics\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title.basics\")\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\n\nAfter this step we will start our EDA(explanatory data analysis)\n\n\n\nSource: geeksforgeeks.org\n\n\n\n\n3) Data Sub-Sampling\nWe will sample our data to smaller chunks for this analysis and will use “knownForTites” names assigned by IMDb and Titles that have more than 100 ratings as we don’t need anything lower for finding the best samples to follow for our movie idea. As well we will do a semi-join to return only the values that have a match and doesn’t add collumns.\n\n\nData Sub-Sampling\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n#semi-join\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\n\n\n4) Data Cleaning\nIn this step, we will correct the column types of the TITLE tables using a combination of mutate and the coercion functions as.numeric and as.logical.\n\n\nNAME_BASICS Example\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\n\nBefore we will change all types it’s useful to check what is your data with glimpse function.\n\n\nGlimpse Example\nglimpse(NAME_BASICS)\nglimpse(TITLE_BASICS)\nglimpse(TITLE_EPISODES)\nglimpse(TITLE_RATINGS)\nglimpse(TITLE_CREW)\nglimpse(TITLE_PRINCIPLES)\n\n\nAnother good function is separate_longer_delim that helps to break view into multiple rows, here’s the example:\n\n\nSeparate_longer_delim function\nNAME_BASICS |&gt; separate_longer_delim(knownForTitles, \",\") |&gt; slice_head(n=10)\n\n\nHere’s a small schema that shows all connections between the tables.\n\n\n\n\n\n\nTask 1. Correct all TITLE tables\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(startYear = as.numeric(startYear),\n           endYear = as.numeric(endYear),\n           isAdult = as.logical(as.numeric(isAdult))\n           )\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(seasonNumber = as.numeric(seasonNumber),\n           episodeNumbers = as.numeric(episodeNumber))\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(averageRating = as.numeric(averageRating),\n           numVotes = as.numeric(numVotes))\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate(directors = as.character(directors),\n           writers = as.character(writers))\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate(ordering = as.numeric(ordering),\n           category = as.character(category),\n           job = as.character(job),\n           characters =as.character(characters))\n\nAfter we wrangled and cleaned our dataset we can proceed to simple data manipulations and answer some questions!\n\n\n\nTask 2. Bunch of dataset questions\n\n\n1) How many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nQuestions\nAnswers\n\n\n\n\nHow many movies are in our data set?\n132091\n\n\nHow many TV series?\n29942\n\n\nHow many TV episodes?\n156442\n\n\n\n\n\nQuestion 1 Code\nTITLE_BASICS |&gt;\n  group_by(titleType) |&gt;\n  summarise(count = n())\n\n\n\n\n2) Who is the oldest living person in our data set?\nAnswer: Traudl Lessing was born in 1625.\n\n\nQuestion 2 Code\noldest_person &lt;- NAME_BASICS |&gt;\n  filter(is.na(deathYear)) |&gt;\n  filter(birthYear == min(birthYear, na.rm = TRUE)) |&gt;\n  select(primaryName,birthYear)\nprint(oldest_person)\n\n\n\n\n3) There is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\nAnswer: Ozymandias\n\n\nQuestion 3 Code\nbest_episode &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10, numVotes &gt;= 200000) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, titleType)\nprint(best_episode)\n\n\n\n\n4) What four projects is the actor Mark Hamill most known for?\nAnswer:\n1. Star Wars: Episode IV - A New Hope\n2. Star Wars: Episode VIII - The Last Jedi\n3. Star Wars: Episode V - The Empire Strikes Back\n4. Star Wars: Episode VI - Return of the Jedi\n\n\nQuestion 4 Code\nhamill_titles &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  separate_rows(knownForTitles, sep = \",\") |&gt;\n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  select (primaryTitle)\nprint(hamill_titles)\nprint(best_episode)\n\n\n\n\n5) What TV series, with more than 12 episodes, has the highest average rating?\nAnswer: Breaking Bad with the average rating 9.5.\n\n\nQuestion 5 Code\ntop_series &lt;- TITLE_EPISODES |&gt;\n  count(parentTconst) |&gt;\n  filter(n&gt;12) |&gt;\n  inner_join(TITLE_RATINGS, by = c(\"parentTconst\" = \"tconst\")) |&gt;\n  arrange(desc(averageRating)) |&gt;\n  top_n(1) |&gt;\n  inner_join(TITLE_BASICS, by = c(\"parentTconst\" =\"tconst\")) |&gt;\n  select(primaryTitle, averageRating)\nprint(top_series)\n\n\n\n\n6) Is it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\nAnswer: It’s not true, all episodes from later seasons have 7.4 rating.\n\n\nQuestion 6 Code\nhappy_days &lt;- TITLE_BASICS |&gt;\n  filter(primaryTitle == \"Happy Days\") |&gt;\n  inner_join(TITLE_EPISODES, by = c(\"tconst\" = \"parentTconst\")) |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  group_by(seasonNumber) |&gt;\n  summarise(avg_rating = mean(averageRating, na.rm = TRUE)) |&gt;\n  arrange (seasonNumber)\nprint(happy_days)\n\n\n\n\nTask 3. Custom Success Metric\nSome time ago I was doing Netflix RFP where was calculating something close to success metric, that was called Weighted Popularity Score(WPS). It’s mission was to define a balance between amount of votes and score to give a fair value that indicated quality, a large number of ratings and broad awareness in the public.\n\n\n\n\n\n\n\nClick on the image to check the whole presentation.\n\n\nThis type of score is pretty similar to calculations that search engine uses to rank the websites in the top but there definitely many more variables to account for. Here’s a great article about Reddit’s Hot Ranking that uses very close logic to this!\nFirst time, when I used this formula it felt “I have no idea what I’m doing”. Giving a credit to the article from Hackernoon and the quote when I read how’s Reddit algo works to make sure that my formula is legit. as I know as well only basic algebra.\n\n\n\n\n\nTo cut the long story short, here’s its meaning:\nThe formula combines IMDB ratings and the logarithm of the number of IMDB votes. The logarithmic scaling minimizes the impact of unevenly high or low vote counts while highlighting quality, popularity, and relevance of the rating to votes. By adding 1 to the formula, we avoid taking the logarithm of zero. Let’s begin coding!\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\n\n\n1) Choose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\nAnswer:\n\n\n\n\n\n\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. Breaking Bad\n138.8069\n9.5\n2216074\n\n\n2. The Shawshank Redemption\n138.5429\n9.3\n2949309\n\n\n3. Game of Thrones\n134.9721\n9.2\n2352239\n\n\n4. The Dark Knight\n134.0153\n9.0\n2930213\n\n\n5. The Godfather\n133.7331\n9.2\n2055854\n\n\n6. The Lord of the Rings: The Return of the King\n130.6624\n9.0\n2018856\n\n\n7. Pulp Fiction\n130.2338\n8.9\n2264831\n\n\n8. Inception\n129.9884\n8.8\n2601001\n\n\n9. The Lord of the Rings: The Fellowship of the Ring\n129.3403\n8.9\n2048498\n\n\n10. Fight Club\n129.2115\n8.8\n2381226\n\n\n\n\n\nQuestion 1 Code\ntop_movies &lt;- TITLE_RATINGS |&gt;\n  arrange(desc(weighted_popularity_score)) |&gt;\n  head(10) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\nprint(top_movies)\n\n\n\n\n2) Choose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\nAnswer:\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. Robyn Hood\n8.764990\n1.0\n6405\n\n\n2. 321 Action\n9.231123\n1.0\n10209\n\n\n3. The Gringo Papi\n9.467536\n1.1\n5468\n\n\n4. Decrepit Crescendo\n9.913832\n1.2\n3871\n\n\n5. What Must Be Done\n9.995746\n1.1\n8839\n\n\n\n\n\nQuestion 2 Code\nlow_movies &lt;- TITLE_RATINGS |&gt;\n  filter(numVotes &gt;quantile(TITLE_RATINGS$numVotes, 0.9)) |&gt;\n  arrange(weighted_popularity_score) |&gt;\n  head(5) |&gt;\n  inner_join (TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\nprint(low_movies)\n\n\nConclusion for 1 & 2, the weighted_popularity_score (WPS) valid compared with the data and show proper calculation to both highest or lowest amount of votes with scores.\n\n\n3) Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\nOne of my the most favorite movies is “Inception” so let’s take Cillian Murphy to check the WPS.\nAnswer:\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. The Dark Knight\n134.01527\n9.0\n2930213\n\n\n2. Inception\n129.98838\n8.8\n2601001\n\n\n3. Peaky Blinders\n118.12761\n8.8\n675758\n\n\n4. Batman Begins\n117.17419\n8.2\n1606446\n\n\n5. Oppenheimer\n112.84997\n8.3\n803217\n\n\n\n\n\nQuestion 3 Code\n#finding cillian murphy id in the dataset\ncillian_murphy &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Cillian Murphy\") |&gt;\n  select(nconst, primaryName)\nprint(cillian_murphy)\n\nsuccessful_actor &lt;- TITLE_PRINCIPALS |&gt;\n  filter(nconst == \"nm0614165\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  arrange(desc(weighted_popularity_score)) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\nprint(successful_actor)\n\n\n\n\n4) Perform at least one other form of ‘spot check’ validation.\nThe best way to cut unpopular vs popular movies is to verify with minimum and maximum functions. And do a quick check where are the most points are.\nMin: 4.62 Max: 138.8\n\n\nQuestion 4 Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\nmin_score &lt;- min(TITLE_RATINGS$weighted_popularity_score, na.rm = TRUE)\nmax_score &lt;- max(TITLE_RATINGS$weighted_popularity_score, na.rm = TRUE)\n\nTITLE_RATINGS |&gt;\n  ggplot(aes(x = weighted_popularity_score)) +\n  geom_histogram(bins = 50) +\n  xlab(\"Weighted Popularity Score\") +\n  ylab(\"Number of Titles\") +\n  ggtitle(\"Distribution of Weighted Popularity Scores\") +\n  theme_minimal()\n\n\n\n\n5) Come up with a numerical threshold for a project to be a ‘success’; that is, determine a value v such that movies above v are all “solid” or better.\nThe 90th percentile corresponds to a 59.87, so we will set a threshold value not lower than 59 to capture the truly successful movies.\n\n\nQuestion 5 - Code\nquantiles &lt;- quantile(TITLE_RATINGS$weighted_popularity_score, probs = seq(0, 1, 0.1), na.rm = TRUE)\nprint(quantiles)\n\nsuccess_threshold &lt;- 59\n\n\n\n\nTask 4. Trends in Success Over Time\nAlright, now we can check data more with a threshold set to find successful plots that attract the audience.\n\n\nTask 4 - Data Prep\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\ntitles_data &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\")\nmovies_data &lt;- titles_data |&gt;\n  filter(titleType == \"movie\")\nmovies_data &lt;- movies_data |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 1900 & startYear &lt;= 2024)\nmovies_data &lt;- movies_data |&gt;\n  separate_rows(genres, sep = \",\")\nmovies_data &lt;- movies_data |&gt;\n  filter(genres != \"\\\\N\")\nsuccess_threshold &lt;- 59\nmovies_data &lt;- movies_data |&gt;\n  mutate(is_success = ifelse(weighted_popularity_score &gt;= success_threshold, TRUE, FALSE))\n#creating a decade\nmovies_data &lt;- movies_data |&gt;\n  mutate(decade = floor(startYear / 10) * 10)\n\n# a) Count successes by genre and decade\ngenre_decade_successes &lt;- movies_data |&gt;\n  filter(is_success) |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n# b) Total number of movies by genre and decade\ngenre_decade_totals &lt;- movies_data |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n# c) Calculate success rate\ngenre_decade_stats &lt;- genre_decade_successes |&gt;\n  inner_join(genre_decade_totals, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count)\n\n\n\n\n1) What was the genre with the most “successes” in each decade?\nPreviously, we assigned the threshold and further analyses will be based on this “success metric”.\nSpoiler: People love Drama!\n\n\n\nDecade\nGenre\nSuccess Count\n\n\n\n\n1910\nDrama\n3\n\n\n1920\nDrama\n51\n\n\n1930\nDrama\n133\n\n\n1940\nDrama\n237\n\n\n1950\nDrama\n341\n\n\n1960\nDrama\n424\n\n\n1970\nDrama\n469\n\n\n1980\nDrama\n574\n\n\n1990\nDrama\n1093\n\n\n2000\nDrama\n1808\n\n\n2010\nDrama\n2446\n\n\n2020\nDrama\n975\n\n\n\n\n\nQuestion 1 - Code\ntop_genres_per_decade &lt;- genre_decade_successes |&gt;\n  group_by(decade) |&gt;\n  top_n(1, wt = success_count) |&gt;\n  arrange(decade)\nprint(top_genres_per_decade)\n\n\nPlotting over time with new gganimate knowledge.\n\n\nQuestion 1 - Moving plot\nif (!require(gganimate)) install.packages(\"gganimate\")\nif (!require(gifski)) install.packages(\"gifski\")\nif (!require(av)) install.packages(\"av\")\nif (!require(scales)) install.packages(\"scales\")\n\n# Load libraries\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(av)\nlibrary(scales)\nlibrary(dplyr)\nlibrary(tidyr)\n#I was doing this code separately in R, so you will see some variables we did before \nmovies_data &lt;- movies_data |&gt;\n  mutate(is_success = ifelse(weighted_popularity_score &gt;= success_threshold, TRUE, FALSE))\n\ngenre_decade_successes &lt;- movies_data |&gt;\n  filter(is_success) |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n\ntop_genres_overall &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(total_successes = sum(success_count), .groups = 'drop') |&gt;\n  arrange(desc(total_successes)) |&gt;\n  head(10) |&gt;\n  pull(genres)\n\nplot_data &lt;- genre_decade_successes |&gt;\n  filter(genres %in% top_genres_overall)\n\n# Create the animated plot\nanimation &lt;- ggplot(plot_data, aes(x = reorder(genres, success_count), y = success_count, fill = genres)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Number of Successful Movies by Genre in {closest_state}\",\n       x = \"Genre\",\n       y = \"Number of Successful Movies\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 16, face = \"bold\")) +\n  transition_states(decade, transition_length = 2, state_length = 1) +\n  ease_aes('cubic-in-out')\n\n# Render\nanimate(animation, renderer = gifski_renderer(), width = 800, height = 600)\nanim_save(\"genre_successes.gif\", animation = last_animation())\n\n\n\n\n2) What genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\nAnswer:\n\n\n\nGenres\nDecades with success\nTotal successes\n\n\n\n\nDrama\n12\n8554\n\n\nAction\n12\n2767\n\n\nCrime\n12\n2639\n\n\nRomance\n12\n2419\n\n\nAdventure\n12\n1826\n\n\nHistory\n12\n687\n\n\nWar\n12\n446\n\n\nComedy\n11\n4379\n\n\nThriller\n11\n1809\n\n\nBiography\n11\n1146\n\n\nMystery\n11\n1143\n\n\nHorror\n11\n1012\n\n\nDocumentary\n11\n883\n\n\nFantasy\n11\n762\n\n\nAnimation\n11\n632\n\n\n\n\n\nQuestion 2 - Code\ngenre_decade_presence &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(decades_with_success = n_distinct(decade), .groups = 'drop')\n\ntotal_successes_per_genre &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(total_successes = sum(success_count), .groups = 'drop')\n\ngenre_consistency &lt;- genre_decade_presence |&gt;\n  inner_join(total_successes_per_genre, by = \"genres\") |&gt;\n  arrange(desc(decades_with_success), desc(total_successes))\n\nprint(n = 15, genre_consistency)\n\n\n\n\n3) What genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nAnswer:\nWhat genre has produced the most “successes” since 2010?\nAnswer: Drama has produced the most “successes” since 2010, with 3,421 successful movies.\nDoes it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nAnswer: Drama does not have the highest success rate. Its large number of successes is primarily due to the high number of productions in that genre. The success rate for Drama is 12.0%, which is lower than genres like Biography (22.4%) and Adventure (20.3%).\n\n\nQuestion 3 - Code\nmovies_since_2010 &lt;- movies_data |&gt;\n  filter(startYear &gt;= 2010)\n\nsuccesses_since_2010 &lt;- movies_since_2010 |&gt;\n  filter(is_success) |&gt;\n  group_by(genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n\ntotal_since_2010 &lt;- movies_since_2010 |&gt;\n  group_by(genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n\ngenre_success_rate_since_2010 &lt;- successes_since_2010 |&gt;\n  inner_join(total_since_2010, by = \"genres\") |&gt;\n  mutate(success_rate = success_count / total_count) |&gt;\n  arrange(desc(success_count))\n\nprint(genre_success_rate_since_2010)\n\n\nHere’s a plot:\n\n\nQuestion 3 - Code\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(genre_success_rate_since_2010, aes(x = reorder(genres, success_count), y = success_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_line(aes(y = success_rate * max(success_count), group = 1), color = \"red\", size = 1) +\n  geom_point(aes(y = success_rate * max(success_count)), color = \"black\", size = 2) +\n  scale_y_continuous(\n    name = \"Success Count\",\n    sec.axis = sec_axis(~ . / max(genre_success_rate_since_2010$success_count), name = \"Success Rate\", labels = percent_format(accuracy = 1))\n  ) +\n  labs(\n    title = \"Success Count and Success Rate by Genre Since 2010\",\n    x = \"Genre\"\n  ) +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n4) What genre has become more popular in recent years?\nAnswer: The News genre has become x10 times more popular in recent years, exhibiting the highest growth rate among all genres according to the provided data.\n\n\nQuestion 4 - Code\ngenre_decade_totals_all &lt;- movies_data |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n\n# Total movies per genre from previous decade\ngenre_growth &lt;- genre_decade_totals_all |&gt;\n  arrange(genres, decade) |&gt;\n  group_by(genres) |&gt;\n  mutate(previous_total = lag(total_count),\n         growth = (total_count - previous_total) / previous_total) |&gt;\n  ungroup()\n\n# Recent decades from 1990 onwards\nrecent_genre_growth &lt;- genre_growth |&gt;\n  filter(decade &gt;= 1990 & !is.na(growth))\n\ntop_growing_genres &lt;- recent_genre_growth |&gt;\n  arrange(desc(growth)) |&gt;\n  head(10)\n\nprint(top_growing_genres)\n\n\n\n\nTask 5. Key Personnel\nLet’s prapare the data to get at least 2 best actors and 1 director.\n\n\nTask 5 - Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\n# Merge TITLE_BASICS, TITLE_RATINGS, and TITLE_PRINCIPALS\nmovies_data &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"tconst\") |&gt;\n  filter(category %in% c(\"actor\", \"actress\", \"director\"))\n\nmovies_data &lt;- movies_data |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 2010 & titleType == \"movie\")\n\n# Join with NAME_BASICS to get actor and director names\nmovies_data &lt;- movies_data |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  select(nconst, primaryName, category, tconst, primaryTitle, startYear, genres, weighted_popularity_score)\n\n#FOR ACTORS/ACTRESSES ONLY\n# Calculate average success metric for actors and actresses\nactor_success &lt;- movies_data |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 3)  # Consider actors with at least 3 movies\n#DIRECTORS ONLY\n# Filter for directors\ndirector_data &lt;- TITLE_CREW |&gt;\n  separate_rows(directors, sep = \",\") |&gt;\n  rename(nconst = directors) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 2010 & titleType == \"movie\") |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  select(nconst, primaryName, tconst, primaryTitle, startYear, genres, weighted_popularity_score)\n\n\nWe will concentrate on two genres Action and War to get our top actors and directors.\n\n\nTask 5 - Code\n# Calculate average success metric for directors\ndirector_success &lt;- director_data |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 2)  # Consider directors with at least 2 movies\n\n#TOP ACTORS\npreferred_genres &lt;- c(\"Action\", \"War\")\n\n# Filter movies in preferred genres\nactors_in_genres &lt;- movies_data |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  filter(genres %in% preferred_genres)\n\n# Average success for actors in preferred genres\nactor_success_genre &lt;- actors_in_genres |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 2)  # At least 2 movies in preferred genres\n\n# Top 5 actors\ntop_actors &lt;- actor_success_genre |&gt;\n  arrange(desc(average_success)) |&gt;\n  head(5)\n\nprint(top_actors)\n\n#TOP DIRECTOR \n# Filter director movies in preferred genres\ndirectors_in_genres &lt;- director_data |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  filter(genres %in% preferred_genres)\n\n# Average success for directors in preferred genres\ndirector_success_genre &lt;- directors_in_genres |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 1)  # At least 1 movie in preferred genres\n\ntop_directors &lt;- director_success_genre |&gt;\n  arrange(desc(average_success)) |&gt;\n  head(3)\nprint(top_directors)\n\n\nAnswer:\n\nTop Actors\n\n\nPrimary Name\nAverage Success\nTotal Movies\n\n\n\n\nLeonardo DiCaprio\n120\n2\n\n\nTimothée Chalamet\n111\n2\n\n\nDon Cheadle\n108\n10\n\n\nRobert Downey Jr.\n107\n15\n\n\nMark Ruffalo\n107\n12\n\n\n\nAnswer:\n\nTop Directors\n\n\nPrimary Name\nAverage Success\nTotal Movies\n\n\n\n\nChristopher Nolan\n114\n4\n\n\nRodney Rothman\n113\n1\n\n\nBob Persichetti\n113\n1\n\n\n\n\n\nBar plot\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Get top 5 actors and top 3 directors\ntop_actors &lt;- actor_success_genre %&gt;%\n  arrange(desc(average_success)) %&gt;%\n  head(5)\n\ntop_directors &lt;- director_success_genre %&gt;%\n  arrange(desc(average_success)) %&gt;%\n  head(3)\n\nplot_data &lt;- bind_rows(\n  top_actors %&gt;% mutate(Talent = \"Actor\"),\n  top_directors %&gt;% mutate(Talent = \"Director\")\n)\n\n# Highlight selected talents\nselected_names &lt;- c(\"Leonardo DiCaprio\", \"Robert Downey Jr.\", \"Christopher Nolan\")\nplot_data &lt;- plot_data %&gt;%\n  mutate(Selected = ifelse(primaryName %in% selected_names, \"Selected\", \"Others\"))\n\n# Create the bar chart\nggplot(plot_data, aes(x = reorder(primaryName, average_success), y = average_success, fill = Selected)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Average Success Scores of Top Actors and Directors\",\n    x = \"Talent\",\n    y = \"Average Success Score\"\n  ) +\n  scale_fill_manual(values = c(\"Selected\" = \"blue\", \"Others\" = \"grey\")) +\n  theme_minimal()\n\n\n\n\nTask 6: Finding a Classic Movie to Remake\nLawrence of Arabia is an epic classic that presents a profound and captivating narrative, making it an ideal candidate for a modern remake. IMDb rating of 8.3 and a substantial number of ratings, reflecting its enduring popularity. There has been no remake of this classic action and war film in the past 25 years. Since the original actors and director are deceased, we can proceed with a new cast featuring Leonardo DiCaprio and Robert Downey Jr., directed by Christopher Nolan. To move forward, we need to clarify and secure the legal rights from Columbia Pictures, the current rights holder.\n\n\nTask 7: Write and Deliver Your Pitch\nElevator Pitch:\nWe propose a groundbreaking remake of the epic classic “Lawrence of Arabia”, a film that holds an impressive IMDb rating of 8.3 with over 275,000 votes, yet has not been remade in over 25 years. This presents a unique opportunity to reintroduce this timeless story to a new generation. Our project perfectly aligns with the high-performing action and war genres, which boast success rates exceeding 20% since 2010.\nChristopher Nolan, renowned for his visionary storytelling in films like “Inception” and “Dunkirk”, will direct this ambitious remake. Leading the cast, Leonardo DiCaprio will embody the complex character of T.E. Lawrence, bringing depth and nuance to the role. Alongside him, Robert Downey Jr. will add his charisma and talent to a pivotal supporting role, enhancing the film’s appeal.\nWith this exceptional team, we aim to create a cinematic masterpiece that honors the original while captivating modern audiences. Securing the rights from Columbia Pictures will allow us to proceed, and with your approval, we can begin this exciting journey.\n\nClassic 90’s Style Teaser:\n\nFrom director Christopher Nolan, the visionary mind behind “Inception” and “Dunkirk”;\nAnd from actor Leonardo DiCaprio, beloved star of “The Revenant”;\nAnd from actor Robert Downey Jr., Hollywood icon of action and war films;\nComes the timeless tale “Lawrence of Arabia”.\nA story of courage, identity, and destiny.\nComing soon to a theater near you."
  }
]