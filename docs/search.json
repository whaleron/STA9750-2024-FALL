[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "",
    "text": "This project is inspired from CityNerd Youtube channel and focuses on farebox recovery - the percentage of a transit system’s revenue that comes from fares instead of taxes. The data for this analysis comes from the National Transit Database(NTD). This mini-project analyzes farebox revenues, total trips, vehicle miles traveled and operating expenses for public transit systems in the U.S. in 2022.\nKey data sources:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Valeriia Frolova",
    "section": "",
    "text": "Short Bio\nFor more than 7 years, I’ve been optimizing websites and elevating brands through targeted SEO strategies. To complement my experience with advanced analytical skills, I’m pursuing an MSBA at Baruch College, driven by a passion for data-driven decisions.\n\nYou can view some of my ML projects.\nConnect with me on: X & Linkedin."
  },
  {
    "objectID": "mp01.html#step-1.-data-downloading-cleaning",
    "href": "mp01.html#step-1.-data-downloading-cleaning",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 1. Data Downloading & Cleaning",
    "text": "Step 1. Data Downloading & Cleaning\nThe first step is to install the tidyverse package, as it provides useful data manipulation tools such as:\n\ndplyr for data manipulation functions (e.g.mutate(), select(), group_by())\nggplot2 for data visualization (e.g. bar charts, line charts, scatter plots)\nreadr for reading and writing data (e.g.read_csv(), write_csv())\n\n\na) Fare Revenue Data\n\nThis dataset contains information on the total fare revenues for transit agencies. All files in downloading steps are taken directly from the official website. After the FARES data is cleaned, only important columns are selected and data is filtered by the rows where Expense Type is Funds Earned During Period.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# Let's start with Fare Revenue\nlibrary(tidyverse)\nif(!file.exists(\"2022_fare_revenue.xlsx\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_fare_revenue.xlsx\" in your project\n    # directory.\n    download.file(\"http://www.transit.dot.gov/sites/fta.dot.gov/files/2024-04/2022%20Fare%20Revenue.xlsx\", \n                  destfile=\"2022_fare_revenue.xlsx\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n    select(-`State/Parent NTD ID`, \n           -`Reporter Type`,\n           -`Reporting Module`,\n           -`TOS`,\n           -`Passenger Paid Fares`,\n           -`Organization Paid Fares`) |&gt;\n    filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n    select(-`Expense Type`) |&gt;\n    group_by(`NTD ID`,       # Sum over different `TOS` for the same `Mode`\n             `Agency Name`,  # These are direct operated and sub-contracted \n             `Mode`) |&gt;      # of the same transit modality\n                             # Not a big effect in most munis (significant DO\n                             # tends to get rid of sub-contractors), but we'll sum\n                             # to unify different passenger experiences\n    summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n    ungroup()\n\n\n\nb) Expenses Data\n\nThis step involves getting the 2022 operating expenses data. The expenses are grouped by NTD ID, Agency, Total and Mode to calculate total operating costs for each agency and transportation mode.\n\n\nif(!file.exists(\"2022_expenses.csv\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_expenses.csv\" in your project\n    # directory.\n    download.file(\"https://data.transportation.gov/api/views/dkxx-zjd6/rows.csv?date=20231102&accessType=DOWNLOAD&bom=true&format=true\", \n                  destfile=\"2022_expenses.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n    select(`NTD ID`, \n           `Agency`,\n           `Total`, \n           `Mode`) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n    rename(Expenses = Total) |&gt;\n    group_by(`NTD ID`, `Mode`) |&gt;\n    summarize(Expenses = sum(Expenses)) |&gt;\n    ungroup()\n\n\n\nc) Merging Financial Data\nFINANCIALS = FARES + EXPENSES\nTo combine the fare revenue and expenses by NTD ID and Mode – the inner_join() function is used.\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n\n\nd) Ridership Data\nIn this part, the monthly ridership data is downloaded and necessary columns are kept, especially we are interested in this data:\n\nUPT - Unlinked Passenger Trips\nVRM - Vehicle Revenue Miles\n\n\nif(!file.exists(\"ridership.xlsx\")){\n  # This should work _in theory_ but in practice it's still a bit finicky\n  # If it doesn't work for you, download this file 'by hand' in your\n  # browser and save it as \"ridership.xlsx\" in your project\n  # directory.\n  download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-09/July%202024%20Complete%20Monthly%20Ridership%20%28with%20adjustments%20and%20estimates%29_240903.xlsx\", \n                destfile=\"ridership.xlsx\", \n                quiet=FALSE, \n                method=\"wget\")\n}\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  rename(metro_area = `UZA Name`) |&gt; #task1\n  pivot_longer(-c(`NTD ID`:`3 Mode`, metro_area), \n               names_to=\"month\", \n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`), \n               names_to=\"month\", \n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  rename(metro_area =`UZA Name`) |&gt; #task1\n  group_by(`NTD ID`, `Agency`, metro_area, \n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\n\n\ne) Merging Ridership Data\nThe inner_join() function is used again for TRIPS and MILES to get them together into USAGE dataset.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\n\n\nf) Glimpse on the Main Dataset and Improving Mode column\n\nsample_n(USAGE, 1000) selects a random sample of 1000 records from the USAGE dataset;\nmutate helps to convert the month column to a character format, ensuring it’s one format for further analysis;\nDT::datatable() gives a web-like interactive table for a sampled dataset for filtering, sorting etc., ensure that DT library is installed, if not use install.packages(\"DT\") function from the previous step;\n\n\nsample_n(USAGE, 1000) |&gt; \n  mutate(month=as.character(month)) |&gt; \n  DT::datatable()\n\n\n\n\n\nNext, the mutate function is used to recode Mode column for better clarity for transportation systems. And, case_when() function replace abbreviations\nAR -&gt; Alaska Railroad etc. The distinct function checks correct transformation for unique modes.\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n))\ndistinct(USAGE, Mode)\n\n# A tibble: 18 × 1\n   Mode                       \n   &lt;chr&gt;                      \n 1 Demand Response            \n 2 Ferryboat                  \n 3 Bus                        \n 4 Streercar Rail             \n 5 Trolleybus                 \n 6 Vanpool                    \n 7 Commuter Bus               \n 8 Bus Rapid Transit          \n 9 Light Rail                 \n10 Hybrid Rail                \n11 Monorail/Automated Guideway\n12 Commuter Rail              \n13 Alaska Railroad            \n14 Aerial Tramway             \n15 Heavy Rail                 \n16 Inclined Plane             \n17 Publico                    \n18 Cable Car"
  },
  {
    "objectID": "mp01.html#step-2.-data-analysis",
    "href": "mp01.html#step-2.-data-analysis",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 2. Data Analysis",
    "text": "Step 2. Data Analysis\nQuestion 1. What transit agency had the most total VRM in our data set?\nTo get this answer, the total vehicle miles traveled by agency are aggregated (ensure to remove empty rows, and get only one agency with the highest VRM):\n\nmost_vrm_agency &lt;- USAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_agency\n\n# A tibble: 1 × 2\n  Agency                      total_VRM\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 MTA New York City Transit 10832855350\n\n\nQuestion 2. What transit mode had the most total VRM in our data set?\nThis question is pretty simple. We need to update the code above to a ‘Mode’ instead of ‘Agency’\n\nmost_vrm_mode &lt;- USAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_mode\n\n# A tibble: 1 × 2\n  Mode    total_VRM\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Bus   49444494088\n\n\nQuestion 3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThe code below calculates MTA NYC Transit trips taken by Heavy Rail mode for the month of May 2024. The summarize() function is used to create a new variable total_trips, sum sums the values in the UPT column and na.rm ignores missing values.\n\nnyc_subway_may2024 &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", Mode == \"Heavy Rail\", month == \"2024-05-01\") |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE))\nnyc_subway_may2024\n\n# A tibble: 1 × 1\n  total_trips\n        &lt;dbl&gt;\n1   180458819\n\n\nQuestion 4. How much did NYC subway ridership fall between April 2019 and April 2020? The code filters only “MTA New York City Transit” for the dates mentioned, then sums the UPT for each month. After that, the percentage drop in ridership is calculated to reflect the impact of the COVID-19 on public transportation usage during the pandemic.\n\nnyc_subway_april_ridership &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", \n         Mode == \"Heavy Rail\", \n         month %in% c(\"2019-04-01\", \"2020-04-01\")) |&gt;\n  group_by(month) |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE)) #ridership fall\n\nridership_fall &lt;- nyc_subway_april_ridership |&gt; # % fall \n  summarize(fall = 100* (total_trips[month == \"2020-04-01\"] - total_trips[month == \"2019-04-01\"]) / total_trips[month == \"2019-04-01\"])\nridership_fall\n\n# A tibble: 1 × 1\n   fall\n  &lt;dbl&gt;\n1 -91.3"
  },
  {
    "objectID": "mp01.html#more-interesting-transit-facts",
    "href": "mp01.html#more-interesting-transit-facts",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "More interesting transit facts",
    "text": "More interesting transit facts\n1. Which transit agency had the most trips in a single month?\nLet’s find out the transit agency with the most trips in a single month by grouping the data by agency and month, summing the total trips, sorting in descending order and getting the top result.\n\nmost_trip_single_month &lt;- USAGE |&gt;\n  group_by(Agency, month) |&gt;\n  summarize(total_trips = sum(UPT,na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(total_trips)) |&gt;\n  slice(1)\nmost_trip_single_month\n\n# A tibble: 1 × 3\n  Agency                    month      total_trips\n  &lt;chr&gt;                     &lt;date&gt;           &lt;dbl&gt;\n1 MTA New York City Transit 2014-10-01   322725962\n\n\n2. Which mode of transit had the highest trip length in 2024?\nThis code filters 2024 by using grepl function for month column. Then, groups Mode and calculates the average trip length by diving totals of VRM and UPT.\n\nlongest_avg_trip_2024 &lt;-USAGE |&gt;\n  filter(grepl(\"2024\", month)) |&gt;\n  group_by(Mode) |&gt;\n  summarize(avg_trip_length = sum(VRM, na.rm = TRUE) / sum(UPT, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_trip_length)) |&gt;\n  slice(1)\nlongest_avg_trip_2024\n\n# A tibble: 1 × 2\n  Mode            avg_trip_length\n  &lt;chr&gt;                     &lt;dbl&gt;\n1 Demand Response            12.8\n\n\n3. Which transit agency had the largest vehicle fleet(VRM) in 2024? This code provides the agency with the most distance(VRM) with its fleet in 2024.\n\nlargest_fleet_2024 &lt;- USAGE |&gt;\n  filter(grepl(\"2024\", month)) |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1)\nlargest_fleet_2024\n\n# A tibble: 1 × 2\n  Agency                    total_VRM\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 MTA New York City Transit 273222702"
  },
  {
    "objectID": "mp01.html#step-3.-table-summarization",
    "href": "mp01.html#step-3.-table-summarization",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 3. Table Summarization",
    "text": "Step 3. Table Summarization\n\n#Task 5 table summarization\nlibrary(dplyr)\nlibrary(lubridate) #year function\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  filter(year(month) == 2022) |&gt;\n  group_by(`NTD ID`, Agency, metro_area, Mode) |&gt;\n  summarize(\n    UPT = sum(UPT, na.rm = TRUE),\n    VRM = sum(VRM, na.rm = TRUE),\n    .groups = \"drop\"\n  )\nUSAGE_2022_ANNUAL\n\n# A tibble: 1,141 × 6\n   `NTD ID` Agency                                metro_area Mode     UPT    VRM\n      &lt;int&gt; &lt;chr&gt;                                 &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1        1 King County                           Seattle--… Bus   5.40e7 6.16e7\n 2        1 King County                           Seattle--… Dema… 6.63e5 1.29e7\n 3        1 King County                           Seattle--… Ferr… 4.00e5 5.12e4\n 4        1 King County                           Seattle--… Stre… 1.12e6 1.80e5\n 5        1 King County                           Seattle--… Trol… 9.58e6 2.64e6\n 6        1 King County                           Seattle--… Vanp… 7.03e5 4.41e6\n 7        2 Spokane Transit Authority             Spokane, … Bus   6.60e6 6.49e6\n 8        2 Spokane Transit Authority             Spokane, … Dema… 3.10e5 4.04e6\n 9        2 Spokane Transit Authority             Spokane, … Vanp… 9.06e4 9.06e5\n10        3 Pierce County Transportation Benefit… Seattle--… Bus   4.95e6 4.23e6\n# ℹ 1,131 more rows\n\nFINANCIALS_mode_updated &lt;- FINANCIALS %&gt;%\n  mutate(Mode =case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n  ))\nFINANCIALS_mode_updated\n\n# A tibble: 1,173 × 5\n   `NTD ID` `Agency Name`                           Mode  `Total Fares` Expenses\n      &lt;dbl&gt; &lt;chr&gt;                                   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1        1 King County Department of Metro Transit Comm…       5216912   0     \n 2        1 King County Department of Metro Transit Dema…        832327   6.05e7\n 3        1 King County Department of Metro Transit Ferr…       1715265   8.90e6\n 4        1 King County Department of Metro Transit Ligh…      29386480   0     \n 5        1 King County Department of Metro Transit Bus        56846337   6.72e8\n 6        1 King County Department of Metro Transit Stre…        588495   1.25e7\n 7        1 King County Department of Metro Transit Trol…      10123486   8.42e7\n 8        1 King County Department of Metro Transit Vanp…       5484481   8.91e6\n 9        2 Spokane Transit Authority               Dema…        531284   1.80e7\n10        2 Spokane Transit Authority               Bus         6135110   7.53e7\n# ℹ 1,163 more rows\n\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n                                  FINANCIALS_mode_updated, \n                                  join_by(`NTD ID`, Mode)) |&gt;\n  drop_na()"
  },
  {
    "objectID": "mp01.html#step-4.-farebox-recovery-among-major-systems",
    "href": "mp01.html#step-4.-farebox-recovery-among-major-systems",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Step 4. Farebox Recovery Among Major Systems",
    "text": "Step 4. Farebox Recovery Among Major Systems\n\nWhich transit system (agency and mode) had the most UPT in 2022?\n\n\nmost_upt_2022 &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  arrange(desc(UPT)) |&gt;\n  slice(1)\nmost_upt_2022\n\n# A tibble: 1 × 9\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20008 MTA New Y… New York-… Heav… 1.79e9 3.38e8 MTA New York…    2326782567\n# ℹ 1 more variable: Expenses &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\n\n\nhighest_farebox_recovery &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(farebox_recovery = `Total Fares` / Expenses) |&gt;\n  arrange(desc(farebox_recovery)) |&gt;\n  slice(1)\nhighest_farebox_recovery\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20190 Port Impe… New York-… Ferr… 3.76e6 504037 Port Imperia…      33443241\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, farebox_recovery &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the lowest expenses per UPT?\n\n\nlower_expenses_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_upt = Expenses / UPT) |&gt;\n  arrange(expenses_per_upt) |&gt;\n  slice(1)\nlower_expenses_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40147 North Car… Raleigh, … Bus   2.31e6 531555 North Caroli…             0\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_upt &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the highest total fares per UPT?\n\n\nhighest_fares_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_upt = `Total Fares` / UPT) |&gt;\n  arrange(desc(fares_per_upt)) |&gt;\n  slice(1)\nhighest_fares_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20217 Hampton J… New York-… Comm… 521577 2.04e6 Hampton Jitn…      21539188\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_upt &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the lowest expenses per VRM?\n\n\nlowest_expenses_per_vrm &lt;-USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_vrm = Expenses / VRM) |&gt;\n  arrange(expenses_per_vrm) |&gt;\n  slice(1)\nlowest_expenses_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    90094 Metropoli… San Franc… Vanp… 1.02e6 1.23e7 Metropolitan…       6504406\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_vrm &lt;dbl&gt;\n\n\n\nWhich transit system (agency and mode) has the highest total fares per VRM?\n\n\nhighest_fares_per_vrm &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_vrm = `Total Fares` / VRM) |&gt;\n  arrange(desc(fares_per_vrm)) |&gt;\n  slice(1)\nhighest_fares_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency      metro_area Mode     UPT   VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40040 Jacksonvil… Jacksonvi… Ferr… 416129  9084 Jacksonville…       1432549\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_vrm &lt;dbl&gt;"
  },
  {
    "objectID": "mp01.html#part-1.-data-downloading-cleaning",
    "href": "mp01.html#part-1.-data-downloading-cleaning",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 1. Data Downloading & Cleaning",
    "text": "Part 1. Data Downloading & Cleaning\nThe first step is to install the tidyverse package, as it provides useful data manipulation tools such as:\n\ndplyr for data manipulation functions (e.g.mutate(), select(), group_by())\nggplot2 for data visualization (e.g. bar charts, line charts, scatter plots)\nreadr for reading and writing data (e.g.read_csv(), write_csv())\n\n\na) Fare Revenue Data\n\nThis dataset contains information on the total fare revenues for transit agencies. All files in downloading steps are taken directly from the official website. After the FARES data is cleaned, only important columns are selected and data is filtered by the rows where Expense Type is Funds Earned During Period.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n# Let's start with Fare Revenue\nlibrary(tidyverse)\nif(!file.exists(\"2022_fare_revenue.xlsx\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_fare_revenue.xlsx\" in your project\n    # directory.\n    download.file(\"http://www.transit.dot.gov/sites/fta.dot.gov/files/2024-04/2022%20Fare%20Revenue.xlsx\", \n                  destfile=\"2022_fare_revenue.xlsx\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n    select(-`State/Parent NTD ID`, \n           -`Reporter Type`,\n           -`Reporting Module`,\n           -`TOS`,\n           -`Passenger Paid Fares`,\n           -`Organization Paid Fares`) |&gt;\n    filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n    select(-`Expense Type`) |&gt;\n    group_by(`NTD ID`,       # Sum over different `TOS` for the same `Mode`\n             `Agency Name`,  # These are direct operated and sub-contracted \n             `Mode`) |&gt;      # of the same transit modality\n                             # Not a big effect in most munis (significant DO\n                             # tends to get rid of sub-contractors), but we'll sum\n                             # to unify different passenger experiences\n    summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n    ungroup()\n\n\n\nb) Expenses Data\n\nThis step involves getting the 2022 operating expenses data. The expenses are grouped by NTD ID, Agency, Total and Mode to calculate total operating costs for each agency and transportation mode.\n\n\nif(!file.exists(\"2022_expenses.csv\")){\n    # This should work _in theory_ but in practice it's still a bit finicky\n    # If it doesn't work for you, download this file 'by hand' in your\n    # browser and save it as \"2022_expenses.csv\" in your project\n    # directory.\n    download.file(\"https://data.transportation.gov/api/views/dkxx-zjd6/rows.csv?date=20231102&accessType=DOWNLOAD&bom=true&format=true\", \n                  destfile=\"2022_expenses.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")\n}\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n    select(`NTD ID`, \n           `Agency`,\n           `Total`, \n           `Mode`) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n    rename(Expenses = Total) |&gt;\n    group_by(`NTD ID`, `Mode`) |&gt;\n    summarize(Expenses = sum(Expenses)) |&gt;\n    ungroup()\n\n\n\nc) Merging Financial Data\nFINANCIALS = FARES + EXPENSES\nTo combine the fare revenue and expenses by NTD ID and Mode – the inner_join() function is used.\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n\n\nd) Ridership Data\nIn this part, the monthly ridership data is downloaded and necessary columns are kept, especially we are interested in this data:\n\nUPT - Unlinked Passenger Trips\nVRM - Vehicle Revenue Miles\n\n\nif(!file.exists(\"ridership.xlsx\")){\n  # This should work _in theory_ but in practice it's still a bit finicky\n  # If it doesn't work for you, download this file 'by hand' in your\n  # browser and save it as \"ridership.xlsx\" in your project\n  # directory.\n  download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-09/July%202024%20Complete%20Monthly%20Ridership%20%28with%20adjustments%20and%20estimates%29_240903.xlsx\", \n                destfile=\"ridership.xlsx\", \n                quiet=FALSE, \n                method=\"wget\")\n}\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  rename(metro_area = `UZA Name`) |&gt; #task1\n  pivot_longer(-c(`NTD ID`:`3 Mode`, metro_area), \n               names_to=\"month\", \n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`, \n         -`Reporter Type`, \n         -`Mode/Type of Service Status`, \n         -`UACE CD`, \n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`), \n               names_to=\"month\", \n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  rename(metro_area =`UZA Name`) |&gt; #task1\n  group_by(`NTD ID`, `Agency`, metro_area, \n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\n\n\ne) Merging Ridership Data\nThe inner_join() function is used again for TRIPS and MILES to get them together into USAGE dataset.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\n\n\nf) Glimpse of the Main Dataset and Improving Mode column\n\nsample_n(USAGE, 1000) selects a random sample of 1000 records from the USAGE dataset;\nmutate helps to convert the month column to a character format, ensuring it’s one format for further analysis;\nDT::datatable() gives a web-like interactive table for a sampled dataset for filtering, sorting etc., ensure that DT library is installed, if not use install.packages(\"DT\") function from the previous step;\n\n\nsample_n(USAGE, 1000) |&gt; \n  mutate(month=as.character(month)) |&gt; \n  DT::datatable()\n\n\n\n\n\nNext, the mutate function is used to recode Mode column for better clarity for transportation systems. And, case_when() function replace abbreviations\nAR -&gt; Alaska Railroad etc. The distinct function checks correct transformation for unique modes.\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode=case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n))\ndistinct(USAGE, Mode)\n\n# A tibble: 18 × 1\n   Mode                       \n   &lt;chr&gt;                      \n 1 Demand Response            \n 2 Ferryboat                  \n 3 Bus                        \n 4 Streercar Rail             \n 5 Trolleybus                 \n 6 Vanpool                    \n 7 Commuter Bus               \n 8 Bus Rapid Transit          \n 9 Light Rail                 \n10 Hybrid Rail                \n11 Monorail/Automated Guideway\n12 Commuter Rail              \n13 Alaska Railroad            \n14 Aerial Tramway             \n15 Heavy Rail                 \n16 Inclined Plane             \n17 Publico                    \n18 Cable Car"
  },
  {
    "objectID": "mp01.html#part-2.-data-analysis",
    "href": "mp01.html#part-2.-data-analysis",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 2. Data Analysis",
    "text": "Part 2. Data Analysis\n\nQuestion 1. What transit agency had the most total VRM in our data set?\nTo get this answer, the total vehicle miles traveled by agency are aggregated (ensure to remove empty rows, and get only one agency with the highest VRM):\n\nmost_vrm_agency &lt;- USAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_agency\n\n# A tibble: 1 × 2\n  Agency                      total_VRM\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 MTA New York City Transit 10832855350\n\n\n\n\nQuestion 2. What transit mode had the most total VRM in our data set?\nThis question is pretty simple. We need to update the code above to a ‘Mode’ instead of ‘Agency’\n\nmost_vrm_mode &lt;- USAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1) #top result\nmost_vrm_mode\n\n# A tibble: 1 × 2\n  Mode    total_VRM\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Bus   49444494088\n\n\n\n\nQuestion 3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThe code below calculates MTA NYC Transit trips taken by Heavy Rail mode for the month of May 2024. The summarize() function is used to create a new variable total_trips, sum sums the values in the UPT column and na.rm ignores missing values.\n\nnyc_subway_may2024 &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", Mode == \"Heavy Rail\", month == \"2024-05-01\") |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE))\nnyc_subway_may2024\n\n# A tibble: 1 × 1\n  total_trips\n        &lt;dbl&gt;\n1   180458819\n\n\n\n\nQuestion 4. How much did NYC subway ridership fall between April 2019 and April 2020?\nThe code filters only “MTA New York City Transit” for the dates mentioned, then sums the UPT for each month. After that, the percentage drop in ridership is calculated to reflect the impact of the COVID-19 on public transportation usage during the pandemic.\n\nnyc_subway_april_ridership &lt;- USAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\", \n         Mode == \"Heavy Rail\", \n         month %in% c(\"2019-04-01\", \"2020-04-01\")) |&gt;\n  group_by(month) |&gt;\n  summarize(total_trips = sum(UPT, na.rm = TRUE)) #ridership fall\n\nridership_fall &lt;- nyc_subway_april_ridership |&gt; # % fall \n  summarize(fall = 100* (total_trips[month == \"2020-04-01\"] - total_trips[month == \"2019-04-01\"]) / total_trips[month == \"2019-04-01\"])\nridership_fall\n\n# A tibble: 1 × 1\n   fall\n  &lt;dbl&gt;\n1 -91.3"
  },
  {
    "objectID": "mp01.html#part-3.-table-summarization",
    "href": "mp01.html#part-3.-table-summarization",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 3. Table Summarization",
    "text": "Part 3. Table Summarization\nThis code is responsible for creating an annual summary of public transit usage and financial data for 2022 - USAGE_2022_ANNUAL, steps\n1) Filtering and summarizing transit data for 2022.\n2) Updating Financial data mode labels.\n3) Join the USAGE_AND_FINANCIALS and making sure that modes aren’t abbreviated.\n\n#Task 5 table summarization\nlibrary(dplyr)\nlibrary(lubridate) #year function\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  filter(year(month) == 2022) |&gt;\n  group_by(`NTD ID`, Agency, metro_area, Mode) |&gt;\n  summarize(\n    UPT = sum(UPT, na.rm = TRUE),\n    VRM = sum(VRM, na.rm = TRUE),\n    .groups = \"drop\"\n  )\nUSAGE_2022_ANNUAL\n\n# A tibble: 1,141 × 6\n   `NTD ID` Agency                                metro_area Mode     UPT    VRM\n      &lt;int&gt; &lt;chr&gt;                                 &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1        1 King County                           Seattle--… Bus   5.40e7 6.16e7\n 2        1 King County                           Seattle--… Dema… 6.63e5 1.29e7\n 3        1 King County                           Seattle--… Ferr… 4.00e5 5.12e4\n 4        1 King County                           Seattle--… Stre… 1.12e6 1.80e5\n 5        1 King County                           Seattle--… Trol… 9.58e6 2.64e6\n 6        1 King County                           Seattle--… Vanp… 7.03e5 4.41e6\n 7        2 Spokane Transit Authority             Spokane, … Bus   6.60e6 6.49e6\n 8        2 Spokane Transit Authority             Spokane, … Dema… 3.10e5 4.04e6\n 9        2 Spokane Transit Authority             Spokane, … Vanp… 9.06e4 9.06e5\n10        3 Pierce County Transportation Benefit… Seattle--… Bus   4.95e6 4.23e6\n# ℹ 1,131 more rows\n\nFINANCIALS_mode_updated &lt;- FINANCIALS %&gt;%\n  mutate(Mode =case_when(\n    Mode == \"AR\" ~ \"Alaska Railroad\", \n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"SR\" ~ \"Streercar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    TRUE ~ \"Unknown\"\n  ))\nFINANCIALS_mode_updated\n\n# A tibble: 1,173 × 5\n   `NTD ID` `Agency Name`                           Mode  `Total Fares` Expenses\n      &lt;dbl&gt; &lt;chr&gt;                                   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1        1 King County Department of Metro Transit Comm…       5216912   0     \n 2        1 King County Department of Metro Transit Dema…        832327   6.05e7\n 3        1 King County Department of Metro Transit Ferr…       1715265   8.90e6\n 4        1 King County Department of Metro Transit Ligh…      29386480   0     \n 5        1 King County Department of Metro Transit Bus        56846337   6.72e8\n 6        1 King County Department of Metro Transit Stre…        588495   1.25e7\n 7        1 King County Department of Metro Transit Trol…      10123486   8.42e7\n 8        1 King County Department of Metro Transit Vanp…       5484481   8.91e6\n 9        2 Spokane Transit Authority               Dema…        531284   1.80e7\n10        2 Spokane Transit Authority               Bus         6135110   7.53e7\n# ℹ 1,163 more rows\n\nUSAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n                                  FINANCIALS_mode_updated, \n                                  join_by(`NTD ID`, Mode)) |&gt;\n  drop_na()"
  },
  {
    "objectID": "mp01.html#part-4.-farebox-recovery-among-major-systems",
    "href": "mp01.html#part-4.-farebox-recovery-among-major-systems",
    "title": "Mini-Project#01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Part 4. Farebox Recovery Among Major Systems",
    "text": "Part 4. Farebox Recovery Among Major Systems\n\n1. Which transit system (agency and mode) had the most UPT in 2022?\nThe metric of Unlinked Passengers Trips or UPT provides insight into how many time passengers boarded a transit vehicle. The high UPT equals to more frequent trips. To filter the busiest system, we set 400,000 UPT at least in 2022 and sorted by the highest total.\n\nmost_upt_2022 &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  arrange(desc(UPT)) |&gt;\n  slice(1)\nmost_upt_2022\n\n# A tibble: 1 × 9\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20008 MTA New Y… New York-… Heav… 1.79e9 3.38e8 MTA New York…    2326782567\n# ℹ 1 more variable: Expenses &lt;dbl&gt;\n\n\nResult: It’s no surprise that MTA New York City Transit - Heavy Rail leads with 1.79 billion UPT. The immense number of people rely on it every day, both New Yorkers and tourists.\n\n\n2. Which transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\nThe farebox recovery ratio measures the percentage of operating expenses covered by fare revenue. In this research we will take only a glimpse how financially self-sustaining a transit system is.\n\nhighest_farebox_recovery &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(farebox_recovery = `Total Fares` / Expenses) |&gt;\n  arrange(desc(farebox_recovery)) |&gt;\n  slice(1)\nhighest_farebox_recovery\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20190 Port Impe… New York-… Ferr… 3.76e6 504037 Port Imperia…      33443241\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, farebox_recovery &lt;dbl&gt;\n\n\nResult: Port Imperial Ferry (New York-New Jersey area) is on the top of the chart with 66.3% farebox recovery ratio. This higher ratio means that it’s less reliant on subsidies from local or federal governments.\n\n\n3. Which transit system (agency and mode) has the lowest expenses per UPT?\nWith Expenses per UPT we measure how much it costs to transport a single pasenger for a trip. Lower expenses per trip indicate better services at reduced cost.\n\nlower_expenses_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_upt = Expenses / UPT) |&gt;\n  arrange(expenses_per_upt) |&gt;\n  slice(1)\nlower_expenses_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40147 North Car… Raleigh, … Bus   2.31e6 531555 North Caroli…             0\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_upt &lt;dbl&gt;\n\n\nResult: The North Carolina Department of Transportation’s Bus system in Raleigh leads this chart with the lowest expenses per trip.\n\n\n4. Which transit system (agency and mode) has the highest total fares per UPT?\nTotal fares per UPT provide an indicator how much revenue the system is generating from each passenger trip. Higher fares can be due to the distances or premium services.\n\nhighest_fares_per_upt &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_upt = `Total Fares` / UPT) |&gt;\n  arrange(desc(fares_per_upt)) |&gt;\n  slice(1)\nhighest_fares_per_upt\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    20217 Hampton J… New York-… Comm… 521577 2.04e6 Hampton Jitn…      21539188\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_upt &lt;dbl&gt;\n\n\nResult: Hampton Jitney(Commuter Bus) in the New York City are had the highest total $41.29 per UPT and is the combination of long-distance and premium services for people who want to spend the vacation in Hamptons.\n\n\n5. Which transit system (agency and mode) has the lowest expenses per VRM?\n\nlowest_expenses_per_vrm &lt;-USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(expenses_per_vrm = Expenses / VRM) |&gt;\n  arrange(expenses_per_vrm) |&gt;\n  slice(1)\nlowest_expenses_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency     metro_area Mode     UPT    VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    90094 Metropoli… San Franc… Vanp… 1.02e6 1.23e7 Metropolitan…       6504406\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, expenses_per_vrm &lt;dbl&gt;\n\n\n\n\n6. Which transit system (agency and mode) has the highest total fares per VRM?\nNow we are interested how much revenue is being generated for each mile traveled and the higher fare revenue is the more expensive/premium services are or efficient fare collection.\n\nhighest_fares_per_vrm &lt;- USAGE_AND_FINANCIALS |&gt;\n  filter(UPT &gt;= 400000) |&gt;\n  mutate(fares_per_vrm = `Total Fares` / VRM) |&gt;\n  arrange(desc(fares_per_vrm)) |&gt;\n  slice(1)\nhighest_fares_per_vrm\n\n# A tibble: 1 × 10\n  `NTD ID` Agency      metro_area Mode     UPT   VRM `Agency Name` `Total Fares`\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1    40040 Jacksonvil… Jacksonvi… Ferr… 416129  9084 Jacksonville…       1432549\n# ℹ 2 more variables: Expenses &lt;dbl&gt;, fares_per_vrm &lt;dbl&gt;\n\n\nResult: Jacksonville Transportation Authority’s Ferry service generates $157.71 per VTM. Meaning, ferry service in that location, has significantly higher fares compared to bus or rail, due to specific travel needs.\n\n\nThis mini-project provides valuable insights into the operational, financial efficiency and sustainability of various U.S. transit systems; and gives a great glimpse into the data how well certain transit agencies manage the cost efficiency and revenue generation from fares."
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "In this project, we will analyze the Hollywood history and get data-driven ideas for a “new movie” by defining best genres, actors, directors of a decade, all the time and assign special weighted score that will help us to identify the secret of a successful sauce to make the catchy and appealing movie for the nowadays audience. Let’s begin!\nThe key data source that will be used is the Internet Movie Database (IMDb) for non-commercial use.\nNote: All answers are provided from a large IMDb dataset that I run locally. However the code in this Quarto file uses compressed data from here. So some charts might be influenced and you can see differneces (e.g. you will notice that moving chart data for 2020 a bit corrupt)."
  },
  {
    "objectID": "mp02.html#before-we-start",
    "href": "mp02.html#before-we-start",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "Before we start",
<<<<<<< HEAD
    "text": "Before we start\n\n1) Import libraries\nThe first step before you start doing anything on your project is to make sure that you have all your packages installed. However, don’t be worried if you miss any, you can add them anywhere in the code, but for readability and clean code writing you should build that habit of importing everything when you start. While we are familiar already with the most of the packages I will add only two comments for new ones.\nNote: The code will be collapsed for better navigation.\n\n\nImport Libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(tidyr)\nlibrary(knitr) #improves readability of outputs\nlibrary(kableExtra) #addition to knitr, styling tables in R Markdown documents \n#install.packages(\"kableExtra\") #if it didn't import, do install command\n\n\n\n\n2) Import the dataset\nIt might take some time to download it and several times I caught myself on thought that R Studio was not working, but it was. Just give it a time, some of the datasets have more than 3M rows!\n\n\nImport IMDb Data\nget_imdb_file &lt;- function(filename) {\n  base_url &lt;- \"https://raw.githubusercontent.com/michaelweylandt/STA9750/main/miniprojects/mini02_preprocessed/\"\n  \n  file_url &lt;- paste0(base_url, filename, \".csv.zip\")\n  dest_file &lt;- paste0(\"data/\", filename, \".csv.zip\")\n  \n  if (!dir.exists(\"data\")) {\n    dir.create(\"data\")\n  }\n  \n  if (!file.exists(dest_file)) {\n    download.file(file_url, destfile = dest_file, mode = \"wb\")\n  }\n  data &lt;- readr::read_csv(dest_file)\n  return(data)\n}\n\nNAME_BASICS      &lt;- get_imdb_file(\"name_basics_small\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title_basics_small\")\nTITLE_EPISODES   &lt;- get_imdb_file(\"title_episodes_small\")\nTITLE_RATINGS    &lt;- get_imdb_file(\"title_ratings_small\")\nTITLE_CREW       &lt;- get_imdb_file(\"title_crew_small\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title_principals_small\")\n\n\nAfter this step we will start our EDA(explanatory data analysis)\n\n\n\nSource: geeksforgeeks.org\n\n\n\n\n3) Data Sub-Sampling\nWe will sample our data to smaller chunks for this analysis and will use “knownForTites” names assigned by IMDb and Titles that have more than 100 ratings as we don’t need anything lower for finding the best samples to follow for our movie idea. As well we will do a semi-join to return only the values that have a match and doesn’t add collumns.\n\n\nData Sub-Sampling\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\n\nData Sub-Sampling\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n\n     0%     25%     50%     75%    100% \n    100     165     332     970 2942823 \n\n\nData Sub-Sampling\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n#semi-join\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\n\n\n4) Data Cleaning\nIn this step, we will correct the column types of the TITLE tables using a combination of mutate and the coercion functions as.numeric and as.logical.\n\n\nNAME_BASICS Example\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\n\nBefore we will change all types it’s useful to check what is your data with glimpse function.\n\n\nGlimpse Example\n# glimpse(NAME_BASICS)\n# glimpse(TITLE_BASICS)\n# glimpse(TITLE_EPISODES)\n# glimpse(TITLE_RATINGS)\n# glimpse(TITLE_CREW)\n# glimpse(TITLE_PRINCIPALS)\n\n\nAnother good function is separate_longer_delim that helps to break view into multiple rows, here’s the example:\n\n\nSeparate_longer_delim function\n# NAME_BASICS |&gt; separate_longer_delim(knownForTitles, \",\") |&gt; slice_head(n=10)\n\n\nHere’s a small schema that shows all connections between the tables.\n\n\n\n\n\n\nTask 1. Correct all TITLE tables\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(startYear = as.numeric(startYear),\n           endYear = as.numeric(endYear),\n           isAdult = as.logical(as.numeric(isAdult))\n           )\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(seasonNumber = as.numeric(seasonNumber),\n           episodeNumbers = as.numeric(episodeNumber))\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(averageRating = as.numeric(averageRating),\n           numVotes = as.numeric(numVotes))\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate(directors = as.character(directors),\n           writers = as.character(writers))\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate(ordering = as.numeric(ordering),\n           category = as.character(category),\n           job = as.character(job),\n           characters =as.character(characters))\n\nAfter we wrangled and cleaned our dataset we can proceed to simple data manipulations and answer some questions!\n\n\n\nTask 2. Bunch of dataset questions\n\n\n1) How many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nQuestions\nAnswers\n\n\n\n\nHow many movies are in our data set?\n132091\n\n\nHow many TV series?\n29942\n\n\nHow many TV episodes?\n156442\n\n\n\n\n\nQuestion 1 Code\nTITLE_BASICS |&gt;\n  group_by(titleType) |&gt;\n  summarise(count = n())\n\n\n# A tibble: 10 × 2\n   titleType     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 movie        131662\n 2 short         16656\n 3 tvEpisode    155722\n 4 tvMiniSeries   5907\n 5 tvMovie       15007\n 6 tvSeries      29789\n 7 tvShort         410\n 8 tvSpecial      3045\n 9 video          9332\n10 videoGame      4668\n\n\n\n\n2) Who is the oldest living person in our data set?\nAnswer: Traudl Lessing was born in 1625.\n\n\nQuestion 2 Code\noldest_person &lt;- NAME_BASICS |&gt;\n  filter(is.na(deathYear)) |&gt;\n  filter(birthYear == min(birthYear, na.rm = TRUE)) |&gt;\n  select(primaryName,birthYear)\n\n\n\n\n3) There is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\nAnswer: Ozymandias\n\n\nQuestion 3 Code\nbest_episode &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10, numVotes &gt;= 200000) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, titleType)\n\n\n\n\n4) git count-objects -vHWhat four projects is the actor Mark Hamill most known for?\ngit Answer:\n1. Star Wars: Episode IV - A New Hope\n2. Star Wars: Episode VIII - The Last Jedi\n3. Star Wars: Episode V - The Empire Strikes Back\n4. Star Wars: Episode VI - Return of the Jedi\n\n\nQuestion 4 Code\nhamill_titles &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  separate_rows(knownForTitles, sep = \",\") |&gt;\n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  select (primaryTitle)\n\n\n\n\n5) What TV series, with more than 12 episodes, has the highest average rating?\nAnswer: Breaking Bad with the average rating 9.5.\n\n\nQuestion 5 Code\ntop_series &lt;- TITLE_EPISODES |&gt;\n  count(parentTconst) |&gt;\n  filter(n&gt;12) |&gt;\n  inner_join(TITLE_RATINGS, by = c(\"parentTconst\" = \"tconst\")) |&gt;\n  arrange(desc(averageRating)) |&gt;\n  top_n(1) |&gt;\n  inner_join(TITLE_BASICS, by = c(\"parentTconst\" =\"tconst\")) |&gt;\n  select(primaryTitle, averageRating)\n\n\n\n\n6) Is it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\nAnswer: It’s not true, all episodes from later seasons have 7.4 rating.\n\n\nQuestion 6 Code\nhappy_days &lt;- TITLE_BASICS |&gt;\n  filter(primaryTitle == \"Happy Days\") |&gt;\n  inner_join(TITLE_EPISODES, by = c(\"tconst\" = \"parentTconst\")) |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  group_by(seasonNumber) |&gt;\n  summarise(avg_rating = mean(averageRating, na.rm = TRUE)) |&gt;\n  arrange (seasonNumber)\n\n\n\n\nTask 3. Custom Success Metric\nSome time ago I was doing Netflix RFP where was calculating something close to success metric, that was called Weighted Popularity Score(WPS). It’s mission was to define a balance between amount of votes and score to give a fair value that indicated quality, a large number of ratings and broad awareness in the public.\n\n\n\n\n\n\n\nClick on the image to check the whole presentation.\n\n\nThis type of score is pretty similar to calculations that search engine uses to rank the websites in the top but there definitely many more variables to account for. Here’s a great article about Reddit’s Hot Ranking that uses very close logic to this!\nFirst time, when I used this formula it felt “I have no idea what I’m doing”. Giving a credit to the article from Hackernoon and the quote when I read how’s Reddit algo works to make sure that my formula is legit. as I know as well only basic algebra.\n\n\n\n\n\nTo cut the long story short, here’s its meaning:\nThe formula combines IMDB ratings and the logarithm of the number of IMDB votes. The logarithmic scaling minimizes the impact of unevenly high or low vote counts while highlighting quality, popularity, and relevance of the rating to votes. By adding 1 to the formula, we avoid taking the logarithm of zero. Let’s begin coding!\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\n\n\n1) Choose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\nAnswer:\n\n\n\n\n\n\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. Breaking Bad\n138.8069\n9.5\n2216074\n\n\n2. The Shawshank Redemption\n138.5429\n9.3\n2949309\n\n\n3. Game of Thrones\n134.9721\n9.2\n2352239\n\n\n4. The Dark Knight\n134.0153\n9.0\n2930213\n\n\n5. The Godfather\n133.7331\n9.2\n2055854\n\n\n6. The Lord of the Rings: The Return of the King\n130.6624\n9.0\n2018856\n\n\n7. Pulp Fiction\n130.2338\n8.9\n2264831\n\n\n8. Inception\n129.9884\n8.8\n2601001\n\n\n9. The Lord of the Rings: The Fellowship of the Ring\n129.3403\n8.9\n2048498\n\n\n10. Fight Club\n129.2115\n8.8\n2381226\n\n\n\n\n\nQuestion 1 Code\ntop_movies &lt;- TITLE_RATINGS |&gt;\n  arrange(desc(weighted_popularity_score)) |&gt;\n  head(10) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\n\n\n\n\n2) Choose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\nAnswer:\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. Robyn Hood\n8.764990\n1.0\n6405\n\n\n2. 321 Action\n9.231123\n1.0\n10209\n\n\n3. The Gringo Papi\n9.467536\n1.1\n5468\n\n\n4. Decrepit Crescendo\n9.913832\n1.2\n3871\n\n\n5. What Must Be Done\n9.995746\n1.1\n8839\n\n\n\n\n\nQuestion 2 Code\nlow_movies &lt;- TITLE_RATINGS |&gt;\n  filter(numVotes &gt;quantile(TITLE_RATINGS$numVotes, 0.9)) |&gt;\n  arrange(weighted_popularity_score) |&gt;\n  head(5) |&gt;\n  inner_join (TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\n\n\nConclusion for 1 & 2, the weighted_popularity_score (WPS) valid compared with the data and show proper calculation to both highest or lowest amount of votes with scores.\n\n\n3) Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\nOne of my the most favorite movies is “Inception” so let’s take Cillian Murphy to check the WPS.\nAnswer:\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. The Dark Knight\n134.01527\n9.0\n2930213\n\n\n2. Inception\n129.98838\n8.8\n2601001\n\n\n3. Peaky Blinders\n118.12761\n8.8\n675758\n\n\n4. Batman Begins\n117.17419\n8.2\n1606446\n\n\n5. Oppenheimer\n112.84997\n8.3\n803217\n\n\n\n\n\nQuestion 3 Code\n#finding cillian murphy id in the dataset\ncillian_murphy &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Cillian Murphy\") |&gt;\n  select(nconst, primaryName)\n\nsuccessful_actor &lt;- TITLE_PRINCIPALS |&gt;\n  filter(nconst == \"nm0614165\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  arrange(desc(weighted_popularity_score)) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\n\n\n\n\n4) Perform at least one other form of ‘spot check’ validation.\nThe best way to cut unpopular vs popular movies is to verify with minimum and maximum functions. And do a quick check where are the most points are.\nMin: 4.62 Max: 138.8\n\n\nQuestion 4 Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\nmin_score &lt;- min(TITLE_RATINGS$weighted_popularity_score, na.rm = TRUE)\nmax_score &lt;- max(TITLE_RATINGS$weighted_popularity_score, na.rm = TRUE)\n\nTITLE_RATINGS |&gt;\n  ggplot(aes(x = weighted_popularity_score)) +\n  geom_histogram(bins = 50) +\n  xlab(\"Weighted Popularity Score\") +\n  ylab(\"Number of Titles\") +\n  ggtitle(\"Distribution of Weighted Popularity Scores\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n5) Come up with a numerical threshold for a project to be a ‘success’; that is, determine a value v such that movies above v are all “solid” or better.\nThe 90th percentile corresponds to a 59.87, so we will set a threshold value not lower than 59 to capture the truly successful movies.\n\n\nQuestion 5 - Code\nquantiles &lt;- quantile(TITLE_RATINGS$weighted_popularity_score, probs = seq(0, 1, 0.1), na.rm = TRUE)\nprint(quantiles)\n\n\n        0%        10%        20%        30%        40%        50%        60% \n  4.624973  27.429451  32.152835  35.240087  37.728284  40.266733  43.192933 \n       70%        80%        90%       100% \n 46.804929  51.731514  59.864480 138.772311 \n\n\nQuestion 5 - Code\nsuccess_threshold &lt;- 59\n\n\n\n\nTask 4. Trends in Success Over Time\nAlright, now we can check data more with a threshold set to find successful plots that attract the audience.\n\n\nTask 4 - Data Prep\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\ntitles_data &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\")\nmovies_data &lt;- titles_data |&gt;\n  filter(titleType == \"movie\")\nmovies_data &lt;- movies_data |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 1900 & startYear &lt;= 2024)\nmovies_data &lt;- movies_data |&gt;\n  separate_rows(genres, sep = \",\")\nmovies_data &lt;- movies_data |&gt;\n  filter(genres != \"\\\\N\")\nsuccess_threshold &lt;- 59\nmovies_data &lt;- movies_data |&gt;\n  mutate(is_success = ifelse(weighted_popularity_score &gt;= success_threshold, TRUE, FALSE))\n#creating a decade\nmovies_data &lt;- movies_data |&gt;\n  mutate(decade = floor(startYear / 10) * 10)\n\n# a) Count successes by genre and decade\ngenre_decade_successes &lt;- movies_data |&gt;\n  filter(is_success) |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n# b) Total number of movies by genre and decade\ngenre_decade_totals &lt;- movies_data |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n# c) Calculate success rate\ngenre_decade_stats &lt;- genre_decade_successes |&gt;\n  inner_join(genre_decade_totals, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count)\n\n\n\n\n1) What was the genre with the most “successes” in each decade?\nPreviously, we assigned the threshold and further analyses will be based on this “success metric”.\nSpoiler: People love Drama!\n\n\n\nDecade\nGenre\nSuccess Count\n\n\n\n\n1910\nDrama\n3\n\n\n1920\nDrama\n51\n\n\n1930\nDrama\n133\n\n\n1940\nDrama\n237\n\n\n1950\nDrama\n341\n\n\n1960\nDrama\n424\n\n\n1970\nDrama\n469\n\n\n1980\nDrama\n574\n\n\n1990\nDrama\n1093\n\n\n2000\nDrama\n1808\n\n\n2010\nDrama\n2446\n\n\n2020\nDrama\n975\n\n\n\n\n\nQuestion 1 - Code\ntop_genres_per_decade &lt;- genre_decade_successes |&gt;\n  group_by(decade) |&gt;\n  top_n(1, wt = success_count) |&gt;\n  arrange(decade)\n\n\nPlotting over time with new gganimate knowledge.\n\n\nQuestion 1 - Moving plot\nif (!require(gganimate)) install.packages(\"gganimate\")\nif (!require(gifski)) install.packages(\"gifski\")\nif (!require(av)) install.packages(\"av\")\nif (!require(scales)) install.packages(\"scales\")\n\n# Load libraries\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(av)\nlibrary(scales)\nlibrary(dplyr)\nlibrary(tidyr)\n#I was doing this code separately in R, so you will see some variables we did before \nmovies_data &lt;- movies_data |&gt;\n  mutate(is_success = ifelse(weighted_popularity_score &gt;= success_threshold, TRUE, FALSE))\n\ngenre_decade_successes &lt;- movies_data |&gt;\n  filter(is_success) |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n\ntop_genres_overall &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(total_successes = sum(success_count), .groups = 'drop') |&gt;\n  arrange(desc(total_successes)) |&gt;\n  head(10) |&gt;\n  pull(genres)\n\nplot_data &lt;- genre_decade_successes |&gt;\n  filter(genres %in% top_genres_overall)\n\n# Collapsed animated plot as it breaks during rendering, works locally well!\n# animation &lt;- ggplot(plot_data, aes(x = reorder(genres, success_count), y = success_count, fill = genres)) +\n#   geom_bar(stat = \"identity\") +\n#   coord_flip() +\n#   labs(title = \"Number of Successful Movies by Genre in {closest_state}\",\n#        x = \"Genre\",\n#        y = \"Number of Successful Movies\") +\n#   theme_minimal() +\n#   theme(legend.position = \"none\",\n#         plot.title = element_text(size = 16, face = \"bold\")) +\n#   transition_states(decade, transition_length = 2, state_length = 1) +\n#   ease_aes('cubic-in-out')\n# \n# # Render\n# animate(animation, renderer = gifski_renderer(), width = 800, height = 600)\n# anim_save(\"genre_successes.gif\", animation = last_animation())\n\n\n\n\n\nGenre Successes Animation\n\n\n\n\n2) What genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\nAnswer:\n\n\n\nGenres\nDecades with success\nTotal successes\n\n\n\n\nDrama\n12\n8554\n\n\nAction\n12\n2767\n\n\nCrime\n12\n2639\n\n\nRomance\n12\n2419\n\n\nAdventure\n12\n1826\n\n\nHistory\n12\n687\n\n\nWar\n12\n446\n\n\nComedy\n11\n4379\n\n\nThriller\n11\n1809\n\n\nBiography\n11\n1146\n\n\nMystery\n11\n1143\n\n\nHorror\n11\n1012\n\n\nDocumentary\n11\n883\n\n\nFantasy\n11\n762\n\n\nAnimation\n11\n632\n\n\n\n\n\nQuestion 2 - Code\ngenre_decade_presence &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(decades_with_success = n_distinct(decade), .groups = 'drop')\n\ntotal_successes_per_genre &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(total_successes = sum(success_count), .groups = 'drop')\n\ngenre_consistency &lt;- genre_decade_presence |&gt;\n  inner_join(total_successes_per_genre, by = \"genres\") |&gt;\n  arrange(desc(decades_with_success), desc(total_successes))\n\n\n\n\n3) What genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nWhat genre has produced the most “successes” since 2010?\nAnswer: Drama has produced the most “successes” since 2010, with 3,421 successful movies.\nDoes it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nAnswer: Drama does not have the highest success rate. Its large number of successes is primarily due to the high number of productions in that genre. The success rate for Drama is 12%, which is lower than genres like Biography 22.4% and Adventure 20.3%.\n\n\nQuestion 3 - Code\nmovies_since_2010 &lt;- movies_data |&gt;\n  filter(startYear &gt;= 2010)\n\nsuccesses_since_2010 &lt;- movies_since_2010 |&gt;\n  filter(is_success) |&gt;\n  group_by(genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n\ntotal_since_2010 &lt;- movies_since_2010 |&gt;\n  group_by(genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n\ngenre_success_rate_since_2010 &lt;- successes_since_2010 |&gt;\n  inner_join(total_since_2010, by = \"genres\") |&gt;\n  mutate(success_rate = success_count / total_count) |&gt;\n  arrange(desc(success_count))\n\n\nHere’s a plot:\n\n\nQuestion 3 - Code\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(genre_success_rate_since_2010, aes(x = reorder(genres, success_count), y = success_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_line(aes(y = success_rate * max(success_count), group = 1), color = \"red\", size = 1) +\n  geom_point(aes(y = success_rate * max(success_count)), color = \"black\", size = 2) +\n  scale_y_continuous(\n    name = \"Success Count\",\n    sec.axis = sec_axis(~ . / max(genre_success_rate_since_2010$success_count), name = \"Success Rate\", labels = percent_format(accuracy = 1))\n  ) +\n  labs(\n    title = \"Success Count and Success Rate by Genre Since 2010\",\n    x = \"Genre\"\n  ) +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n4) What genre has become more popular in recent years?\nAnswer: The News genre has become x10 times more popular in recent years, exhibiting the highest growth rate among all genres according to the provided data.\n\n\nQuestion 4 - Code\ngenre_decade_totals_all &lt;- movies_data |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n\n# Total movies per genre from previous decade\ngenre_growth &lt;- genre_decade_totals_all |&gt;\n  arrange(genres, decade) |&gt;\n  group_by(genres) |&gt;\n  mutate(previous_total = lag(total_count),\n         growth = (total_count - previous_total) / previous_total) |&gt;\n  ungroup()\n\n# Recent decades from 1990 onwards\nrecent_genre_growth &lt;- genre_growth |&gt;\n  filter(decade &gt;= 1990 & !is.na(growth))\n\ntop_growing_genres &lt;- recent_genre_growth |&gt;\n  arrange(desc(growth)) |&gt;\n  head(10)\n\nprint(top_growing_genres)\n\n\n# A tibble: 10 × 5\n   decade genres      total_count previous_total growth\n    &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt;          &lt;int&gt;  &lt;dbl&gt;\n 1   2010 News                147             12  11.2 \n 2   2000 News                 12              2   5   \n 3   2000 Documentary        2225            554   3.02\n 4   2010 Biography          2097            677   2.10\n 5   2010 History            1551            512   2.03\n 6   2020 Reality-TV           12              4   2   \n 7   2000 Sport               396            152   1.61\n 8   2010 Documentary        5551           2225   1.49\n 9   2000 Music               653            268   1.44\n10   2000 Horror             2180            898   1.43\n\n\n\n\nTask 5. Key Personnel\nLet’s prapare the data to get at least 2 best actors and 1 director.\n\n\nTask 5 - Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\n# Merge TITLE_BASICS, TITLE_RATINGS, and TITLE_PRINCIPALS\nmovies_data &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"tconst\") |&gt;\n  filter(category %in% c(\"actor\", \"actress\", \"director\"))\n\nmovies_data &lt;- movies_data |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 2010 & titleType == \"movie\")\n\n# Join with NAME_BASICS to get actor and director names\nmovies_data &lt;- movies_data |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  select(nconst, primaryName, category, tconst, primaryTitle, startYear, genres, weighted_popularity_score)\n\n#FOR ACTORS/ACTRESSES ONLY\n# Calculate average success metric for actors and actresses\nactor_success &lt;- movies_data |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 3)  # Consider actors with at least 3 movies\n#DIRECTORS ONLY\n# Filter for directors\ndirector_data &lt;- TITLE_CREW |&gt;\n  separate_rows(directors, sep = \",\") |&gt;\n  rename(nconst = directors) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 2010 & titleType == \"movie\") |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  select(nconst, primaryName, tconst, primaryTitle, startYear, genres, weighted_popularity_score)\n\n\nWe will concentrate on two genres Action and War to get our top actors and directors.\n\n\nTask 5 - Code\n# Calculate average success metric for directors\ndirector_success &lt;- director_data |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 2)  # Consider directors with at least 2 movies\n\n#TOP ACTORS\npreferred_genres &lt;- c(\"Action\", \"War\")\n\n# Filter movies in preferred genres\nactors_in_genres &lt;- movies_data |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  filter(genres %in% preferred_genres)\n\n# Average success for actors in preferred genres\nactor_success_genre &lt;- actors_in_genres |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 2)  # At least 2 movies in preferred genres\n\n# Top 5 actors\ntop_actors &lt;- actor_success_genre |&gt;\n  arrange(desc(average_success)) |&gt;\n  head(5)\n# print(top_actors)\n\n#TOP DIRECTOR \n# Filter director movies in preferred genres\ndirectors_in_genres &lt;- director_data |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  filter(genres %in% preferred_genres)\n\n# Average success for directors in preferred genres\ndirector_success_genre &lt;- directors_in_genres |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 1)  # At least 1 movie in preferred genres\n\ntop_directors &lt;- director_success_genre |&gt;\n  arrange(desc(average_success)) |&gt;\n  head(3)\n# print(top_directors)\n\n\nAnswer:\n\nTop Actors\n\n\nPrimary Name\nAverage Success\nTotal Movies\n\n\n\n\nLeonardo DiCaprio\n120\n2\n\n\nTimothée Chalamet\n111\n2\n\n\nDon Cheadle\n108\n10\n\n\nRobert Downey Jr.\n107\n15\n\n\nMark Ruffalo\n107\n12\n\n\n\nAnswer:\n\nTop Directors\n\n\nPrimary Name\nAverage Success\nTotal Movies\n\n\n\n\nChristopher Nolan\n114\n4\n\n\nRodney Rothman\n113\n1\n\n\nBob Persichetti\n113\n1\n\n\n\nI’ve combined directors and actors successes scores and highlighted selected ones.\n\n\nBar plot\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Get top 5 actors and top 3 directors\ntop_actors &lt;- actor_success_genre %&gt;%\n  arrange(desc(average_success)) %&gt;%\n  head(5)\n\ntop_directors &lt;- director_success_genre %&gt;%\n  arrange(desc(average_success)) %&gt;%\n  head(3)\n\nplot_data &lt;- bind_rows(\n  top_actors %&gt;% mutate(Talent = \"Actor\"),\n  top_directors %&gt;% mutate(Talent = \"Director\")\n)\n\n# Highlight selected talents\nselected_names &lt;- c(\"Leonardo DiCaprio\", \"Robert Downey Jr.\", \"Christopher Nolan\")\nplot_data &lt;- plot_data %&gt;%\n  mutate(Selected = ifelse(primaryName %in% selected_names, \"Selected\", \"Others\"))\n\n# Create the bar chart\nggplot(plot_data, aes(x = reorder(primaryName, average_success), y = average_success, fill = Selected)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Average Success Scores of Top Actors and Directors\",\n    x = \"Talent\",\n    y = \"Average Success Score\"\n  ) +\n  scale_fill_manual(values = c(\"Selected\" = \"blue\", \"Others\" = \"grey\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nTask 6: Finding a Classic Movie to Remake\nLawrence of Arabia is an epic classic that presents a profound and captivating narrative, making it an ideal candidate for a modern remake. IMDb rating of 8.3 and a substantial number of ratings, reflecting its enduring popularity. There has been no remake of this classic action and war film in the past 25 years. Since the original actors and director are deceased, we can proceed with a new cast featuring Leonardo DiCaprio and Robert Downey Jr., directed by Christopher Nolan. To move forward, we need to clarify and secure the legal rights from Columbia Pictures, the current rights holder.\n\n\nTask 7: Write and Deliver Your Pitch\nElevator Pitch:\nWe propose a groundbreaking remake of the epic classic “Lawrence of Arabia”, a film that holds an impressive IMDb rating of 8.3 with over 275,000 votes, yet has not been remade in over 25 years. This presents a unique opportunity to reintroduce this timeless story to a new generation. Our project perfectly aligns with the high-performing action and war genres, which boast success rates exceeding 20% since 2010.\nChristopher Nolan, renowned for his visionary storytelling in films like “Inception” and “Dunkirk”, will direct this ambitious remake. Leading the cast, Leonardo DiCaprio will embody the complex character of T.E. Lawrence, bringing depth and nuance to the role. Alongside him, Robert Downey Jr. will add his charisma and talent to a pivotal supporting role, enhancing the film’s appeal.\nWith this exceptional team, we aim to create a cinematic masterpiece that honors the original while captivating modern audiences. Securing the rights from Columbia Pictures will allow us to proceed, and with your approval, we can begin this exciting journey.\n\nClassic 90’s Style Teaser:\n\nFrom director Christopher Nolan, the visionary mind behind “Inception” and “Dunkirk”;\nAnd from actor Leonardo DiCaprio, beloved star of “The Revenant”;\nAnd from actor Robert Downey Jr., Hollywood icon of action and war films;\nComes the timeless tale “Lawrence of Arabia”.\nA story of courage, identity, and destiny.\nComing soon to a theater near you."
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini-Project 03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "In this project, we’re crafting a political fact-check, one of the most defining formats of contemporary journalism. Our focus will be on examining whether the US Electoral College consistently skews election outcomes away from the popular vote. As we explore political data, we’ll also gain a deeper understanding of the workings of federal elections in the United States.\nIn this project, we’ll:"
  },
  {
    "objectID": "mp03.html#data-i-us-house-election-votes-from-1976-to-2022-downloading-the-data",
    "href": "mp03.html#data-i-us-house-election-votes-from-1976-to-2022-downloading-the-data",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data I: US House Election Votes from 1976 to 2022 Downloading the data",
    "text": "Data I: US House Election Votes from 1976 to 2022 Downloading the data\n\n\nDownloading the data\npresident_data_path &lt;- \"/Users/valeriafrolova/STA9750-2024-FALL/docs/1976-2020-president.csv\"\nhouse_data_path &lt;- \"/Users/valeriafrolova/STA9750-2024-FALL/docs/1976-2022-house.csv\"\n\n# Load the datasets\npresident_data &lt;- read.csv(president_data_path)\nhouse_data &lt;- read.csv(house_data_path)\n\n# Preview the data\nhead(president_data)\n\n\n  year   state state_po state_fips state_cen state_ic       office\n1 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n2 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n3 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n4 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n5 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n6 1976 ALABAMA       AL          1        63       41 US PRESIDENT\n                candidate             party_detailed writein candidatevotes\n1           CARTER, JIMMY                   DEMOCRAT   FALSE         659170\n2            FORD, GERALD                 REPUBLICAN   FALSE         504070\n3          MADDOX, LESTER AMERICAN INDEPENDENT PARTY   FALSE           9198\n4 BUBAR, BENJAMIN \"\"BEN\"\"                PROHIBITION   FALSE           6669\n5               HALL, GUS        COMMUNIST PARTY USE   FALSE           1954\n6         MACBRIDE, ROGER                LIBERTARIAN   FALSE           1481\n  totalvotes  version notes party_simplified\n1    1182850 20210113    NA         DEMOCRAT\n2    1182850 20210113    NA       REPUBLICAN\n3    1182850 20210113    NA            OTHER\n4    1182850 20210113    NA            OTHER\n5    1182850 20210113    NA            OTHER\n6    1182850 20210113    NA      LIBERTARIAN\n\n\nDownloading the data\nhead(house_data)\n\n\n  year   state state_po state_fips state_cen state_ic   office district stage\n1 1976 ALABAMA       AL          1        63       41 US HOUSE        1   GEN\n2 1976 ALABAMA       AL          1        63       41 US HOUSE        1   GEN\n3 1976 ALABAMA       AL          1        63       41 US HOUSE        1   GEN\n4 1976 ALABAMA       AL          1        63       41 US HOUSE        2   GEN\n5 1976 ALABAMA       AL          1        63       41 US HOUSE        2   GEN\n6 1976 ALABAMA       AL          1        63       41 US HOUSE        2   GEN\n  runoff special                  candidate      party writein  mode\n1  FALSE   FALSE             BILL DAVENPORT   DEMOCRAT   FALSE TOTAL\n2  FALSE   FALSE               JACK EDWARDS REPUBLICAN   FALSE TOTAL\n3  FALSE   FALSE                    WRITEIN               TRUE TOTAL\n4  FALSE   FALSE            J CAROLE KEAHEY   DEMOCRAT   FALSE TOTAL\n5  FALSE   FALSE WILLIAM L \"BILL\" DICKINSON REPUBLICAN   FALSE TOTAL\n6  FALSE   FALSE                    WRITEIN               TRUE TOTAL\n  candidatevotes totalvotes unofficial  version fusion_ticket\n1          58906     157170      FALSE 20230706         FALSE\n2          98257     157170      FALSE 20230706         FALSE\n3              7     157170      FALSE 20230706         FALSE\n4          66288     156362      FALSE 20230706         FALSE\n5          90069     156362      FALSE 20230706         FALSE\n6              5     156362      FALSE 20230706         FALSE"
  },
  {
    "objectID": "mp03.html#data-ii-congressional-boundary-files-1976-to-2012-task-1-download-congressional-shapefiles-1976-2012",
    "href": "mp03.html#data-ii-congressional-boundary-files-1976-to-2012-task-1-download-congressional-shapefiles-1976-2012",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data II: Congressional Boundary Files 1976 to 2012 Task 1: Download Congressional Shapefiles 1976-2012",
    "text": "Data II: Congressional Boundary Files 1976 to 2012 Task 1: Download Congressional Shapefiles 1976-2012\n\n\nDownloading the Shapefiles\n# Create directory for shapefiles\ndir.create(\"data/shapefiles\", showWarnings = FALSE, recursive = TRUE)\n\n# Function to download shapefiles systematically\ndownload_shapefiles &lt;- function(start, end, base_url) {\n  for (session in start:end) {\n    file_name &lt;- paste0(\"districts\", sprintf(\"%03d\", session), \".zip\")\n    url &lt;- paste0(base_url, file_name)\n    destfile &lt;- file.path(\"data/shapefiles\", file_name)\n    \n    if (!file.exists(destfile)) {\n      GET(url, write_disk(destfile, overwrite = TRUE))\n      message(paste(\"Downloaded:\", file_name))\n    } else {\n      message(paste(\"File already exists:\", file_name))\n    }\n  }\n}\n\n# Define the base URL and download the files\nbase_url &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\ndownload_shapefiles(94, 112, base_url)\n\n# Create directory for shapefiles if it doesn't exist\ndir.create(\"data/census_shapefiles\", showWarnings = FALSE, recursive = TRUE)"
  },
  {
    "objectID": "mp03.html#data-iii-congressional-boundary-files-2014-to-present-task-2-download-congressional-shapefiles-2014-2022",
    "href": "mp03.html#data-iii-congressional-boundary-files-2014-to-present-task-2-download-congressional-shapefiles-2014-2022",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data III: Congressional Boundary Files 2014 to Present Task 2: Download Congressional Shapefiles 2014-2022",
    "text": "Data III: Congressional Boundary Files 2014 to Present Task 2: Download Congressional Shapefiles 2014-2022\n\n\nShapefiles\n# List of download URLs and file names for the shapefiles\nshapefile_urls &lt;- c(\n  \"https://www2.census.gov/geo/tiger/TIGER2014/CD/tl_2014_us_cd114.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2015/CD/tl_2015_us_cd114.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2016/CD/tl_2016_us_cd115.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2017/CD/tl_2017_us_cd115.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2018/CD/tl_2018_us_cd116.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2019/CD/tl_2019_us_cd116.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2020/CD/tl_2020_us_cd116.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2021/CD/tl_2021_us_cd116.zip\",\n  \"https://www2.census.gov/geo/tiger/TIGER2022/CD/tl_2022_us_cd116.zip\"\n)\n\n# Function to download shapefiles systematically\ndownload_shapefiles_census &lt;- function(urls, dest_dir) {\n  for (url in urls) {\n    file_name &lt;- basename(url)\n    destfile &lt;- file.path(dest_dir, file_name)\n    \n    if (!file.exists(destfile)) {\n      GET(url, write_disk(destfile, overwrite = TRUE))\n      message(paste(\"Downloaded:\", file_name))\n    } else {\n      message(paste(\"File already exists:\", file_name))\n    }\n  }\n}\n\n# Define the destination directory and download the files\ndest_dir &lt;- \"data/census_shapefiles\"\ndownload_shapefiles_census(shapefile_urls, dest_dir)"
  },
  {
    "objectID": "mp03.html#task-3-exploration-of-vote-count-data",
    "href": "mp03.html#task-3-exploration-of-vote-count-data",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Task 3: Exploration of Vote Count Data",
    "text": "Task 3: Exploration of Vote Count Data\n\nWhich states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\nTexas gained the biggest amount of votes, while New York lost the most of seats.\n\n\nCode: Gained vs Lost\nhouse_seats &lt;- house_data |&gt;\n  filter(year %in% c(1976, 2022)) |&gt;\n  distinct(year, state, district) |&gt;\n  group_by(year, state) |&gt;\n  summarise(seat_count = n(), .groups = \"drop\")\n\nseat_changes &lt;- house_seats |&gt;\n  pivot_wider(names_from = year, values_from = seat_count, names_prefix = \"year_\") |&gt;\n  mutate(seat_change = year_2022 - year_1976) |&gt;\n  arrange(desc(seat_change))\n\nmax_gain &lt;- seat_changes |&gt;\n  filter(seat_change == max(seat_change, na.rm = TRUE))\n\nmax_loss &lt;- seat_changes |&gt;\n  filter(seat_change == min(seat_change, na.rm = TRUE))\n\n# Display the result\nprint(seat_changes)\n\n\n# A tibble: 50 × 4\n   state          year_1976 year_2022 seat_change\n   &lt;chr&gt;              &lt;int&gt;     &lt;int&gt;       &lt;int&gt;\n 1 TEXAS                 24        38          14\n 2 FLORIDA               15        28          13\n 3 CALIFORNIA            43        52           9\n 4 ARIZONA                4         9           5\n 5 GEORGIA               10        14           4\n 6 COLORADO               5         8           3\n 7 NEVADA                 1         4           3\n 8 NORTH CAROLINA        11        14           3\n 9 WASHINGTON             7        10           3\n10 OREGON                 4         6           2\n# ℹ 40 more rows\n\n\nCode: Gained vs Lost\nprint(max_gain)\n\n\n# A tibble: 1 × 4\n  state year_1976 year_2022 seat_change\n  &lt;chr&gt;     &lt;int&gt;     &lt;int&gt;       &lt;int&gt;\n1 TEXAS        24        38          14\n\n\nCode: Gained vs Lost\nprint(max_loss)\n\n\n# A tibble: 1 × 4\n  state    year_1976 year_2022 seat_change\n  &lt;chr&gt;        &lt;int&gt;     &lt;int&gt;       &lt;int&gt;\n1 NEW YORK        39        26         -13\n\n\nCode: Gained vs Lost\n#plot \nstate_seat_changes &lt;- seat_changes |&gt;\n  arrange(seat_change) |&gt;\n  mutate(state = factor(state, levels = state))\n\n# Create the horizontal bar plot\nggplot(state_seat_changes, aes(x = seat_change, y = state, fill = seat_change &gt; 0)) +\n  geom_bar(stat = 'identity') +\n  scale_fill_manual(values = c(\"red\", \"blue\"), guide = FALSE) +\n  labs(\n    title = \"Seat Changes in US House of Representatives (1976-2022)\",\n    x = \"Seat Change\",\n    y = \"State\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7))\n\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\n\n\n\n\n\n\n\n\n\n\nNew York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).\n\nAre there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\nFusion system plays important role, as one candidate can get votes from several parties. You can find below the outcomes comparison for non-fusion system, that proves that actual winners for fusion system are not having the same winning status for non-fusion.\n\n\nFusion vs. Non-Fusion Votes Comparison\n# Step 1: Filter for New York State and select relevant columns\nny_house_data &lt;- house_data |&gt;\n  filter(state == \"NEW YORK\") |&gt;\n  dplyr::select(year, district, candidate, party, candidatevotes)\n\n# Step 2: Determine actual winners (with fusion votes)\nactual_winners &lt;- ny_house_data |&gt;\n  group_by(year, district, candidate) |&gt;\n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  group_by(year, district) |&gt;\n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  select(year, district, actual_winner = candidate)  \nactual_winners \n\n\n# A tibble: 748 × 3\n# Groups:   year, district [748]\n    year district actual_winner       \n   &lt;int&gt;    &lt;int&gt; &lt;chr&gt;               \n 1  1976        1 OTIS G PIKE         \n 2  1976        2 THOMAS J DOWNEY     \n 3  1976        3 JEROME A AMBRO JR   \n 4  1976        4 NORMAN F LENT       \n 5  1976        5 JOHN W WYDLER       \n 6  1976        6 LESTER L WOLF       \n 7  1976        7 JOSEPH P ADDABBO    \n 8  1976        8 BENJAMIN S ROSENTHAL\n 9  1976        9 JAMES J DELANEY     \n10  1976       10 MARIO BIAGGI        \n# ℹ 738 more rows\n\n\nFusion vs. Non-Fusion Votes Comparison\n# Step 3: Determine hypothetical winners (without fusion votes)\nhypothetical_winners &lt;- ny_house_data |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, district, candidate) |&gt;\n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  group_by(year, district) |&gt;\n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  dplyr::select(year, district, hypothetical_winner = candidate)\nhypothetical_winners\n\n\n# A tibble: 748 × 3\n# Groups:   year, district [748]\n    year district hypothetical_winner \n   &lt;int&gt;    &lt;int&gt; &lt;chr&gt;               \n 1  1976        1 OTIS G PIKE         \n 2  1976        2 THOMAS J DOWNEY     \n 3  1976        3 JEROME A AMBRO JR   \n 4  1976        4 NORMAN F LENT       \n 5  1976        5 JOHN W WYDLER       \n 6  1976        6 LESTER L WOLF       \n 7  1976        7 JOSEPH P ADDABBO    \n 8  1976        8 BENJAMIN S ROSENTHAL\n 9  1976        9 JAMES J DELANEY     \n10  1976       10 MARIO BIAGGI        \n# ℹ 738 more rows\n\n\nFusion vs. Non-Fusion Votes Comparison\n# Step 4: Compare actual and hypothetical winners\ndifferent_outcomes &lt;- actual_winners |&gt;\n  left_join(hypothetical_winners, by = c(\"year\", \"district\")) |&gt;\n  filter(actual_winner != hypothetical_winner)\n\n# Display the results\nprint(different_outcomes)\n\n\n# A tibble: 22 × 4\n# Groups:   year, district [22]\n    year district actual_winner      hypothetical_winner   \n   &lt;int&gt;    &lt;int&gt; &lt;chr&gt;              &lt;chr&gt;                 \n 1  1976       29 EDWARD W PATTISON  JOSEPH A MARTINO      \n 2  1980        3 GREGORY W CARMAN   JEROME A AMBRO JR     \n 3  1980        6 JOHN LEBOUTILLIER  LESTER L WOLFF        \n 4  1984       20 JOSEPH J DIOGUARDI OREN J TEICHER        \n 5  1986       27 GEORGE C WORTLEY   ROSEMARY S POOLER     \n 6  1992        3 PETER T KING       STEVE A ORLINS        \n 7  1994        1 MICHAEL P FORBES   GEORGE J HOCHBRUECKNER\n 8  1996        1 MICHAEL P FORBES   NORA L BREDES         \n 9  1996       30 JACK QUINN         FRANCIS J PORDUM      \n10  2006       25 JAMES T WALSH      DAN MAFFEI            \n# ℹ 12 more rows\n\n\n\nDo presidential candidates tend to run ahead of or run behind congressional candidates in the same state?\n\nPresidential candidates tend to run ahead of congressional candidates, there’re only several exceptions between 1990 and 1996 they were only behind.\n\n\nPresidential vs. Congressional Votes\nhouse_votes_yearly &lt;- house_data |&gt;\n  group_by(year, state, party) |&gt;\n  summarise(total_votes_house = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup()\nhouse_votes_yearly\n\n\n# A tibble: 5,572 × 4\n    year state   party               total_votes_house\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;                           &lt;int&gt;\n 1  1976 ALABAMA \"\"                                 27\n 2  1976 ALABAMA \"DEMOCRAT\"                     667052\n 3  1976 ALABAMA \"NATIONAL DEMOCRAT\"              1021\n 4  1976 ALABAMA \"PROHIBITION\"                    1111\n 5  1976 ALABAMA \"REPUBLICAN\"                   314970\n 6  1976 ALASKA  \"\"                                292\n 7  1976 ALASKA  \"DEMOCRAT\"                      34194\n 8  1976 ALASKA  \"REPUBLICAN\"                    83722\n 9  1976 ARIZONA \"DEMOCRAT\"                     355747\n10  1976 ARIZONA \"INDEPENDENT\"                   20189\n# ℹ 5,562 more rows\n\n\nPresidential vs. Congressional Votes\npres_votes_yearly &lt;- president_data |&gt;\n  group_by(year, state, party_detailed) |&gt;\n  summarise(\n    total_votes_pres = sum(candidatevotes, na.rm = TRUE),\n    candidate = first(candidate)\n  ) |&gt;\n  ungroup()\npres_votes_yearly\n\n\n# A tibble: 4,051 × 5\n    year state   party_detailed               total_votes_pres candidate        \n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;                                   &lt;int&gt; &lt;chr&gt;            \n 1  1976 ALABAMA \"\"                                        308 \"\"               \n 2  1976 ALABAMA \"AMERICAN INDEPENDENT PARTY\"             9198 \"MADDOX, LESTER\" \n 3  1976 ALABAMA \"COMMUNIST PARTY USE\"                    1954 \"HALL, GUS\"      \n 4  1976 ALABAMA \"DEMOCRAT\"                             659170 \"CARTER, JIMMY\"  \n 5  1976 ALABAMA \"LIBERTARIAN\"                            1481 \"MACBRIDE, ROGER\"\n 6  1976 ALABAMA \"PROHIBITION\"                            6669 \"BUBAR, BENJAMIN…\n 7  1976 ALABAMA \"REPUBLICAN\"                           504070 \"FORD, GERALD\"   \n 8  1976 ALASKA  \"\"                                       1176 \"\"               \n 9  1976 ALASKA  \"DEMOCRAT\"                              44058 \"CARTER, JIMMY\"  \n10  1976 ALASKA  \"LIBERTARIAN\"                            6785 \"MACBRIDE, ROGER\"\n# ℹ 4,041 more rows\n\n\nPresidential vs. Congressional Votes\npres_votes_yearly &lt;- pres_votes_yearly |&gt;\n  rename(party = party_detailed)\n\ncombined_votes_yearly &lt;- pres_votes_yearly |&gt;\n  left_join(house_votes_yearly, by = c(\"year\", \"state\", \"party\")) |&gt;\n  drop_na()\n\ncombined_votes_yearly &lt;- combined_votes_yearly |&gt;\n  mutate(total_votes_house = as.integer(total_votes_house))\ncombined_votes_yearly\n\n\n# A tibble: 2,154 × 6\n    year state   party         total_votes_pres candidate      total_votes_house\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;                    &lt;int&gt; &lt;chr&gt;                      &lt;int&gt;\n 1  1976 ALABAMA \"\"                         308 \"\"                            27\n 2  1976 ALABAMA \"DEMOCRAT\"              659170 \"CARTER, JIMM…            667052\n 3  1976 ALABAMA \"PROHIBITION\"             6669 \"BUBAR, BENJA…              1111\n 4  1976 ALABAMA \"REPUBLICAN\"            504070 \"FORD, GERALD\"            314970\n 5  1976 ALASKA  \"\"                        1176 \"\"                           292\n 6  1976 ALASKA  \"DEMOCRAT\"               44058 \"CARTER, JIMM…             34194\n 7  1976 ALASKA  \"REPUBLICAN\"             71555 \"FORD, GERALD\"             83722\n 8  1976 ARIZONA \"DEMOCRAT\"              295602 \"CARTER, JIMM…            355747\n 9  1976 ARIZONA \"INDEPENDENT\"            19229 \"MCCARTHY, EU…             20189\n10  1976 ARIZONA \"LIBERTARIAN\"             7647 \"MACBRIDE, RO…             12588\n# ℹ 2,144 more rows\n\n\nThat is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\nThe data suggests that a Democratic candidate for president does not always receive more votes than all Democratic congressional candidates in the same state. Specifically, in 1976, in multiple states, Jimmy Carter received fewer votes than the total Democratic congressional candidates, indicating that he was relatively less popular compared to his party’s congressional candidates in those states.\n\n\nDemocrat Presidential vs. Congressional Votes\n# Filter for only Democratic candidates\ncombined_votes_democrats &lt;- combined_votes_yearly |&gt;\n  filter(party == \"DEMOCRAT\")\n\npres_outperformed_house_democrats &lt;- combined_votes_democrats |&gt;\n  filter(total_votes_pres &gt; total_votes_house)\npres_outperformed_house_democrats\n\n\n# A tibble: 317 × 6\n    year state     party    total_votes_pres candidate     total_votes_house\n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;                     &lt;int&gt;\n 1  1976 ALASKA    DEMOCRAT            44058 CARTER, JIMMY             34194\n 2  1976 ARKANSAS  DEMOCRAT           498604 CARTER, JIMMY            260998\n 3  1976 COLORADO  DEMOCRAT           460801 CARTER, JIMMY            454741\n 4  1976 DELAWARE  DEMOCRAT           122461 CARTER, JIMMY            102411\n 5  1976 FLORIDA   DEMOCRAT          1636000 CARTER, JIMMY           1125786\n 6  1976 GEORGIA   DEMOCRAT           979409 CARTER, JIMMY            929829\n 7  1976 ILLINOIS  DEMOCRAT          2271295 CARTER, JIMMY           2246614\n 8  1976 KANSAS    DEMOCRAT           430421 CARTER, JIMMY            348621\n 9  1976 KENTUCKY  DEMOCRAT           615717 CARTER, JIMMY            605680\n10  1976 LOUISIANA DEMOCRAT           661365 CARTER, JIMMY            624098\n# ℹ 307 more rows\n\n\nDemocrat Presidential vs. Congressional Votes\nhouse_outperformed_house_democrats &lt;- combined_votes_democrats |&gt;\n  filter(total_votes_house &gt; total_votes_pres)\nhouse_outperformed_house_democrats\n\n\n# A tibble: 274 × 6\n    year state         party    total_votes_pres candidate     total_votes_house\n   &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;                     &lt;int&gt;\n 1  1976 ALABAMA       DEMOCRAT           659170 CARTER, JIMMY            667052\n 2  1976 ARIZONA       DEMOCRAT           295602 CARTER, JIMMY            355747\n 3  1976 CALIFORNIA    DEMOCRAT          3742284 CARTER, JIMMY           4144324\n 4  1976 CONNECTICUT   DEMOCRAT           647895 CARTER, JIMMY            681730\n 5  1976 HAWAII        DEMOCRAT           147375 CARTER, JIMMY            184166\n 6  1976 IDAHO         DEMOCRAT           126549 CARTER, JIMMY            161899\n 7  1976 INDIANA       DEMOCRAT          1014714 CARTER, JIMMY           1166368\n 8  1976 IOWA          DEMOCRAT           619931 CARTER, JIMMY            709435\n 9  1976 MARYLAND      DEMOCRAT           759612 CARTER, JIMMY            789029\n10  1976 MASSACHUSETTS DEMOCRAT          1429475 CARTER, JIMMY           1509521\n# ℹ 264 more rows\n\n\nDoes this trend differ over time?\nThis chart displays the total votes cast for Presidential candidates versus House candidates over time, showing how voter turnout or engagement has changed across these two types of elections.\nBoth presidential and House votes have steadily increased over time, indicating a rise in voter turnout or engagement across the years. This is likely due to population growth and possibly higher political engagement in more recent elections.\nIn many election cycles, the total votes for Presidential candidates slightly exceed those for House candidates, as shown by the blue line generally trending higher than the red line. In 1990-1997 higher volume of House votes over Presidential can be observed.\n\n\nPresidential vs. Congressional Votes Comparison\nstate_totals &lt;- combined_votes_yearly |&gt;\n  group_by(state) |&gt;\n  summarise(\n    total_votes_pres = sum(total_votes_pres, na.rm = TRUE),\n    total_votes_house = sum(total_votes_house, na.rm = TRUE),\n    vote_difference = sum(total_votes_pres, na.rm = TRUE) - sum(total_votes_house, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\nyearly_totals &lt;- combined_votes_yearly |&gt;\n  group_by(year) |&gt;\n  summarise(\n    total_votes_pres = sum(total_votes_pres, na.rm = TRUE),\n    total_votes_house = sum(total_votes_house, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\nyearly_totals_long &lt;- yearly_totals |&gt;\n  pivot_longer(cols = c(total_votes_pres, total_votes_house), names_to = \"election_type\", values_to = \"total_votes\")\n\n#plotting \n# Compare total votes over time\nggplot(yearly_totals_long, aes(x = year, y = total_votes / 1e6, color = election_type)) +\n    geom_line(size = 1.2) +\n    labs(\n        title = \"Total Votes: Presidential vs. House Candidates Over Time\",\n        x = \"Year\",\n        y = \"Total Votes (in Millions)\",\n        color = \"Election Type\"\n    ) +\n    theme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nDoes it differ across states or across parties?\nThe chart displays the vote difference between presidential and House candidates by state, with each state showing whether presidential candidates received more or fewer votes than House candidates. Positive values (teal bars): indicate states where presidential candidates received more votes than House candidates. Negative values (red bars): indicate states where House candidates received more votes than presidential candidates.\n\n\nPresidential vs. Congressional Votes Comparison by State\nlibrary(scales)\n\nstate_totals &lt;- state_totals |&gt;\n  mutate(vote_difference = total_votes_pres - total_votes_house)\nstate_totals\n\n\n# A tibble: 51 × 4\n   state                total_votes_pres total_votes_house vote_difference\n   &lt;chr&gt;                           &lt;int&gt;             &lt;int&gt;           &lt;int&gt;\n 1 ALABAMA                      20431192          18352022         2079170\n 2 ALASKA                        2886125           2912424          -26299\n 3 ARIZONA                      20415755          19724679          691076\n 4 ARKANSAS                     11373074           8829935         2543139\n 5 CALIFORNIA                  135638338         129478292         6160046\n 6 COLORADO                     22423083          21690400          732683\n 7 CONNECTICUT                  18022731          16645602         1377129\n 8 DELAWARE                      3882456           3789202           93254\n 9 DISTRICT OF COLUMBIA           324044            331922           -7878\n10 FLORIDA                      75813653          64389176        11424477\n# ℹ 41 more rows\n\n\nPresidential vs. Congressional Votes Comparison by State\n# Plot vote differences by state\nggplot(state_totals, aes(x = reorder(state, vote_difference), y = vote_difference, fill = vote_difference &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Vote Difference by State: Presidential vs. House Candidates\",\n    x = \"State\",\n    y = \"Vote Difference (Presidential - House)\"\n  ) +\n  scale_y_continuous(labels = label_comma()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nAre any presidents particularly more or less popular than their co-partisans?\nCandidates such as Ronald Reagan, George W. Bush, Bill Clinton, and Barack Obama have positive vote differences, meaning they received significantly more votes than their congressional counterparts. This suggests these presidents were particularly popular within their states compared to their co-partisan congressional candidates.\nIn contrast, some entries show negative vote differences, particularly with candidates like Walter Mondale and Jimmy Carter. This suggests these candidates received fewer votes than their party’s congressional candidates in those states, indicating they may have been less popular relative to their co-partisan representatives.\n\n\nPresidential vs. Congressional Votes Comparison by Presidents\nstate_totals &lt;- state_totals |&gt;\n  mutate(vote_difference = total_votes_pres - total_votes_house)\nstate_totals\n\n\n# A tibble: 51 × 4\n   state                total_votes_pres total_votes_house vote_difference\n   &lt;chr&gt;                           &lt;int&gt;             &lt;int&gt;           &lt;int&gt;\n 1 ALABAMA                      20431192          18352022         2079170\n 2 ALASKA                        2886125           2912424          -26299\n 3 ARIZONA                      20415755          19724679          691076\n 4 ARKANSAS                     11373074           8829935         2543139\n 5 CALIFORNIA                  135638338         129478292         6160046\n 6 COLORADO                     22423083          21690400          732683\n 7 CONNECTICUT                  18022731          16645602         1377129\n 8 DELAWARE                      3882456           3789202           93254\n 9 DISTRICT OF COLUMBIA           324044            331922           -7878\n10 FLORIDA                      75813653          64389176        11424477\n# ℹ 41 more rows\n\n\nPresidential vs. Congressional Votes Comparison by Presidents\n# Plot vote differences by state\nggplot(state_totals, aes(x = reorder(state, vote_difference), y = vote_difference, fill = vote_difference &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Vote Difference by State: Presidential vs. House Candidates\",\n    x = \"State\",\n    y = \"Vote Difference (Presidential - House)\"\n  ) +\n  scale_y_continuous(labels = label_comma()) +\n  theme_minimal()"
  },
  {
    "objectID": "mp03.html#project-setup-and-preliminary-data-exploration",
    "href": "mp03.html#project-setup-and-preliminary-data-exploration",
    "title": "Mini-Project 03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Project Setup and Preliminary Data Exploration",
    "text": "Project Setup and Preliminary Data Exploration\n\n\nImport Libraries\n# Load necessary packages\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"httr\")) install.packages(\"httr\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"gt\")) install.packages(\"gt\")\nif (!require(\"gt\")) install.packages(\"DT\")\n\nlibrary(sf)\nlibrary(httr)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gt)\nlibrary(DT)\n\n\nData I: US House Election Votes from 1976 to 2022 - Downloading the data\nThe MIT Election Data Science Lab collects votes from all biennial congressional races in all 50 states here. Download this data as a CSV file using your web browser.\n\n\nDownloading the data\npresident_data_path &lt;- \"/Users/valeriafrolova/STA9750-2024-FALL/docs/1976-2020-president.csv\"\nhouse_data_path &lt;- \"/Users/valeriafrolova/STA9750-2024-FALL/docs/1976-2022-house.csv\"\n\n# Load the datasets\npresident_data &lt;- read.csv(president_data_path)\nhouse_data &lt;- read.csv(house_data_path)\n\n\nData II: Congressional Boundary Files 1976 to 2012\nJeffrey B. Lewis, Brandon DeVine, Lincoln Pritcher, and Kenneth C. Martis have created shapefiles for all US congressional districts from 1789 to 2012; they generously make these available here.\nTask 1: Download Congressional Shapefiles 1976-2012\n\n\nDownloading the Shapefiles\n# Create directory for shapefiles\ndir.create(\"data/shapefiles\", showWarnings = FALSE, recursive = TRUE)\n\n# Function to download shapefiles systematically\ndownload_shapefiles &lt;- function(start, end, base_url) {\n  for (session in start:end) {\n    file_name &lt;- paste0(\"districts\", sprintf(\"%03d\", session), \".zip\")\n    url &lt;- paste0(base_url, file_name)\n    destfile &lt;- file.path(\"data/shapefiles\", file_name)\n    \n    if (!file.exists(destfile)) {\n      GET(url, write_disk(destfile, overwrite = TRUE))\n      message(paste(\"Downloaded:\", file_name))\n    } else {\n      message(paste(\"File already exists:\", file_name))\n    }\n  }\n}\n\n# Define the base URL and download the files\nbase_url &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\ndownload_shapefiles(94, 112, base_url)\n\n# Create directory for shapefiles if it doesn't exist\ndir.create(\"data/census_shapefiles\", showWarnings = FALSE, recursive = TRUE)\n\n\nData III: Congressional Boundary Files 2014 to Present\nTask 2: Download Congressional Shapefiles 2014-2022\n\n\nDownloading the Shapefiles\n# Load necessary library\nlibrary(httr)\n\n# Function to map years to Congress numbers\nget_congress_number &lt;- function(year) {\n  if (year %in% c(2014, 2015)) {\n    return(114)\n  } else if (year %in% c(2016, 2017)) {\n    return(115)\n  } else if (year &gt;= 2018 && year &lt;= 2022) {\n    return(116)\n  } else {\n    stop(\"Congress number for the given year is not defined.\")\n  }\n}\n\n# Function to download shapefiles systematically\ndownload_shapefiles_census &lt;- function(years, dest_dir) {\n  # Create the destination directory if it doesn't exist\n  if (!dir.exists(dest_dir)) {\n    dir.create(dest_dir, recursive = TRUE)\n  }\n  \n  for (year in years) {\n    congress &lt;- get_congress_number(year)\n    \n    # Construct the URL and file name\n    url &lt;- sprintf(\"https://www2.census.gov/geo/tiger/TIGER%d/CD/tl_%d_us_cd%d.zip\", year, year, congress)\n    file_name &lt;- sprintf(\"tl_%d_us_cd%d.zip\", year, congress)\n    destfile &lt;- file.path(dest_dir, file_name)\n    \n    # Check if the file already exists\n    if (!file.exists(destfile)) {\n      # Download the file\n      GET(url, write_disk(destfile, overwrite = TRUE))\n      message(paste(\"Downloaded:\", file_name))\n    } else {\n      message(paste(\"File already exists:\", file_name))\n    }\n  }\n}\n\n# Define the years and destination directory\nyears &lt;- 2014:2022\ndest_dir &lt;- \"data/census_shapefiles\"\n\n# Download the shapefiles\ndownload_shapefiles_census(years, dest_dir)\n\n\nTask 3: Exploration of Vote Count Data\n\nWhich states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\nTexas gained the biggest amount of votes, while New York lost the most of seats.\n\n\nCode: Gained vs Lost\nhouse_seats &lt;- house_data |&gt;\n  filter(year %in% c(1976, 2022)) |&gt;\n  distinct(year, state, district) |&gt;\n  group_by(year, state) |&gt;\n  summarise(seat_count = n(), .groups = \"drop\")\nprint(house_seats)\n\n\n# A tibble: 100 × 3\n    year state       seat_count\n   &lt;int&gt; &lt;chr&gt;            &lt;int&gt;\n 1  1976 ALABAMA              7\n 2  1976 ALASKA               1\n 3  1976 ARIZONA              4\n 4  1976 ARKANSAS             4\n 5  1976 CALIFORNIA          43\n 6  1976 COLORADO             5\n 7  1976 CONNECTICUT          6\n 8  1976 DELAWARE             1\n 9  1976 FLORIDA             15\n10  1976 GEORGIA             10\n# ℹ 90 more rows\n\n\nCode: Gained vs Lost\nseat_changes &lt;- house_seats |&gt;\n  pivot_wider(names_from = year, values_from = seat_count, names_prefix = \"year_\") |&gt;\n  mutate(seat_change = year_2022 - year_1976) |&gt;\n  arrange(desc(seat_change))\n\nmax_gain &lt;- seat_changes |&gt;\n  filter(seat_change == max(seat_change, na.rm = TRUE))\n\nmax_loss &lt;- seat_changes |&gt;\n  filter(seat_change == min(seat_change, na.rm = TRUE))\n\nprint(max_gain)\n\n\n# A tibble: 1 × 4\n  state year_1976 year_2022 seat_change\n  &lt;chr&gt;     &lt;int&gt;     &lt;int&gt;       &lt;int&gt;\n1 TEXAS        24        38          14\n\n\nCode: Gained vs Lost\nprint(max_loss)\n\n\n# A tibble: 1 × 4\n  state    year_1976 year_2022 seat_change\n  &lt;chr&gt;        &lt;int&gt;     &lt;int&gt;       &lt;int&gt;\n1 NEW YORK        39        26         -13\n\n\nCode: Gained vs Lost\n#plot \nstate_seat_changes &lt;- seat_changes |&gt;\n  filter(seat_change != 0) |&gt;\n  arrange(seat_change) |&gt;\n  mutate(state = factor(state, levels = state))\n\n# Create the horizontal bar plot\nggplot(state_seat_changes, aes(x = seat_change, y = state, fill = seat_change &gt; 0)) +\n  geom_bar(stat = 'identity') +\n  scale_fill_manual(values = c(\"red\", \"blue\"), guide = FALSE) +\n  labs(\n    title = \"Seat Changes in US House of Representatives (1976-2022)\",\n    x = \"Seat Change\",\n    y = \"State\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7))\n\n\n\n\n\n\n\n\n\nThe chart shows which states gained or lost seats over the period, with positive changes in blue bars and negative changes in red bars. The length of each bar represents the number of seats gained or lost. Texas has the largest gain, while New York has the largest loss over this period.\n\nAre there any elections in our data where the election would have had a different outcome if the fusion system was not used and candidates only received the votes their received from their major party line (Democrat or Republican) and not their total number of votes across all lines?\n\nNew York State has a unique fusion voting system where one candidate can appear on multiple lines on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent).\nFusion system plays important role, as one candidate can get votes from several parties. You can find below the outcomes comparison for non-fusion system, that proves that actual winners for fusion system are not having the same winning status for non-fusion.\n\n\nFusion vs. Non-Fusion Votes Comparison\n# Step 1: Filter for New York State and select relevant columns\nny_house_data &lt;- house_data |&gt;\n  filter(state == \"NEW YORK\") |&gt;\n  dplyr::select(year, district, candidate, party, candidatevotes)\n\n# Step 2: Determine actual winners (with fusion votes)\nactual_winners &lt;- ny_house_data |&gt;\n  group_by(year, district, candidate) |&gt;\n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  group_by(year, district) |&gt;\n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  select(year, district, actual_winner = candidate)  \n\n# Step 3: Determine hypothetical winners (without fusion votes)\nhypothetical_winners &lt;- ny_house_data |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, district, candidate) |&gt;\n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  group_by(year, district) |&gt;\n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  dplyr::select(year, district, hypothetical_winner = candidate)\n\n# Step 4: Compare actual and hypothetical winners\ndifferent_outcomes &lt;- actual_winners |&gt;\n  left_join(hypothetical_winners, by = c(\"year\", \"district\")) |&gt;\n  filter(actual_winner != hypothetical_winner)\n\n# TABLE VIEW\nrownames(different_outcomes) &lt;- NULL\ndifferent_outcomes &lt;- different_outcomes |&gt;\n  ungroup()\nlibrary(tibble)\ndifferent_outcomes &lt;- as_tibble(different_outcomes)\n\ndifferent_outcomes |&gt;\n  select(year, district, actual_winner, hypothetical_winner) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Fusion vs. Non-Fusion Vote Outcomes in New York\",\n    subtitle = \"Comparison of Actual Winners vs. Hypothetical Winners\"\n  ) |&gt;\n  cols_label(\n    year = \"Year\",\n    district = \"District\",\n    actual_winner = \"Actual Winner\",\n    hypothetical_winner = \"Hypothetical Winner\"\n  ) |&gt;\n  cols_align(\n    align = \"center\",\n    columns = everything()\n  ) |&gt;\n  tab_options(\n    table.font.size = 12,\n    heading.align = \"center\"\n  ) |&gt;\n  tab_style(\n    style = cell_fill(color = \"lightgray\"),\n    locations = cells_body(\n      columns = everything(),\n      rows = seq(1, nrow(different_outcomes), by = 2)\n    )\n  )\n\n\n\n\n\n\n\n\nFusion vs. Non-Fusion Vote Outcomes in New York\n\n\nComparison of Actual Winners vs. Hypothetical Winners\n\n\nYear\nDistrict\nActual Winner\nHypothetical Winner\n\n\n\n\n1976\n29\nEDWARD W PATTISON\nJOSEPH A MARTINO\n\n\n1980\n3\nGREGORY W CARMAN\nJEROME A AMBRO JR\n\n\n1980\n6\nJOHN LEBOUTILLIER\nLESTER L WOLFF\n\n\n1984\n20\nJOSEPH J DIOGUARDI\nOREN J TEICHER\n\n\n1986\n27\nGEORGE C WORTLEY\nROSEMARY S POOLER\n\n\n1992\n3\nPETER T KING\nSTEVE A ORLINS\n\n\n1994\n1\nMICHAEL P FORBES\nGEORGE J HOCHBRUECKNER\n\n\n1996\n1\nMICHAEL P FORBES\nNORA L BREDES\n\n\n1996\n30\nJACK QUINN\nFRANCIS J PORDUM\n\n\n2006\n25\nJAMES T WALSH\nDAN MAFFEI\n\n\n2006\n29\nJOHN R \"RANDY\" KUHL JR\nERIC J MASSA\n\n\n2010\n13\nMICHAEL G GRIMM\nMICHAEL E MCMAHON\n\n\n2010\n19\nNAN HAYMORTH\nJOHN J HALL\n\n\n2010\n24\nRICHARD L HANNA\nMICHAEL A ARCURI\n\n\n2010\n25\nANN MARIE BUERKLE\nDANIEL B MAFFEI\n\n\n2012\n27\nCHRIS COLLINS\nKATHLEEN C HOCHUL\n\n\n2018\n1\nLEE M ZELDIN\nPERRY GERSHON\n\n\n2018\n24\nJOHN M KATKO\nDANA BALTER\n\n\n2018\n27\nCHRIS COLLINS\nNATHAN D MCMURRAY\n\n\n2022\n4\nANTHONY P D’ESPOSITO\nLAURA A GILLEN\n\n\n2022\n17\nMICHAEL V LAWLER\nSEAN PATRICK MALONEY\n\n\n2022\n22\nBRANDON M WILLIAMS\nFRANCIS CONOLE\n\n\n\n\n\n\n\nYes, the table shows instances where the election outcome would indeed have been different if New York’s fusion voting system was not in place. In a fusion system, candidates are allowed to run on multiple party lines, and their votes from all party lines are combined. However, if candidates were only counted for their major party line (Democrat or Republican), some races would have had different winners, as indicated in the table.\n\nDo presidential candidates tend to run ahead of or run behind congressional candidates in the same state?\n\nPresidential candidates typically receive more votes than their party’s congressional candidates in the same election year. However, the data shows notable exceptions: in 1992, both Democratic and Republican presidential candidates received fewer votes than their congressional counterparts. Additionally, in years like 1976, 1980, 1984, 1988, and 1996, only one party’s presidential candidate received more votes than their House candidates, indicating that voter focus sometimes shifts depending on the election year and party dynamics. Overall, while presidential candidates tend to run ahead, there are specific years where this trend does not hold across both parties.\n\n\nPresidential vs. Congressional Votes\n# Aggregate House Votes by Year and Party\nhouse_votes_yearly &lt;- house_data |&gt;\n  group_by(year, party) |&gt;\n  summarise(total_votes_house = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# Aggregate Presidential Votes by Year and Party\npres_votes_yearly &lt;- president_data |&gt;\n  group_by(year, party_detailed) |&gt;\n  summarise(\n    total_votes_pres = sum(candidatevotes, na.rm = TRUE),\n    candidate = first(candidate)\n  ) |&gt;\n  ungroup()\n\n# Rename 'party_detailed' to 'party' for consistency\npres_votes_yearly &lt;- pres_votes_yearly |&gt;\n  rename(party = party_detailed)\n\n# Merge Presidential and House Data\ncombined_votes_yearly &lt;- pres_votes_yearly |&gt;\n  left_join(house_votes_yearly, by = c(\"year\", \"party\")) |&gt;\n  drop_na()\n\n# Ensure 'total_votes_house' is an integer\ncombined_votes_yearly &lt;- combined_votes_yearly |&gt;\n  mutate(total_votes_house = as.integer(total_votes_house))\n\n# **Filter to Show Only Instances Where Presidential Votes &gt; House Votes**\nfiltered_votes_yearly &lt;- combined_votes_yearly |&gt;\n  filter(\n    party != \"\",\n    candidate != \"\",\n    party %in% c(\"DEMOCRAT\", \"REPUBLICAN\"),\n    total_votes_pres &gt; total_votes_house  # New filter condition\n  ) |&gt;\n  select(\n    Year = year,\n    Party = party,\n    Presidential_Candidate = candidate,\n    Presidential_Votes = total_votes_pres,\n    House_Votes = total_votes_house\n  ) |&gt;\n  drop_na()\n\nfiltered_votes_yearly |&gt;\n  gt() \n\n\n\n\n\n\n\n\nYear\nParty\nPresidential_Candidate\nPresidential_Votes\nHouse_Votes\n\n\n\n\n1976\nREPUBLICAN\nFORD, GERALD\n38870893\n31194553\n\n\n1980\nREPUBLICAN\nREAGAN, RONALD\n43642639\n37068793\n\n\n1984\nREPUBLICAN\nREAGAN, RONALD\n54166829\n38540768\n\n\n1988\nREPUBLICAN\nBUSH, GEORGE H.W.\n48642640\n37015826\n\n\n1996\nDEMOCRAT\nCLINTON, BILL\n47295351\n43598585\n\n\n2000\nDEMOCRAT\nGORE, AL\n49662314\n45177356\n\n\n2000\nREPUBLICAN\nBUSH, GEORGE W.\n50311372\n46750176\n\n\n2004\nDEMOCRAT\nKERRY, JOHN\n57449547\n51345579\n\n\n2004\nREPUBLICAN\nBUSH, GEORGE W.\n61872711\n55723203\n\n\n2008\nDEMOCRAT\nOBAMA, BARACK H.\n69338846\n63272262\n\n\n2008\nREPUBLICAN\nMCCAIN, JOHN\n59613835\n51952377\n\n\n2012\nDEMOCRAT\nOBAMA, BARACK H.\n64205850\n58503445\n\n\n2012\nREPUBLICAN\nROMNEY, MITT\n60670117\n57977915\n\n\n2016\nDEMOCRAT\nCLINTON, HILLARY\n65677288\n60957891\n\n\n2020\nDEMOCRAT\nBIDEN, JOSEPH R. JR\n81268908\n76879506\n\n\n2020\nREPUBLICAN\nTRUMP, DONALD J.\n74216146\n72671813\n\n\n\n\n\n\n\nThat is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\nThe data indicates that a Democratic candidate for president often receives more votes than all Democratic congressional candidates combined in the same state. Specifically, in 2020, in multiple states, Joe Biden received more votes than the total votes for Democratic congressional candidates. This suggests that he was relatively more popular compared to his party’s congressional candidates in those states.\nHowever, this trend is not consistent across all elections. For instance, in 1976, Jimmy Carter received fewer votes than the total Democratic congressional candidates in multiple states, indicating that he was relatively less popular compared to his party’s congressional candidates at that time.\n\n\nDemocrat Presidential vs. Congressional Votes\n# Filter for only Democratic candidates\ncombined_votes_democrats &lt;- combined_votes_yearly |&gt;\n  filter(party == \"DEMOCRAT\")\n\npres_outperformed_house_democrats &lt;- combined_votes_democrats |&gt;\n  filter(total_votes_pres &gt; total_votes_house)\n\nhouse_outperformed_house_democrats &lt;- combined_votes_democrats |&gt;\n  filter(total_votes_house &gt; total_votes_pres)\n\n#table view\npres_outperformed_house_democrats |&gt;\n  select(\n    Year = year,\n    State = state,\n    Presidential_Candidate = candidate,\n    Presidential_Votes = total_votes_pres,\n    House_Votes = total_votes_house\n  ) |&gt;\n  arrange(desc(Year), State) |&gt;  # Sort by Year descending and State\n  head(10) |&gt;\n  gt() |&gt;\n  fmt_number(\n    columns = c(Presidential_Votes, House_Votes),\n    decimals = 0,\n    use_seps = TRUE\n  )\n\n\n\n\n\n\n\n\nYear\nState\nPresidential_Candidate\nPresidential_Votes\nHouse_Votes\n\n\n\n\n2020\nALABAMA\nBIDEN, JOSEPH R. JR\n849,624\n608,809\n\n\n2020\nARIZONA\nBIDEN, JOSEPH R. JR\n1,672,143\n1,629,318\n\n\n2020\nARKANSAS\nBIDEN, JOSEPH R. JR\n423,932\n330,485\n\n\n2020\nCALIFORNIA\nBIDEN, JOSEPH R. JR\n11,110,250\n11,084,234\n\n\n2020\nCOLORADO\nBIDEN, JOSEPH R. JR\n1,804,352\n1,679,052\n\n\n2020\nCONNECTICUT\nBIDEN, JOSEPH R. JR\n1,080,831\n1,022,792\n\n\n2020\nDELAWARE\nBIDEN, JOSEPH R. JR\n296,268\n281,382\n\n\n2020\nDISTRICT OF COLUMBIA\nBIDEN, JOSEPH R. JR\n317,323\n299,388\n\n\n2020\nFLORIDA\nBIDEN, JOSEPH R. JR\n5,297,045\n4,942,287\n\n\n2020\nGEORGIA\nBIDEN, JOSEPH R. JR\n2,473,633\n2,393,089\n\n\n\n\n\n\n\nDoes this trend differ over time?\nThis chart displays the total votes cast for Presidential candidates versus House candidates over time, showing how voter turnout or engagement has changed across these two types of elections.\nBoth presidential and House votes have steadily increased over time, indicating a rise in voter turnout or engagement across the years. This is likely due to population growth and possibly higher political engagement in more recent elections.\nIn many election cycles, the total votes for Presidential candidates slightly exceed those for House candidates, as shown by the blue line generally trending higher than the red line. In 1994-1997 higher volume of House votes over Presidential can be observed.\n\n\nPresidential vs. Congressional Votes Comparison\nstate_totals &lt;- combined_votes_yearly |&gt;\n  group_by(state) |&gt;\n  summarise(\n    total_votes_pres = sum(total_votes_pres, na.rm = TRUE),\n    total_votes_house = sum(total_votes_house, na.rm = TRUE),\n    vote_difference = sum(total_votes_pres, na.rm = TRUE) - sum(total_votes_house, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\nyearly_totals &lt;- combined_votes_yearly |&gt;\n  group_by(year) |&gt;\n  summarise(\n    total_votes_pres = sum(total_votes_pres, na.rm = TRUE),\n    total_votes_house = sum(total_votes_house, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\nyearly_totals_long &lt;- yearly_totals |&gt;\n  pivot_longer(cols = c(total_votes_pres, total_votes_house), names_to = \"election_type\", values_to = \"total_votes\")\n\n#plotting \n# Compare total votes over time\nggplot(yearly_totals_long, aes(x = year, y = total_votes / 1e6, color = election_type)) +\n    geom_line(size = 1.2) +\n    labs(\n        title = \"Total Votes: Presidential vs. House Candidates Over Time\",\n        x = \"Year\",\n        y = \"Total Votes (in Millions)\",\n        color = \"Election Type\"\n    ) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\nDoes it differ across states or across parties?\nThe chart displays the vote difference between presidential and House candidates by state, with each state showing whether presidential candidates received more or fewer votes than House candidates. Positive values (teal bars): indicate states where presidential candidates received more votes than House candidates. Negative values (red bars): indicate states where House candidates received more votes than presidential candidates.\n\n\nPresidential vs. Congressional Votes Comparison by State\nlibrary(scales)\n\nstate_totals &lt;- state_totals |&gt;\n  mutate(vote_difference = total_votes_pres - total_votes_house)\n\n# Plot vote differences by state\nggplot(state_totals, aes(x = reorder(state, vote_difference), y = vote_difference, fill = vote_difference &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Vote Difference by State: Presidential vs. House Candidates\",\n    x = \"State\",\n    y = \"Vote Difference (Presidential - House)\"\n  ) +\n  scale_y_continuous(labels = label_comma()) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 5, vjust = 0.3, margin = margin(t = 4, b = 4)) # Increase top and bottom margins\n  )\n\n\n\n\n\n\n\n\n\nAre any presidents particularly more or less popular than their co-partisans?\nCandidates such as Ronald Reagan, George W. Bush, Bill Clinton, and Barack Obama have positive vote differences, meaning they received significantly more votes than their congressional counterparts. This suggests these presidents were particularly popular within their states compared to their co-partisan congressional candidates.\nIn contrast, some entries show negative vote differences, particularly with candidates like Walter Mondale and Jimmy Carter. This suggests these candidates received fewer votes than their party’s congressional candidates in those states, indicating they may have been less popular relative to their co-partisan representatives.\n\n\nPresidential vs. Congressional Votes Comparison by Presidents\npres_total_votes &lt;- pres_votes_yearly |&gt;\n  group_by(year, party, candidate) |&gt;\n  summarise(total_votes_pres = sum(total_votes_pres, na.rm = TRUE)) |&gt;\n  ungroup()\n\nhouse_total_votes &lt;- house_votes_yearly |&gt;\n  group_by(year, party) |&gt;\n  summarise(total_votes_house = sum(total_votes_house, na.rm = TRUE)) |&gt;\n  ungroup()\n\ncombined_votes &lt;- pres_total_votes |&gt;\n  left_join(house_total_votes, by = c(\"year\", \"party\")) |&gt;\n  drop_na()\n# Calculate the vote difference for each president compared to House candidates of the same party\ncombined_votes &lt;- combined_votes |&gt;\n  mutate(vote_difference = total_votes_pres - total_votes_house)\n\n# Filter data to include only rows with vote differences greater than 300,000\nfiltered_votes &lt;- combined_votes |&gt;\n  filter(abs(vote_difference) &gt; 300000)\n\n# Plot the filtered data\nggplot(filtered_votes, aes(x = reorder(candidate, vote_difference), y = vote_difference, fill = vote_difference &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Vote Difference by President(Vote Difference &gt; 100,000)\",\n    x = \"President\",\n    y = \"Vote Difference (Presidential - House)\"\n  ) +\n  scale_y_continuous(labels = scales::label_comma()) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 6, vjust = 0.5, margin = margin(t = 6, b = 8)) # Increase spacing for candidate names\n  )\n\n\n\n\n\n\n\n\n\nShapefiles - Import and Plotting\n\n\nTask 4: Automate Zip File Extraction\n# Load necessary library\nlibrary(sf)\n\n# Create a global list to store the loaded shapefiles to avoid re-loading\nshapefile_cache &lt;- list()\n\n# Function to load shapefiles from zip archives within a specified directory\nextract_and_load_shapefiles &lt;- function(directory_path) {\n  \n  # Get a list of all zip files within the directory\n  zip_archives &lt;- list.files(directory_path, pattern = \"\\\\.zip$\", full.names = TRUE)\n  \n  for (archive_path in zip_archives) {\n    # Create a temporary directory for file extraction\n    temp_dir &lt;- tempdir()\n    unzip(archive_path, exdir = temp_dir)\n    \n    # Identify shapefiles in the extracted contents\n    shp_files &lt;- list.files(temp_dir, pattern = \"\\\\.shp$\", full.names = TRUE, recursive = TRUE)\n    \n    for (file_path in shp_files) {\n      shp_filename &lt;- basename(file_path)\n      \n      # Only read the shapefile if it hasn't been loaded before\n      if (!shp_filename %in% names(shapefile_cache)) {\n        tryCatch({\n          # Read the shapefile and add it to the cache\n          shape_data &lt;- st_read(file_path, quiet = TRUE)\n          shapefile_cache[[shp_filename]] &lt;- shape_data\n        }, error = function(err) {\n          message(\"Error reading file:\", file_path, \" - \", err$message)\n        })\n      }\n    }\n  }\n  \n  # Return the list containing loaded shapefiles\n  return(shapefile_cache)\n}\n\n# Specify the directory containing the shapefile zip files\nshapefile_directory &lt;- \"data/shapefiles\"\n\n# Load shapefiles from the specified directory\nshapefile_cache &lt;- extract_and_load_shapefiles(shapefile_directory)\n\n\n\n\nTask 5: 2020 US Elections\n# Load the election\nelection_data &lt;- read.csv(\"/Users/valeriafrolova/STA9750-2024-FALL/docs/1976-2020-president.csv\")\n\n# Filter data for the 2000 presidential election\nelection_2000 &lt;- election_data %&gt;%\n  filter(year == 2000, office == \"US PRESIDENT\")\n\n# Determine the winning party per state\nstate_winners &lt;- election_2000 %&gt;%\n  group_by(state, state_po) %&gt;%\n  summarise(winning_party = party_simplified[which.max(candidatevotes)]) %&gt;%\n  ungroup()\n\n# Load the US shapefile\nus_states &lt;- shapefile_cache[[\"districts106.shp\"]]\n\n\n# Optional: Filter out territories if needed\nus_states &lt;- us_states %&gt;%\n  filter(!STATENAME %in% c(\"Alaska\", \"Hawaii\", \"Puerto Rico\"))\nstate_abbreviations &lt;- data.frame(\n  STATENAME = c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\",\n                \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\",\n                \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\",\n                \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\",\n                \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\",\n                \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\",\n                \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"),\n  state_po = c(\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\",\n               \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\",\n               \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\",\n               \"WI\", \"WY\")\n)\n\n# Join the state abbreviations to the filtered shapefile data\nus_states_with_abbrev &lt;- us_states %&gt;%\n  left_join(state_abbreviations, by = \"STATENAME\")\n\n# Join election results data to add information on the winning party by state\nmap_data &lt;- us_states_with_abbrev %&gt;%\n  left_join(state_winners, by = \"state_po\")\n\n# Define a bold color scheme for Republican and Democratic states\nparty_color_map &lt;- c(\n  \"REPUBLICAN\" = \"#B82100\",  # Bold red for Republicans\n  \"DEMOCRAT\" = \"#0057CE\"     # Bold blue for Democrats\n)\n\n# Ensure geometries are valid before aggregating\nus_states_valid &lt;- us_states_with_abbrev %&gt;%\n  st_make_valid()\n\n# Join election results data and aggregate to state level\nstate_map_data &lt;- us_states_valid %&gt;%\n  left_join(state_winners, by = \"state_po\") %&gt;%\n  group_by(state_po, winning_party) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\") |&gt; # Combine geometries to get state boundaries only\n  st_as_sf() %&gt;%\n  st_transform(crs = 5070)  # Albers Equal Area projection for the U.S.\n\n# Calculate centroids for placing state labels in the center of each state\nstate_centroids &lt;- st_centroid(state_map_data)\n\nstate_centroids &lt;- state_centroids %&gt;%\n  mutate(label = state_po)\n\n# Create the map plot\nggplot(data = state_map_data) +\n  geom_sf(aes(fill = winning_party), color = \"white\", size = 0.6) +  # Thicker white borders for states\n  scale_fill_manual(\n    values = party_color_map,\n    name = \"Won\",  # Legend title\n    labels = c(\"Democratic Party - Gore\", \"Republican Party - Bush\")  # Explicitly label colors in the legend\n  ) +\n  geom_text(data = state_centroids, aes(geometry = geometry, label = state_po),\n            size = 4, color = \"white\", fontface = \"bold\", stat = \"sf_coordinates\") +  # Place single abbreviation at the center\n  labs(\n    title = \"2000 U.S. Elections\",\n    subtitle = \"Gore vs. Bush\"\n  ) +\n  theme_void() +  # Remove axes, gridlines, and background for a cleaner look\n  theme(\n    legend.position = \"bottom\",  # Place legend at the bottom for clear interpretation\n    plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),\n    plot.subtitle = element_text(size = 10, hjust = 0.5),\n    panel.border = element_blank(),\n    panel.background = element_rect(fill = \"transparent\")\n  )\n\n\n\n\n\n\n\n\n\nTask 6: Faceted Map\n\n\nTask 6: Faceted Map\n# Ensure STATENAME is present in state_map_data\nstate_map_data &lt;- us_states_valid |&gt;\n  left_join(state_winners, by = \"state_po\") |&gt;\n  group_by(state_po, winning_party, STATENAME) |&gt;\n  summarise(geometry = st_union(geometry), .groups = \"drop\") |&gt; # Combine geometries to get state boundaries only\n  st_as_sf() %&gt;%\n  st_transform(crs = 5070)  # Albers Equal Area projection for the U.S.\n\n# Faceted Map Plot\nggplot(data = state_map_data) +\n  geom_sf(aes(fill = winning_party), color = \"white\", size = 0.4) +\n  scale_fill_manual(values = party_color_map, name = \"Winning Party\") +\n  labs(\n    title = \"2000 U.S. Presidential Election Results by State\",\n    subtitle = \"Faceted view by state, displaying the winning party\",\n    caption = \"Source: 2000 U.S. Presidential Election Data\"\n  ) +\n  theme_void() +\n  theme(\n    strip.text = element_text(face = \"bold\", size = 10),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    plot.subtitle = element_text(hjust = 0.5, size = 10)\n  ) +\n  facet_wrap(~STATENAME, ncol = 5)\n\n\n\n\n\n\n\n\n\nTask 7: Evaluating Fairness of ECV Allocation Schemes\nGoing through the historical voting data, here’s each state’s ECVs according to various strategies:\nState-Wide Winner-Take-All District-Wide Winner-Take-All + State-Wide At Large Votes State-Wide Proportional National Proportional\nWrite a fact check evaluating the fairness of the different ECV electoral allocation schemes.\nTo do so, you should first determine which allocation scheme you consider fairest. You should then see which schemes give different results, if they ever do. To make your fact check more compelling, select one election where the ECV scheme had the largest impact–if one exists–and explain how the results would have been different under a different ECV scheme.\nAnalyzing the impact of different Electoral College Vote (ECV) allocation methods, we assign each state’s ECVs according to various strategies to observe outcomes. The resulting data table will showcase the winning candidate and their ECV totals under each allocation rule. Before proceeding, we need to identify each state’s ECV allocation for each election year.\n\n\nECV Task\necv_state &lt;- house_data |&gt;\n  group_by(year, state) |&gt;\n  summarize(total_reps = n_distinct(district)) |&gt;\n  mutate(ecv = total_reps + 2) |&gt;\n  select(year, state, ecv)\ndatatable(setNames(ecv_state,\n                  c(\"Year\", \"State\", \"ECV\")),\n          options = list(pageLength = 10, \n                         autoWidth = TRUE))\n\n\n\n\n\n\nIn a state-wide winner-take-all strategy, the state awards all its electoral college votes (R+2) to the candidate with the highest popular vote within that state. Simply put, the candidate receiving the most votes in the state captures all its electoral votes.\n\n\nState-Wide Winner-Take-All\nstate_winner_take_all &lt;- president_data |&gt;\n  group_by(year,\n           state,\n           candidate) |&gt;\n  summarize(total_votes = sum(candidatevotes),\n            .groups = \"drop\") |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = total_votes,\n            n=1,\n            with_ties = FALSE) |&gt;\n  rename(winner = candidate)\n\n# Find which candidate gest the most electoral votes\nstate_winner_take_all &lt;- state_winner_take_all |&gt;\n  left_join(ecv_state,\n            by = c(\"year\", \"state\")) |&gt;\n  group_by(year, winner) |&gt;\n  summarize(total_ecv = sum(ecv)) |&gt;\n  slice_max(order_by = total_ecv,\n            n = 1,\n            with_ties = FALSE)\ndatatable(setNames(state_winner_take_all, \n                   c(\"Year\", \"Won Candidate\", \"ECV\")),\n          options = list(pageLength = 10,\n                         autoWidth = TRUE))\n\n\n\n\n\n\nDistrict-Wide Winner-Take-All + State-Wide At Large Votes:\nIn a district-based winner-take-all approach, each district assigns its electoral vote to the candidate who wins within that district. Additionally, the candidate who secures the popular vote across the entire state receives the remaining two electoral votes.\n\n\nDistrict-Wide Winner-Take-All\ndistrict_winner &lt;- house_data |&gt;\n  group_by(year, state, district) |&gt;\n  slice_max(order_by = candidatevotes,\n            n = 1,\n            with_ties = FALSE) |&gt;\n  select(year, \n         state, \n         district, \n         party) |&gt;\n  group_by(year, state, party) |&gt;\n  summarize(districts_won = n())\n# Popular vote winner in the state\npop_winner &lt;- house_data |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = candidatevotes,\n            n = 1,\n            with_ties = FALSE) |&gt;\n  select(year, state, party) |&gt;\n  add_column(pop_votes = 2)\n\ndistrict_wide_winner &lt;- district_winner |&gt;\n  left_join(pop_winner,\n            by = c(\"year\", \"state\", \"party\")) |&gt;\n  mutate(across(where(is.numeric), \n                ~ ifelse(is.na(.), 0, .))) |&gt;\n  mutate(total_electoral = districts_won + pop_votes) |&gt;\n  select(-districts_won, -pop_votes) |&gt;\n  rename(party_simplified = party) |&gt;\n  left_join(president_data,\n            by = c(\"year\", \"state\", \"party_simplified\")) |&gt;\n  select(year, state, total_electoral, candidate) |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(electoral = sum(total_electoral)) |&gt;\n  slice_max(order_by = electoral,\n            n = 1,\n            with_ties = FALSE) |&gt;\n  drop_na()\ndatatable(setNames(district_wide_winner, \n                   c(\"Year\", \"Candidate Votes\", \"ECV\")),\n          options = list(pageLength = 10, autoWidth = TRUE))\n\n\n\n\n\n\nIn a state-wide proportional method, each candidate receives a portion of the state’s electoral college votes according to their share of the popular vote in that state. The following code will determine the winning candidate in each state for each election year.\n\n\nState-Wide Proportional\npresident_data1 &lt;- president_data |&gt;\n  mutate(vote_share = round((candidatevotes / totalvotes), digits = 0))\n\n# Join ecv data and pres races data\npresident_data1 &lt;- president_data1 |&gt;\n  left_join(ecv_state,\n            by = c(\"year\", \"state\"))\n\n# Calculate ECVs per candidate\npresident_data1 &lt;- president_data1 |&gt;\n  mutate(ecv_candidate = round((vote_share * ecv), digits = 0))\n\n# Filter to keep only the candidate with the maximum ECVs per state and year\nstate_proportion &lt;- president_data1 |&gt;\n  group_by(year, state) |&gt;\n  slice_max(ecv_candidate, with_ties = FALSE) |&gt;\n  ungroup()\n\nstate_proportion &lt;- state_proportion |&gt;\n  select(year, state, candidate, ecv_candidate)\nnational_winner &lt;- state_proportion |&gt;\n  group_by(year, candidate) |&gt;\n  summarise(total_ecv = sum(ecv_candidate, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  group_by(year) |&gt;\n  slice_max(total_ecv, with_ties = FALSE) |&gt;\n  ungroup()\n\ndatatable(\n  setNames(national_winner, c(\"Year\", \"Candidate\", \"ECV\")),\n  options = list(pageLength = 10, autoWidth = TRUE)\n)\n\n\n\n\n\n\nIn a national-proportional approach, each candidate’s share of the national popular vote determines their allotment of electoral college votes.\n\n\nNational Proportional\necv_all &lt;- ecv_state |&gt;\n  group_by(year) |&gt;\n  summarize(ecv_vote = sum(ecv))\n\nnational_proportional &lt;- president_data |&gt;\n  select(year, state, candidate, candidatevotes) |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(total_electoral_votes = sum(candidatevotes)) |&gt;\n  group_by(year) |&gt;\n  mutate(pop_vote_count = sum(total_electoral_votes)) |&gt;\n  ungroup() |&gt;\n  mutate(perc_pop_vote = (total_electoral_votes / pop_vote_count)) |&gt;\n  select(-total_electoral_votes, -pop_vote_count) |&gt;\n  left_join(ecv_all,\n            join_by(year == year)) |&gt;\n  mutate(ecv_received = round(perc_pop_vote * ecv_vote, digits = 0)) |&gt;\n  select(-perc_pop_vote, -ecv_vote) |&gt;\n  group_by(year) |&gt;\n  slice_max(order_by = ecv_received,\n            n = 1,\n            with_ties = FALSE) |&gt;\n  rename(winner = candidate)\n\ndatatable(setNames(national_proportional,\n          c(\"Year\", \n            \"Won Candidate\",\n            \"ECV\")),\n          options = list(pageLength = 10,\n                         autoWidth = TRUE))\n\n\n\n\n\n\nFact Check: Evaluating Electoral College Allocation Methods\nWhen comparing fairness across Electoral College allocation methods, four main systems stand out: national proportional, state-wide winner-take-all, district-wide winner-take-all with state-wide at-large votes, and state-wide proportional.\nThe national proportional system often appears the fairest, as it allocates each state’s electoral votes in direct proportion to candidates’ national popular vote shares, closely mirroring the actual voter sentiment across the country. This reduces any single state’s impact and avoids exaggerating the margin for a narrow winner, making it a balanced reflection of the nationwide vote.\nThe state-wide winner-take-all method assigns all of a state’s electoral votes to the candidate with the most votes in that state, regardless of the margin. This can distort outcomes by giving outsized influence to large, competitive states, sometimes resulting in a winner who lacks a true national majority.\nThe district-wide winner-take-all with state-wide at-large votes assigns electoral votes by individual congressional districts, with two additional votes awarded to the state’s overall winner. This method allows representation of varied regional preferences but may still over-represent winning margins within states and does not fully capture the national voter sentiment.\nThe state-wide proportional method divides each state’s electoral votes according to each candidate’s percentage of the state vote, giving a fairer state-by-state distribution. However, it can produce close election outcomes where the national winner is not as clear.\nIn closely contested elections, the national proportional method typically gives the clearest and most balanced outcome, as it minimizes biases tied to specific states and aligns more closely with the popular vote, making it arguably the fairest system."
=======
    "text": "Before we start\n\n1) Import libraries\nThe first step before you start doing anything on your project is to make sure that you have all your packages installed. However, don’t be worried if you miss any, you can add them anywhere in the code, but for readability and clean code writing you should build that habit of importing everything when you start. While we are familiar already with the most of the packages I will add only two comments for new ones.\nNote: The code will be collapsed for better navigation.\n\n\nImport Libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(tidyr)\nlibrary(knitr) #improves readability of outputs\nlibrary(kableExtra) #addition to knitr, styling tables in R Markdown documents \n#install.packages(\"kableExtra\") #if it didn't import, do install command\n\n\n\n\n2) Import the dataset\nIt might take some time to download it and several times I caught myself on thought that R Studio was not working, but it was. Just give it a time, some of the datasets have more than 3M rows!\n\n\nImport IMDb Data\nget_imdb_file &lt;- function(filename) {\n  base_url &lt;- \"https://raw.githubusercontent.com/michaelweylandt/STA9750/main/miniprojects/mini02_preprocessed/\"\n  \n  file_url &lt;- paste0(base_url, filename, \".csv.zip\")\n  dest_file &lt;- paste0(\"data/\", filename, \".csv.zip\")\n  \n  if (!dir.exists(\"data\")) {\n    dir.create(\"data\")\n  }\n  \n  if (!file.exists(dest_file)) {\n    download.file(file_url, destfile = dest_file, mode = \"wb\")\n  }\n  data &lt;- readr::read_csv(dest_file)\n  return(data)\n}\n\nNAME_BASICS      &lt;- get_imdb_file(\"name_basics_small\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title_basics_small\")\nTITLE_EPISODES   &lt;- get_imdb_file(\"title_episodes_small\")\nTITLE_RATINGS    &lt;- get_imdb_file(\"title_ratings_small\")\nTITLE_CREW       &lt;- get_imdb_file(\"title_crew_small\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title_principals_small\")\n\n\nAfter this step we will start our EDA(explanatory data analysis)\n\n\n\nSource: geeksforgeeks.org\n\n\n\n\n3) Data Sub-Sampling\nWe will sample our data to smaller chunks for this analysis and will use “knownForTites” names assigned by IMDb and Titles that have more than 100 ratings as we don’t need anything lower for finding the best samples to follow for our movie idea. As well we will do a semi-join to return only the values that have a match and doesn’t add collumns.\n\n\nData Sub-Sampling\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\n\nData Sub-Sampling\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n\n     0%     25%     50%     75%    100% \n    100     165     332     970 2942823 \n\n\nData Sub-Sampling\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n#semi-join\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\n\n\n4) Data Cleaning\nIn this step, we will correct the column types of the TITLE tables using a combination of mutate and the coercion functions as.numeric and as.logical.\n\n\nNAME_BASICS Example\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\n\nBefore we will change all types it’s useful to check what is your data with glimpse function.\n\n\nGlimpse Example\n# glimpse(NAME_BASICS)\n# glimpse(TITLE_BASICS)\n# glimpse(TITLE_EPISODES)\n# glimpse(TITLE_RATINGS)\n# glimpse(TITLE_CREW)\n# glimpse(TITLE_PRINCIPALS)\n\n\nAnother good function is separate_longer_delim that helps to break view into multiple rows, here’s the example:\n\n\nSeparate_longer_delim function\n# NAME_BASICS |&gt; separate_longer_delim(knownForTitles, \",\") |&gt; slice_head(n=10)\n\n\nHere’s a small schema that shows all connections between the tables.\n\n\n\n\n\n\nTask 1. Correct all TITLE tables\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(startYear = as.numeric(startYear),\n           endYear = as.numeric(endYear),\n           isAdult = as.logical(as.numeric(isAdult))\n           )\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(seasonNumber = as.numeric(seasonNumber),\n           episodeNumbers = as.numeric(episodeNumber))\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(averageRating = as.numeric(averageRating),\n           numVotes = as.numeric(numVotes))\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate(directors = as.character(directors),\n           writers = as.character(writers))\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate(ordering = as.numeric(ordering),\n           category = as.character(category),\n           job = as.character(job),\n           characters =as.character(characters))\n\nAfter we wrangled and cleaned our dataset we can proceed to simple data manipulations and answer some questions!\n\n\n\nTask 2. Bunch of dataset questions\n\n\n1) How many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nQuestions\nAnswers\n\n\n\n\nHow many movies are in our data set?\n132091\n\n\nHow many TV series?\n29942\n\n\nHow many TV episodes?\n156442\n\n\n\n\n\nQuestion 1 Code\nTITLE_BASICS |&gt;\n  group_by(titleType) |&gt;\n  summarise(count = n())\n\n\n# A tibble: 10 × 2\n   titleType     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 movie        131662\n 2 short         16656\n 3 tvEpisode    155722\n 4 tvMiniSeries   5907\n 5 tvMovie       15007\n 6 tvSeries      29789\n 7 tvShort         410\n 8 tvSpecial      3045\n 9 video          9332\n10 videoGame      4668\n\n\n\n\n2) Who is the oldest living person in our data set?\nAnswer: Traudl Lessing was born in 1625.\n\n\nQuestion 2 Code\noldest_person &lt;- NAME_BASICS |&gt;\n  filter(is.na(deathYear)) |&gt;\n  filter(birthYear == min(birthYear, na.rm = TRUE)) |&gt;\n  select(primaryName,birthYear)\n\n\n\n\n3) There is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\nAnswer: Ozymandias\n\n\nQuestion 3 Code\nbest_episode &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10, numVotes &gt;= 200000) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, titleType)\n\n\n\n\n4) What four projects is the actor Mark Hamill most known for?\nAnswer:\n1. Star Wars: Episode IV - A New Hope\n2. Star Wars: Episode VIII - The Last Jedi\n3. Star Wars: Episode V - The Empire Strikes Back\n4. Star Wars: Episode VI - Return of the Jedi\n\n\nQuestion 4 Code\nhamill_titles &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  separate_rows(knownForTitles, sep = \",\") |&gt;\n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  select (primaryTitle)\n\n\n\n\n5) What TV series, with more than 12 episodes, has the highest average rating?\nAnswer: Breaking Bad with the average rating 9.5.\n\n\nQuestion 5 Code\ntop_series &lt;- TITLE_EPISODES |&gt;\n  count(parentTconst) |&gt;\n  filter(n&gt;12) |&gt;\n  inner_join(TITLE_RATINGS, by = c(\"parentTconst\" = \"tconst\")) |&gt;\n  arrange(desc(averageRating)) |&gt;\n  top_n(1) |&gt;\n  inner_join(TITLE_BASICS, by = c(\"parentTconst\" =\"tconst\")) |&gt;\n  select(primaryTitle, averageRating)\n\n\n\n\n6) Is it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\nAnswer: It’s not true, all episodes from later seasons have 7.4 rating.\n\n\nQuestion 6 Code\nhappy_days &lt;- TITLE_BASICS |&gt;\n  filter(primaryTitle == \"Happy Days\") |&gt;\n  inner_join(TITLE_EPISODES, by = c(\"tconst\" = \"parentTconst\")) |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  group_by(seasonNumber) |&gt;\n  summarise(avg_rating = mean(averageRating, na.rm = TRUE)) |&gt;\n  arrange (seasonNumber)\n\n\n\n\nTask 3. Custom Success Metric\nSome time ago I was doing Netflix RFP where was calculating something close to success metric, that was called Weighted Popularity Score(WPS). It’s mission was to define a balance between amount of votes and score to give a fair value that indicated quality, a large number of ratings and broad awareness in the public.\n\n\n\n\n\n\n\nClick on the image to check the whole presentation.\n\n\nThis type of score is pretty similar to calculations that search engine uses to rank the websites in the top but there definitely many more variables to account for. Here’s a great article about Reddit’s Hot Ranking that uses very close logic to this!\nFirst time, when I used this formula it felt “I have no idea what I’m doing”. Giving a credit to the article from Hackernoon and the quote when I read how’s Reddit algo works to make sure that my formula is legit. as I know as well only basic algebra.\n\n\n\n\n\nTo cut the long story short, here’s its meaning:\nThe formula combines IMDB ratings and the logarithm of the number of IMDB votes. The logarithmic scaling minimizes the impact of unevenly high or low vote counts while highlighting quality, popularity, and relevance of the rating to votes. By adding 1 to the formula, we avoid taking the logarithm of zero. Let’s begin coding!\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\n\n\n1) Choose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\nAnswer:\n\n\n\n\n\n\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. Breaking Bad\n138.8069\n9.5\n2216074\n\n\n2. The Shawshank Redemption\n138.5429\n9.3\n2949309\n\n\n3. Game of Thrones\n134.9721\n9.2\n2352239\n\n\n4. The Dark Knight\n134.0153\n9.0\n2930213\n\n\n5. The Godfather\n133.7331\n9.2\n2055854\n\n\n6. The Lord of the Rings: The Return of the King\n130.6624\n9.0\n2018856\n\n\n7. Pulp Fiction\n130.2338\n8.9\n2264831\n\n\n8. Inception\n129.9884\n8.8\n2601001\n\n\n9. The Lord of the Rings: The Fellowship of the Ring\n129.3403\n8.9\n2048498\n\n\n10. Fight Club\n129.2115\n8.8\n2381226\n\n\n\n\n\nQuestion 1 Code\ntop_movies &lt;- TITLE_RATINGS |&gt;\n  arrange(desc(weighted_popularity_score)) |&gt;\n  head(10) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\n\n\n\n\n2) Choose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\nAnswer:\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. Robyn Hood\n8.764990\n1.0\n6405\n\n\n2. 321 Action\n9.231123\n1.0\n10209\n\n\n3. The Gringo Papi\n9.467536\n1.1\n5468\n\n\n4. Decrepit Crescendo\n9.913832\n1.2\n3871\n\n\n5. What Must Be Done\n9.995746\n1.1\n8839\n\n\n\n\n\nQuestion 2 Code\nlow_movies &lt;- TITLE_RATINGS |&gt;\n  filter(numVotes &gt;quantile(TITLE_RATINGS$numVotes, 0.9)) |&gt;\n  arrange(weighted_popularity_score) |&gt;\n  head(5) |&gt;\n  inner_join (TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\n\n\nConclusion for 1 & 2, the weighted_popularity_score (WPS) valid compared with the data and show proper calculation to both highest or lowest amount of votes with scores.\n\n\n3) Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\nOne of my the most favorite movies is “Inception” so let’s take Cillian Murphy to check the WPS.\nAnswer:\n\n\n\nPrimary Title\nWPS\nAverage Rating\nNumber of Votes\n\n\n\n\n1. The Dark Knight\n134.01527\n9.0\n2930213\n\n\n2. Inception\n129.98838\n8.8\n2601001\n\n\n3. Peaky Blinders\n118.12761\n8.8\n675758\n\n\n4. Batman Begins\n117.17419\n8.2\n1606446\n\n\n5. Oppenheimer\n112.84997\n8.3\n803217\n\n\n\n\n\nQuestion 3 Code\n#finding cillian murphy id in the dataset\ncillian_murphy &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Cillian Murphy\") |&gt;\n  select(nconst, primaryName)\n\nsuccessful_actor &lt;- TITLE_PRINCIPALS |&gt;\n  filter(nconst == \"nm0614165\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  arrange(desc(weighted_popularity_score)) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  select(primaryTitle, weighted_popularity_score, averageRating, numVotes)\n\n\n\n\n4) Perform at least one other form of ‘spot check’ validation.\nThe best way to cut unpopular vs popular movies is to verify with minimum and maximum functions. And do a quick check where are the most points are.\nMin: 4.62 Max: 138.8\n\n\nQuestion 4 Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\nmin_score &lt;- min(TITLE_RATINGS$weighted_popularity_score, na.rm = TRUE)\nmax_score &lt;- max(TITLE_RATINGS$weighted_popularity_score, na.rm = TRUE)\n\nTITLE_RATINGS |&gt;\n  ggplot(aes(x = weighted_popularity_score)) +\n  geom_histogram(bins = 50) +\n  xlab(\"Weighted Popularity Score\") +\n  ylab(\"Number of Titles\") +\n  ggtitle(\"Distribution of Weighted Popularity Scores\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n5) Come up with a numerical threshold for a project to be a ‘success’; that is, determine a value v such that movies above v are all “solid” or better.\nThe 90th percentile corresponds to a 59.87, so we will set a threshold value not lower than 59 to capture the truly successful movies.\n\n\nQuestion 5 - Code\nquantiles &lt;- quantile(TITLE_RATINGS$weighted_popularity_score, probs = seq(0, 1, 0.1), na.rm = TRUE)\nprint(quantiles)\n\n\n        0%        10%        20%        30%        40%        50%        60% \n  4.624973  27.429451  32.152835  35.240087  37.728284  40.266733  43.192933 \n       70%        80%        90%       100% \n 46.804929  51.731514  59.864480 138.772311 \n\n\nQuestion 5 - Code\nsuccess_threshold &lt;- 59\n\n\n\n\nTask 4. Trends in Success Over Time\nAlright, now we can check data more with a threshold set to find successful plots that attract the audience.\n\n\nTask 4 - Data Prep\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\ntitles_data &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\")\nmovies_data &lt;- titles_data |&gt;\n  filter(titleType == \"movie\")\nmovies_data &lt;- movies_data |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 1900 & startYear &lt;= 2024)\nmovies_data &lt;- movies_data |&gt;\n  separate_rows(genres, sep = \",\")\nmovies_data &lt;- movies_data |&gt;\n  filter(genres != \"\\\\N\")\nsuccess_threshold &lt;- 59\nmovies_data &lt;- movies_data |&gt;\n  mutate(is_success = ifelse(weighted_popularity_score &gt;= success_threshold, TRUE, FALSE))\n#creating a decade\nmovies_data &lt;- movies_data |&gt;\n  mutate(decade = floor(startYear / 10) * 10)\n\n# a) Count successes by genre and decade\ngenre_decade_successes &lt;- movies_data |&gt;\n  filter(is_success) |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n# b) Total number of movies by genre and decade\ngenre_decade_totals &lt;- movies_data |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n# c) Calculate success rate\ngenre_decade_stats &lt;- genre_decade_successes |&gt;\n  inner_join(genre_decade_totals, by = c(\"decade\", \"genres\")) |&gt;\n  mutate(success_rate = success_count / total_count)\n\n\n\n\n1) What was the genre with the most “successes” in each decade?\nPreviously, we assigned the threshold and further analyses will be based on this “success metric”.\nSpoiler: People love Drama!\n\n\n\nDecade\nGenre\nSuccess Count\n\n\n\n\n1910\nDrama\n3\n\n\n1920\nDrama\n51\n\n\n1930\nDrama\n133\n\n\n1940\nDrama\n237\n\n\n1950\nDrama\n341\n\n\n1960\nDrama\n424\n\n\n1970\nDrama\n469\n\n\n1980\nDrama\n574\n\n\n1990\nDrama\n1093\n\n\n2000\nDrama\n1808\n\n\n2010\nDrama\n2446\n\n\n2020\nDrama\n975\n\n\n\n\n\nQuestion 1 - Code\ntop_genres_per_decade &lt;- genre_decade_successes |&gt;\n  group_by(decade) |&gt;\n  top_n(1, wt = success_count) |&gt;\n  arrange(decade)\n\n\nPlotting over time with new gganimate knowledge.\n\n\nQuestion 1 - Moving plot\nif (!require(gganimate)) install.packages(\"gganimate\")\nif (!require(gifski)) install.packages(\"gifski\")\nif (!require(av)) install.packages(\"av\")\nif (!require(scales)) install.packages(\"scales\")\n\n# Load libraries\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(av)\nlibrary(scales)\nlibrary(dplyr)\nlibrary(tidyr)\n#I was doing this code separately in R, so you will see some variables we did before \nmovies_data &lt;- movies_data |&gt;\n  mutate(is_success = ifelse(weighted_popularity_score &gt;= success_threshold, TRUE, FALSE))\n\ngenre_decade_successes &lt;- movies_data |&gt;\n  filter(is_success) |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n\ntop_genres_overall &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(total_successes = sum(success_count), .groups = 'drop') |&gt;\n  arrange(desc(total_successes)) |&gt;\n  head(10) |&gt;\n  pull(genres)\n\nplot_data &lt;- genre_decade_successes |&gt;\n  filter(genres %in% top_genres_overall)\n\n# Collapsed animated plot as it breaks during rendering, works locally well!\n# animation &lt;- ggplot(plot_data, aes(x = reorder(genres, success_count), y = success_count, fill = genres)) +\n#   geom_bar(stat = \"identity\") +\n#   coord_flip() +\n#   labs(title = \"Number of Successful Movies by Genre in {closest_state}\",\n#        x = \"Genre\",\n#        y = \"Number of Successful Movies\") +\n#   theme_minimal() +\n#   theme(legend.position = \"none\",\n#         plot.title = element_text(size = 16, face = \"bold\")) +\n#   transition_states(decade, transition_length = 2, state_length = 1) +\n#   ease_aes('cubic-in-out')\n# \n# # Render\n# animate(animation, renderer = gifski_renderer(), width = 800, height = 600)\n# anim_save(\"genre_successes.gif\", animation = last_animation())\n\n\n\n\n\nGenre Successes Animation\n\n\n\n\n2) What genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\nAnswer:\n\n\n\nGenres\nDecades with success\nTotal successes\n\n\n\n\nDrama\n12\n8554\n\n\nAction\n12\n2767\n\n\nCrime\n12\n2639\n\n\nRomance\n12\n2419\n\n\nAdventure\n12\n1826\n\n\nHistory\n12\n687\n\n\nWar\n12\n446\n\n\nComedy\n11\n4379\n\n\nThriller\n11\n1809\n\n\nBiography\n11\n1146\n\n\nMystery\n11\n1143\n\n\nHorror\n11\n1012\n\n\nDocumentary\n11\n883\n\n\nFantasy\n11\n762\n\n\nAnimation\n11\n632\n\n\n\n\n\nQuestion 2 - Code\ngenre_decade_presence &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(decades_with_success = n_distinct(decade), .groups = 'drop')\n\ntotal_successes_per_genre &lt;- genre_decade_successes |&gt;\n  group_by(genres) |&gt;\n  summarise(total_successes = sum(success_count), .groups = 'drop')\n\ngenre_consistency &lt;- genre_decade_presence |&gt;\n  inner_join(total_successes_per_genre, by = \"genres\") |&gt;\n  arrange(desc(decades_with_success), desc(total_successes))\n\n\n\n\n3) What genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nWhat genre has produced the most “successes” since 2010?\nAnswer: Drama has produced the most “successes” since 2010, with 3,421 successful movies.\nDoes it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nAnswer: Drama does not have the highest success rate. Its large number of successes is primarily due to the high number of productions in that genre. The success rate for Drama is 12%, which is lower than genres like Biography 22.4% and Adventure 20.3%.\n\n\nQuestion 3 - Code\nmovies_since_2010 &lt;- movies_data |&gt;\n  filter(startYear &gt;= 2010)\n\nsuccesses_since_2010 &lt;- movies_since_2010 |&gt;\n  filter(is_success) |&gt;\n  group_by(genres) |&gt;\n  summarise(success_count = n(), .groups = 'drop')\n\ntotal_since_2010 &lt;- movies_since_2010 |&gt;\n  group_by(genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n\ngenre_success_rate_since_2010 &lt;- successes_since_2010 |&gt;\n  inner_join(total_since_2010, by = \"genres\") |&gt;\n  mutate(success_rate = success_count / total_count) |&gt;\n  arrange(desc(success_count))\n\n\nHere’s a plot:\n\n\nQuestion 3 - Code\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(genre_success_rate_since_2010, aes(x = reorder(genres, success_count), y = success_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_line(aes(y = success_rate * max(success_count), group = 1), color = \"red\", size = 1) +\n  geom_point(aes(y = success_rate * max(success_count)), color = \"black\", size = 2) +\n  scale_y_continuous(\n    name = \"Success Count\",\n    sec.axis = sec_axis(~ . / max(genre_success_rate_since_2010$success_count), name = \"Success Rate\", labels = percent_format(accuracy = 1))\n  ) +\n  labs(\n    title = \"Success Count and Success Rate by Genre Since 2010\",\n    x = \"Genre\"\n  ) +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n4) What genre has become more popular in recent years?\nAnswer: The News genre has become x10 times more popular in recent years, exhibiting the highest growth rate among all genres according to the provided data.\n\n\nQuestion 4 - Code\ngenre_decade_totals_all &lt;- movies_data |&gt;\n  group_by(decade, genres) |&gt;\n  summarise(total_count = n(), .groups = 'drop')\n\n# Total movies per genre from previous decade\ngenre_growth &lt;- genre_decade_totals_all |&gt;\n  arrange(genres, decade) |&gt;\n  group_by(genres) |&gt;\n  mutate(previous_total = lag(total_count),\n         growth = (total_count - previous_total) / previous_total) |&gt;\n  ungroup()\n\n# Recent decades from 1990 onwards\nrecent_genre_growth &lt;- genre_growth |&gt;\n  filter(decade &gt;= 1990 & !is.na(growth))\n\ntop_growing_genres &lt;- recent_genre_growth |&gt;\n  arrange(desc(growth)) |&gt;\n  head(10)\n\nprint(top_growing_genres)\n\n\n# A tibble: 10 × 5\n   decade genres      total_count previous_total growth\n    &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt;          &lt;int&gt;  &lt;dbl&gt;\n 1   2010 News                147             12  11.2 \n 2   2000 News                 12              2   5   \n 3   2000 Documentary        2225            554   3.02\n 4   2010 Biography          2097            677   2.10\n 5   2010 History            1551            512   2.03\n 6   2020 Reality-TV           12              4   2   \n 7   2000 Sport               396            152   1.61\n 8   2010 Documentary        5551           2225   1.49\n 9   2000 Music               653            268   1.44\n10   2000 Horror             2180            898   1.43\n\n\n\n\nTask 5. Key Personnel\nLet’s prapare the data to get at least 2 best actors and 1 director.\n\n\nTask 5 - Code\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n  mutate(weighted_popularity_score = averageRating * log(numVotes + 1))\n\n# Merge TITLE_BASICS, TITLE_RATINGS, and TITLE_PRINCIPALS\nmovies_data &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  inner_join(TITLE_PRINCIPALS, by = \"tconst\") |&gt;\n  filter(category %in% c(\"actor\", \"actress\", \"director\"))\n\nmovies_data &lt;- movies_data |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 2010 & titleType == \"movie\")\n\n# Join with NAME_BASICS to get actor and director names\nmovies_data &lt;- movies_data |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  select(nconst, primaryName, category, tconst, primaryTitle, startYear, genres, weighted_popularity_score)\n\n#FOR ACTORS/ACTRESSES ONLY\n# Calculate average success metric for actors and actresses\nactor_success &lt;- movies_data |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 3)  # Consider actors with at least 3 movies\n#DIRECTORS ONLY\n# Filter for directors\ndirector_data &lt;- TITLE_CREW |&gt;\n  separate_rows(directors, sep = \",\") |&gt;\n  rename(nconst = directors) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  mutate(startYear = as.numeric(startYear)) |&gt;\n  filter(!is.na(startYear) & startYear &gt;= 2010 & titleType == \"movie\") |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  select(nconst, primaryName, tconst, primaryTitle, startYear, genres, weighted_popularity_score)\n\n\nWe will concentrate on two genres Action and War to get our top actors and directors.\n\n\nTask 5 - Code\n# Calculate average success metric for directors\ndirector_success &lt;- director_data |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 2)  # Consider directors with at least 2 movies\n\n#TOP ACTORS\npreferred_genres &lt;- c(\"Action\", \"War\")\n\n# Filter movies in preferred genres\nactors_in_genres &lt;- movies_data |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  filter(genres %in% preferred_genres)\n\n# Average success for actors in preferred genres\nactor_success_genre &lt;- actors_in_genres |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 2)  # At least 2 movies in preferred genres\n\n# Top 5 actors\ntop_actors &lt;- actor_success_genre |&gt;\n  arrange(desc(average_success)) |&gt;\n  head(5)\n# print(top_actors)\n\n#TOP DIRECTOR \n# Filter director movies in preferred genres\ndirectors_in_genres &lt;- director_data |&gt;\n  separate_rows(genres, sep = \",\") |&gt;\n  filter(genres %in% preferred_genres)\n\n# Average success for directors in preferred genres\ndirector_success_genre &lt;- directors_in_genres |&gt;\n  group_by(nconst, primaryName) |&gt;\n  summarise(\n    average_success = mean(weighted_popularity_score, na.rm = TRUE),\n    total_movies = n(),\n    .groups = 'drop'\n  ) |&gt;\n  filter(total_movies &gt;= 1)  # At least 1 movie in preferred genres\n\ntop_directors &lt;- director_success_genre |&gt;\n  arrange(desc(average_success)) |&gt;\n  head(3)\n# print(top_directors)\n\n\nAnswer:\n\nTop Actors\n\n\nPrimary Name\nAverage Success\nTotal Movies\n\n\n\n\nLeonardo DiCaprio\n120\n2\n\n\nTimothée Chalamet\n111\n2\n\n\nDon Cheadle\n108\n10\n\n\nRobert Downey Jr.\n107\n15\n\n\nMark Ruffalo\n107\n12\n\n\n\nAnswer:\n\nTop Directors\n\n\nPrimary Name\nAverage Success\nTotal Movies\n\n\n\n\nChristopher Nolan\n114\n4\n\n\nRodney Rothman\n113\n1\n\n\nBob Persichetti\n113\n1\n\n\n\nI’ve combined directors and actors successes scores and highlighted selected ones.\n\n\nBar plot\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Get top 5 actors and top 3 directors\ntop_actors &lt;- actor_success_genre %&gt;%\n  arrange(desc(average_success)) %&gt;%\n  head(5)\n\ntop_directors &lt;- director_success_genre %&gt;%\n  arrange(desc(average_success)) %&gt;%\n  head(3)\n\nplot_data &lt;- bind_rows(\n  top_actors %&gt;% mutate(Talent = \"Actor\"),\n  top_directors %&gt;% mutate(Talent = \"Director\")\n)\n\n# Highlight selected talents\nselected_names &lt;- c(\"Leonardo DiCaprio\", \"Robert Downey Jr.\", \"Christopher Nolan\")\nplot_data &lt;- plot_data %&gt;%\n  mutate(Selected = ifelse(primaryName %in% selected_names, \"Selected\", \"Others\"))\n\n# Create the bar chart\nggplot(plot_data, aes(x = reorder(primaryName, average_success), y = average_success, fill = Selected)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(\n    title = \"Average Success Scores of Top Actors and Directors\",\n    x = \"Talent\",\n    y = \"Average Success Score\"\n  ) +\n  scale_fill_manual(values = c(\"Selected\" = \"blue\", \"Others\" = \"grey\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nTask 6: Finding a Classic Movie to Remake\nLawrence of Arabia is an epic classic that presents a profound and captivating narrative, making it an ideal candidate for a modern remake. IMDb rating of 8.3 and a substantial number of ratings, reflecting its enduring popularity. There has been no remake of this classic action and war film in the past 25 years. Since the original actors and director are deceased, we can proceed with a new cast featuring Leonardo DiCaprio and Robert Downey Jr., directed by Christopher Nolan. To move forward, we need to clarify and secure the legal rights from Columbia Pictures, the current rights holder.\n\n\nTask 7: Write and Deliver Your Pitch\nElevator Pitch:\nWe propose a groundbreaking remake of the epic classic “Lawrence of Arabia”, a film that holds an impressive IMDb rating of 8.3 with over 275,000 votes, yet has not been remade in over 25 years. This presents a unique opportunity to reintroduce this timeless story to a new generation. Our project perfectly aligns with the high-performing action and war genres, which boast success rates exceeding 20% since 2010.\nChristopher Nolan, renowned for his visionary storytelling in films like “Inception” and “Dunkirk”, will direct this ambitious remake. Leading the cast, Leonardo DiCaprio will embody the complex character of T.E. Lawrence, bringing depth and nuance to the role. Alongside him, Robert Downey Jr. will add his charisma and talent to a pivotal supporting role, enhancing the film’s appeal.\nWith this exceptional team, we aim to create a cinematic masterpiece that honors the original while captivating modern audiences. Securing the rights from Columbia Pictures will allow us to proceed, and with your approval, we can begin this exciting journey.\n\nClassic 90’s Style Teaser:\n\nFrom director Christopher Nolan, the visionary mind behind “Inception” and “Dunkirk”;\nAnd from actor Leonardo DiCaprio, beloved star of “The Revenant”;\nAnd from actor Robert Downey Jr., Hollywood icon of action and war films;\nComes the timeless tale “Lawrence of Arabia”.\nA story of courage, identity, and destiny.\nComing soon to a theater near you."
>>>>>>> db5dd7cbee5f36d537da720fa4e7eb2d3ac3ec82
  }
]